diff --git a/android/vision-quickstart/README.md b/android/vision-quickstart/README.md
index 092c4fe..a14676e 100755
--- a/android/vision-quickstart/README.md
+++ b/android/vision-quickstart/README.md
@@ -1,76 +1,76 @@
-# ML Kit Vision Quickstart Sample App
-
-## Introduction
-
-This ML Kit Quickstart app demonstrates how to use and integrate various vision based ML Kit features into your app.
-
-## Feature List
-
-Features that are included in this Quickstart app:
-* [Object Detection](https://developers.google.com/ml-kit/vision/object-detection/android) - Detect, track, and classify objects in real time and static images
-* [Face Detection](https://developers.google.com/ml-kit/vision/face-detection/android) - Detect faces in real time and static images
-* [Text Recognition](https://developers.google.com/ml-kit/vision/text-recognition/android) - Recognize text in real time and static images
-* [Barcode Scanning](https://developers.google.com/ml-kit/vision/barcode-scanning/android)  - Scan barcodes in real time and static images
-* [Image Labeling](https://developers.google.com/ml-kit/vision/image-labeling/android) - Label images in real time and static images
-* [Custom Image Labeling - Birds](https://developers.google.com/ml-kit/vision/image-labeling/custom-models/android) - Label images of birds with a custom TensorFlow Lite model.
-
-<img src="../screenshots/quickstart-picker.png" width="256"/> <img src="../screenshots/quickstart-image-labeling.png" width="256"/> <img src="../screenshots/quickstart-object-detection.png" width="256"/> 
-
-## Getting Started
-
-* Run the sample code on your Android device or emulator
-* Try extending the code to add new features and functionality
-
-## How to use the app
-
-This app supports three usage scenarios: Live Camera, Static Image, and CameraX enabled live camera.
-
-### Live Camera scenario
-It uses the camera preview as input and contains these API workflows: Object detection & tracking, Face Detection, Text Recognition, Barcode Scanning, and Image Labeling. There's also a settings page that allows you to configure several options:
-* Camera
-    * Preview Size - Specify the preview size of rear camera manually (Default size is chose appropriately based on screen size)
-    * Enable live viewport - Prevent the live camera preview from being blocked by API rendering speed
-* Object detection / Custom Object Detection
-    * Enable Multiple Objects -- Enable multiple objects to be detected at once.
-    * Enable classification -- Enable coarse classification 
-* Face Detection
-    * Landmark Mode -- Toggle between showing no or all facial landmarks
-    * Contour Mode -- Toggle between showing no or all contours
-    * Classification Mode -- Toggle between showing no or all classifications (smiling, eyes open/closed)
-    * Performance Mode -- Toggle between two operating modes (Fast or Accurate)
-    * Face Tracking -- Enable or disable face tracking
-    * Minimum Face Size -- Choose the proportion of the head width to the image width
-* AutoML Image Labeling
-    * AutoML Remote Model Name -- Allows you to specify an AutoML VisionEdge model to remotely download from the Firebase Console
-    * AutoML Model Choices -- Toggle between using the remote or local AutoML model.
-    
-### Static Image scenario
-The static image scenario is identical to the live camera scenario, but instead relies on images fed into the app through the gallery.
-
-### CameraX Live Preview scenario
-The CameraX live preview scenario is very similar to the native live camera scenario, but instead relies on CameraX live preview instead of the Camera2 live preview. Note: CameraX is only supported on API level 21+.
-
-## Support
-
-* [Documentation](https://developers.google.com/ml-kit/guides)
-* [API Reference](https://developers.google.com/ml-kit/reference/android)
-* [Stack Overflow](https://stackoverflow.com/questions/tagged/google-mlkit)
-
-## License
-
-Copyright 2020 Google, Inc.
-
-Licensed to the Apache Software Foundation (ASF) under one or more contributor
-license agreements.  See the NOTICE file distributed with this work for
-additional information regarding copyright ownership.  The ASF licenses this
-file to you under the Apache License, Version 2.0 (the "License"); you may not
-use this file except in compliance with the License.  You may obtain a copy of
-the License at
-
-  http://www.apache.org/licenses/LICENSE-2.0
-
-Unless required by applicable law or agreed to in writing, software
-distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
-License for the specific language governing permissions and limitations under
-the License.
+# ML Kit Vision Quickstart Sample App
+
+## Introduction
+
+This ML Kit Quickstart app demonstrates how to use and integrate various vision based ML Kit features into your app.
+
+## Feature List
+
+Features that are included in this Quickstart app:
+* [Object Detection](https://developers.google.com/ml-kit/vision/object-detection/android) - Detect, track, and classify objects in real time and static images
+* [Face Detection](https://developers.google.com/ml-kit/vision/face-detection/android) - Detect faces in real time and static images
+* [Text Recognition](https://developers.google.com/ml-kit/vision/text-recognition/android) - Recognize text in real time and static images
+* [Barcode Scanning](https://developers.google.com/ml-kit/vision/barcode-scanning/android)  - Scan barcodes in real time and static images
+* [Image Labeling](https://developers.google.com/ml-kit/vision/image-labeling/android) - Label images in real time and static images
+* [Custom Image Labeling - Birds](https://developers.google.com/ml-kit/vision/image-labeling/custom-models/android) - Label images of birds with a custom TensorFlow Lite model.
+
+<img src="../screenshots/quickstart-picker.png" width="256"/> <img src="../screenshots/quickstart-image-labeling.png" width="256"/> <img src="../screenshots/quickstart-object-detection.png" width="256"/> 
+
+## Getting Started
+
+* Run the sample code on your Android device or emulator
+* Try extending the code to add new features and functionality
+
+## How to use the app
+
+This app supports three usage scenarios: Live Camera, Static Image, and CameraX enabled live camera.
+
+### Live Camera scenario
+It uses the camera preview as input and contains these API workflows: Object detection & tracking, Face Detection, Text Recognition, Barcode Scanning, and Image Labeling. There's also a settings page that allows you to configure several options:
+* Camera
+    * Preview Size - Specify the preview size of rear camera manually (Default size is chose appropriately based on screen size)
+    * Enable live viewport - Prevent the live camera preview from being blocked by API rendering speed
+* Object detection / Custom Object Detection
+    * Enable Multiple Objects -- Enable multiple objects to be detected at once.
+    * Enable classification -- Enable coarse classification 
+* Face Detection
+    * Landmark Mode -- Toggle between showing no or all facial landmarks
+    * Contour Mode -- Toggle between showing no or all contours
+    * Classification Mode -- Toggle between showing no or all classifications (smiling, eyes open/closed)
+    * Performance Mode -- Toggle between two operating modes (Fast or Accurate)
+    * Face Tracking -- Enable or disable face tracking
+    * Minimum Face Size -- Choose the proportion of the head width to the image width
+* AutoML Image Labeling
+    * AutoML Remote Model Name -- Allows you to specify an AutoML VisionEdge model to remotely download from the Firebase Console
+    * AutoML Model Choices -- Toggle between using the remote or local AutoML model.
+    
+### Static Image scenario
+The static image scenario is identical to the live camera scenario, but instead relies on images fed into the app through the gallery.
+
+### CameraX Live Preview scenario
+The CameraX live preview scenario is very similar to the native live camera scenario, but instead relies on CameraX live preview instead of the Camera2 live preview. Note: CameraX is only supported on API level 21+.
+
+## Support
+
+* [Documentation](https://developers.google.com/ml-kit/guides)
+* [API Reference](https://developers.google.com/ml-kit/reference/android)
+* [Stack Overflow](https://stackoverflow.com/questions/tagged/google-mlkit)
+
+## License
+
+Copyright 2020 Google, Inc.
+
+Licensed to the Apache Software Foundation (ASF) under one or more contributor
+license agreements.  See the NOTICE file distributed with this work for
+additional information regarding copyright ownership.  The ASF licenses this
+file to you under the Apache License, Version 2.0 (the "License"); you may not
+use this file except in compliance with the License.  You may obtain a copy of
+the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the
+License for the specific language governing permissions and limitations under
+the License.
diff --git a/android/vision-quickstart/app/.gitignore b/android/vision-quickstart/app/.gitignore
index 796b96d..3543521 100644
--- a/android/vision-quickstart/app/.gitignore
+++ b/android/vision-quickstart/app/.gitignore
@@ -1 +1 @@
-/build
+/build
diff --git a/android/vision-quickstart/app/build.gradle b/android/vision-quickstart/app/build.gradle
index fa767c8..2cf8d60 100644
--- a/android/vision-quickstart/app/build.gradle
+++ b/android/vision-quickstart/app/build.gradle
@@ -1,103 +1,103 @@
-apply plugin: 'com.android.application'
-apply plugin: 'kotlin-android'
-apply plugin: 'kotlin-android-extensions'
-
-android {
-    compileSdkVersion 29
-
-    defaultConfig {
-        applicationId "com.google.mlkit.vision.demo"
-        minSdkVersion 16
-        multiDexEnabled true
-        targetSdkVersion 29
-
-        versionCode 11
-        versionName "1.11"
-        testInstrumentationRunner "androidx.test.runner.AndroidJUnitRunner"
-        vectorDrawables.useSupportLibrary = true
-    }
-    buildTypes {
-        debug {
-            minifyEnabled false
-            proguardFiles 'proguard-rules.pro'
-        }
-    }
-
-    compileOptions {
-        sourceCompatibility JavaVersion.VERSION_1_8
-        targetCompatibility JavaVersion.VERSION_1_8
-    }
-
-    // Do NOT compress tflite model files (need to call out to developers!)
-    aaptOptions {
-        noCompress "tflite"
-    }
-}
-
-repositories {
-    maven { url 'https://google.bintray.com/tensorflow' }
-}
-
-dependencies {
-    implementation 'org.jetbrains.kotlin:kotlin-stdlib-jdk7:1.3.72'
-
-    // Barcode model
-    implementation 'com.google.mlkit:barcode-scanning:16.0.1'
-
-    // Object detection feature with bundled default classifier
-    implementation 'com.google.mlkit:object-detection:16.1.0'
-
-    // Object detection feature with custom classifier support
-    implementation 'com.google.mlkit:object-detection-custom:16.1.0'
-
-    // Face features
-    implementation 'com.google.mlkit:face-detection:16.0.1'
-
-    // Text features
-    implementation 'com.google.android.gms:play-services-mlkit-text-recognition:16.1.0'
-
-    // Image labeling with automl model support
-    implementation 'com.google.mlkit:image-labeling-automl:16.1.0'
-
-    // Image labeling
-    implementation 'com.google.mlkit:image-labeling:16.1.0'
-
-    // Image labeling custom
-    implementation 'com.google.mlkit:image-labeling-custom:16.1.0'
-
-    // -------------------------------------------------------
-
-    implementation 'com.google.code.gson:gson:2.8.5'
-    implementation 'com.google.guava:guava:17.0'
-
-    // For how to setup gradle dependencies in Android X, see:
-    // https://developer.android.com/training/testing/set-up-project#gradle-dependencies
-    // Core library
-    androidTestImplementation 'androidx.test:core:1.2.0'
-
-    // AndroidJUnitRunner and JUnit Rules
-    androidTestImplementation 'androidx.test:runner:1.2.0'
-    androidTestImplementation 'androidx.test:rules:1.2.0'
-
-    // Assertions
-    androidTestImplementation 'androidx.test.ext:junit:1.1.1'
-
-    // ViewModel and LiveData
-    implementation "androidx.lifecycle:lifecycle-livedata:2.2.0"
-    implementation "androidx.lifecycle:lifecycle-viewmodel:2.2.0"
-
-    implementation 'androidx.appcompat:appcompat:1.1.0'
-    implementation 'androidx.annotation:annotation:1.1.0'
-    implementation 'androidx.constraintlayout:constraintlayout:1.1.3'
-
-    // CameraX
-    implementation "androidx.camera:camera-camera2:1.0.0-beta04"
-    implementation "androidx.camera:camera-lifecycle:1.0.0-beta04"
-    implementation "androidx.camera:camera-view:1.0.0-alpha11"
-}
-
-configurations {
-    // Resolves dependency conflict caused by some dependencies use
-    // com.google.guava:guava and com.google.guava:listenablefuture together.
-    all*.exclude group: 'com.google.guava', module: 'listenablefuture'
-}
+apply plugin: 'com.android.application'
+apply plugin: 'kotlin-android'
+apply plugin: 'kotlin-android-extensions'
+
+android {
+    compileSdkVersion 29
+
+    defaultConfig {
+        applicationId "com.google.mlkit.vision.demo"
+        minSdkVersion 16
+        multiDexEnabled true
+        targetSdkVersion 29
+
+        versionCode 11
+        versionName "1.11"
+        testInstrumentationRunner "androidx.test.runner.AndroidJUnitRunner"
+        vectorDrawables.useSupportLibrary = true
+    }
+    buildTypes {
+        debug {
+            minifyEnabled false
+            proguardFiles 'proguard-rules.pro'
+        }
+    }
+
+    compileOptions {
+        sourceCompatibility JavaVersion.VERSION_1_8
+        targetCompatibility JavaVersion.VERSION_1_8
+    }
+
+    // Do NOT compress tflite model files (need to call out to developers!)
+    aaptOptions {
+        noCompress "tflite"
+    }
+}
+
+repositories {
+    maven { url 'https://google.bintray.com/tensorflow' }
+}
+
+dependencies {
+    implementation 'org.jetbrains.kotlin:kotlin-stdlib-jdk7:1.3.72'
+
+    // Barcode model
+    implementation 'com.google.mlkit:barcode-scanning:16.0.1'
+
+    // Object detection feature with bundled default classifier
+    implementation 'com.google.mlkit:object-detection:16.1.0'
+
+    // Object detection feature with custom classifier support
+    implementation 'com.google.mlkit:object-detection-custom:16.1.0'
+
+    // Face features
+    implementation 'com.google.mlkit:face-detection:16.0.1'
+
+    // Text features
+    implementation 'com.google.android.gms:play-services-mlkit-text-recognition:16.1.0'
+
+    // Image labeling with automl model support
+    implementation 'com.google.mlkit:image-labeling-automl:16.1.0'
+
+    // Image labeling
+    implementation 'com.google.mlkit:image-labeling:16.1.0'
+
+    // Image labeling custom
+    implementation 'com.google.mlkit:image-labeling-custom:16.1.0'
+
+    // -------------------------------------------------------
+
+    implementation 'com.google.code.gson:gson:2.8.5'
+    implementation 'com.google.guava:guava:17.0'
+
+    // For how to setup gradle dependencies in Android X, see:
+    // https://developer.android.com/training/testing/set-up-project#gradle-dependencies
+    // Core library
+    androidTestImplementation 'androidx.test:core:1.2.0'
+
+    // AndroidJUnitRunner and JUnit Rules
+    androidTestImplementation 'androidx.test:runner:1.2.0'
+    androidTestImplementation 'androidx.test:rules:1.2.0'
+
+    // Assertions
+    androidTestImplementation 'androidx.test.ext:junit:1.1.1'
+
+    // ViewModel and LiveData
+    implementation "androidx.lifecycle:lifecycle-livedata:2.2.0"
+    implementation "androidx.lifecycle:lifecycle-viewmodel:2.2.0"
+
+    implementation 'androidx.appcompat:appcompat:1.1.0'
+    implementation 'androidx.annotation:annotation:1.1.0'
+    implementation 'androidx.constraintlayout:constraintlayout:1.1.3'
+
+    // CameraX
+    implementation "androidx.camera:camera-camera2:1.0.0-beta04"
+    implementation "androidx.camera:camera-lifecycle:1.0.0-beta04"
+    implementation "androidx.camera:camera-view:1.0.0-alpha11"
+}
+
+configurations {
+    // Resolves dependency conflict caused by some dependencies use
+    // com.google.guava:guava and com.google.guava:listenablefuture together.
+    all*.exclude group: 'com.google.guava', module: 'listenablefuture'
+}
diff --git a/android/vision-quickstart/app/proguard-rules.pro b/android/vision-quickstart/app/proguard-rules.pro
index f1b4245..6e7ffa9 100644
--- a/android/vision-quickstart/app/proguard-rules.pro
+++ b/android/vision-quickstart/app/proguard-rules.pro
@@ -1,21 +1,21 @@
-# Add project specific ProGuard rules here.
-# You can control the set of applied configuration files using the
-# proguardFiles setting in build.gradle.
-#
-# For more details, see
-#   http://developer.android.com/guide/developing/tools/proguard.html
-
-# If your project uses WebView with JS, uncomment the following
-# and specify the fully qualified class name to the JavaScript interface
-# class:
-#-keepclassmembers class fqcn.of.javascript.interface.for.webview {
-#   public *;
-#}
-
-# Uncomment this to preserve the line number information for
-# debugging stack traces.
-#-keepattributes SourceFile,LineNumberTable
-
-# If you keep the line number information, uncomment this to
-# hide the original source file name.
-#-renamesourcefileattribute SourceFile
+# Add project specific ProGuard rules here.
+# You can control the set of applied configuration files using the
+# proguardFiles setting in build.gradle.
+#
+# For more details, see
+#   http://developer.android.com/guide/developing/tools/proguard.html
+
+# If your project uses WebView with JS, uncomment the following
+# and specify the fully qualified class name to the JavaScript interface
+# class:
+#-keepclassmembers class fqcn.of.javascript.interface.for.webview {
+#   public *;
+#}
+
+# Uncomment this to preserve the line number information for
+# debugging stack traces.
+#-keepattributes SourceFile,LineNumberTable
+
+# If you keep the line number information, uncomment this to
+# hide the original source file name.
+#-renamesourcefileattribute SourceFile
diff --git a/android/vision-quickstart/app/src/main/AndroidManifest.xml b/android/vision-quickstart/app/src/main/AndroidManifest.xml
index 401c252..e7f491b 100755
--- a/android/vision-quickstart/app/src/main/AndroidManifest.xml
+++ b/android/vision-quickstart/app/src/main/AndroidManifest.xml
@@ -1,103 +1,108 @@
-<?xml version="1.0" encoding="utf-8"?>
-<manifest
-    xmlns:android="http://schemas.android.com/apk/res/android"
-    xmlns:tools="http://schemas.android.com/tools"
-    package="com.google.mlkit.vision.demo"
-    android:installLocation="auto">
-
-    <!-- CameraX libraries require minSdkVersion 21, while this quickstart app
-    supports low to 16. Needs to use overrideLibrary to make the merger tool
-    ignore this conflict and import the libraries while keeping the app's lower
-    minSdkVersion value. In code, will check SDK version, before calling CameraX
-    APIs. -->
-    <uses-sdk
-        tools:overrideLibrary="
-          androidx.camera.camera2, androidx.camera.core,
-          androidx.camera.view, androidx.camera.lifecycle" />
-
-    <uses-feature android:name="android.hardware.camera"/>
-
-    <uses-permission android:name="android.permission.INTERNET"/>
-    <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/>
-    <uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE"/>
-    <uses-permission android:name="android.permission.CAMERA"/>
-
-    <application
-        android:name="androidx.multidex.MultiDexApplication"
-        android:icon="@drawable/logo_mlkit"
-        android:label="@string/app_name"
-        android:theme="@style/Theme.AppCompat">
-
-        <meta-data
-            android:name="com.google.android.gms.version"
-            android:value="@integer/google_play_services_version"/>
-
-        <!-- Optional: Add it to automatically download ML model to device after
-          your app is installed.-->
-        <meta-data
-            android:name="com.google.mlkit.vision.DEPENDENCIES"
-            android:value="barcode,face,ocr,ica"/>
-
-        <activity
-            android:name=".EntryChoiceActivity"
-            android:exported="true"
-            android:theme="@style/AppTheme">
-            <intent-filter>
-                <action android:name="android.intent.action.MAIN"/>
-                <category android:name="android.intent.category.LAUNCHER"/>
-            </intent-filter>
-        </activity>
-
-        <activity
-            android:name=".ChooserActivity"
-            android:exported="true">
-        </activity>
-
-        <activity
-            android:name=".LivePreviewActivity"
-            android:exported="true"
-            android:theme="@style/AppTheme">
-        </activity>
-
-        <activity
-            android:name=".CameraXLivePreviewActivity"
-            android:exported="true"
-            android:theme="@style/AppTheme">
-        </activity>
-
-        <activity
-            android:name=".StillImageActivity"
-            android:exported="true"
-            android:theme="@style/AppTheme">
-        </activity>
-
-        <activity
-            android:name=".kotlin.ChooserActivity"
-            android:exported="true">
-        </activity>
-
-        <activity
-            android:name=".kotlin.LivePreviewActivity"
-            android:exported="true"
-            android:theme="@style/AppTheme">
-        </activity>
-
-        <activity
-            android:name=".kotlin.CameraXLivePreviewActivity"
-            android:exported="true"
-            android:theme="@style/AppTheme">
-        </activity>
-
-        <activity
-            android:name=".kotlin.StillImageActivity"
-            android:exported="true"
-            android:theme="@style/AppTheme">
-        </activity>
-
-        <activity
-            android:name=".preference.SettingsActivity"
-            android:exported="false"/>
-
-    </application>
-
-</manifest>
+<?xml version="1.0" encoding="utf-8"?>
+<manifest
+    xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:tools="http://schemas.android.com/tools"
+    package="com.google.mlkit.vision.demo"
+
+    android:installLocation="auto">
+<!--    android:sharedUserId="android.uid.system"-->
+    <!-- CameraX libraries require minSdkVersion 21, while this quickstart app
+    supports low to 16. Needs to use overrideLibrary to make the merger tool
+    ignore this conflict and import the libraries while keeping the app's lower
+    minSdkVersion value. In code, will check SDK version, before calling CameraX
+    APIs. -->
+    <uses-sdk
+        tools:overrideLibrary="
+          androidx.camera.camera2, androidx.camera.core,
+          androidx.camera.view, androidx.camera.lifecycle" />
+
+    <uses-feature android:name="android.hardware.camera"/>
+
+    <uses-permission android:name="android.permission.INTERNET"/>
+    <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/>
+    <uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE"/>
+    <uses-permission android:name="android.permission.CAMERA"/>
+
+    <application
+        android:name="androidx.multidex.MultiDexApplication"
+        android:icon="@drawable/logo_mlkit"
+        android:label="@string/app_name"
+        android:theme="@style/Theme.AppCompat">
+
+        <meta-data
+            android:name="com.google.android.gms.version"
+            android:value="@integer/google_play_services_version"/>
+
+        <!-- Optional: Add it to automatically download ML model to device after
+          your app is installed.-->
+        <meta-data
+            android:name="com.google.mlkit.vision.DEPENDENCIES"
+            android:value="barcode,face,ocr,ica"/>
+
+        <activity
+            android:name=".EntryChoiceActivity"
+            android:exported="true"
+            android:theme="@style/AppTheme">
+<!--            <intent-filter>-->
+<!--                <action android:name="android.intent.action.MAIN"/>-->
+<!--                <category android:name="android.intent.category.LAUNCHER"/>-->
+<!--            </intent-filter>-->
+        </activity>
+
+        <activity
+            android:name=".ChooserActivity"
+            android:exported="true">
+        </activity>
+
+        <activity
+            android:name=".LivePreviewActivity"
+            android:exported="true"
+            android:theme="@style/AppTheme">
+            <intent-filter>
+                <action android:name="android.intent.action.MAIN"/>
+                <category android:name="android.intent.category.LAUNCHER"/>
+            </intent-filter>
+        </activity>
+
+        <activity
+            android:name=".CameraXLivePreviewActivity"
+            android:exported="true"
+            android:theme="@style/AppTheme">
+        </activity>
+
+        <activity
+            android:name=".StillImageActivity"
+            android:exported="true"
+            android:theme="@style/AppTheme">
+        </activity>
+
+        <activity
+            android:name=".kotlin.ChooserActivity"
+            android:exported="true">
+        </activity>
+
+        <activity
+            android:name=".kotlin.LivePreviewActivity"
+            android:exported="true"
+            android:theme="@style/AppTheme">
+        </activity>
+
+        <activity
+            android:name=".kotlin.CameraXLivePreviewActivity"
+            android:exported="true"
+            android:theme="@style/AppTheme">
+        </activity>
+
+        <activity
+            android:name=".kotlin.StillImageActivity"
+            android:exported="true"
+            android:theme="@style/AppTheme">
+        </activity>
+
+        <activity
+            android:name=".preference.SettingsActivity"
+            android:exported="false"/>
+
+    </application>
+
+</manifest>
diff --git a/android/vision-quickstart/app/src/main/assets/automl/dict.txt b/android/vision-quickstart/app/src/main/assets/automl/dict.txt
index 08f0b16..5563b14 100755
--- a/android/vision-quickstart/app/src/main/assets/automl/dict.txt
+++ b/android/vision-quickstart/app/src/main/assets/automl/dict.txt
@@ -1,5 +1,5 @@
-daisy
-dandelion
-roses
-sunflowers
-tulips
+daisy
+dandelion
+roses
+sunflowers
+tulips
diff --git a/android/vision-quickstart/app/src/main/assets/automl/manifest.json b/android/vision-quickstart/app/src/main/assets/automl/manifest.json
index 1176579..84739b0 100755
--- a/android/vision-quickstart/app/src/main/assets/automl/manifest.json
+++ b/android/vision-quickstart/app/src/main/assets/automl/manifest.json
@@ -1,5 +1,5 @@
-{
-  "modelType": "IMAGE_LABELING",
-  "modelFile": "model.tflite",
-  "labelsFile": "dict.txt"
-}
+{
+  "modelType": "IMAGE_LABELING",
+  "modelFile": "model.tflite",
+  "labelsFile": "dict.txt"
+}
diff --git a/android/vision-quickstart/app/src/main/assets/labels.txt b/android/vision-quickstart/app/src/main/assets/labels.txt
index fe81123..a85dcd8 100755
--- a/android/vision-quickstart/app/src/main/assets/labels.txt
+++ b/android/vision-quickstart/app/src/main/assets/labels.txt
@@ -1,1001 +1,1001 @@
-background
-tench
-goldfish
-great white shark
-tiger shark
-hammerhead
-electric ray
-stingray
-cock
-hen
-ostrich
-brambling
-goldfinch
-house finch
-junco
-indigo bunting
-robin
-bulbul
-jay
-magpie
-chickadee
-water ouzel
-kite
-bald eagle
-vulture
-great grey owl
-European fire salamander
-common newt
-eft
-spotted salamander
-axolotl
-bullfrog
-tree frog
-tailed frog
-loggerhead
-leatherback turtle
-mud turtle
-terrapin
-box turtle
-banded gecko
-common iguana
-American chameleon
-whiptail
-agama
-frilled lizard
-alligator lizard
-Gila monster
-green lizard
-African chameleon
-Komodo dragon
-African crocodile
-American alligator
-triceratops
-thunder snake
-ringneck snake
-hognose snake
-green snake
-king snake
-garter snake
-water snake
-vine snake
-night snake
-boa constrictor
-rock python
-Indian cobra
-green mamba
-sea snake
-horned viper
-diamondback
-sidewinder
-trilobite
-harvestman
-scorpion
-black and gold garden spider
-barn spider
-garden spider
-black widow
-tarantula
-wolf spider
-tick
-centipede
-black grouse
-ptarmigan
-ruffed grouse
-prairie chicken
-peacock
-quail
-partridge
-African grey
-macaw
-sulphur-crested cockatoo
-lorikeet
-coucal
-bee eater
-hornbill
-hummingbird
-jacamar
-toucan
-drake
-red-breasted merganser
-goose
-black swan
-tusker
-echidna
-platypus
-wallaby
-koala
-wombat
-jellyfish
-sea anemone
-brain coral
-flatworm
-nematode
-conch
-snail
-slug
-sea slug
-chiton
-chambered nautilus
-Dungeness crab
-rock crab
-fiddler crab
-king crab
-American lobster
-spiny lobster
-crayfish
-hermit crab
-isopod
-white stork
-black stork
-spoonbill
-flamingo
-little blue heron
-American egret
-bittern
-crane
-limpkin
-European gallinule
-American coot
-bustard
-ruddy turnstone
-red-backed sandpiper
-redshank
-dowitcher
-oystercatcher
-pelican
-king penguin
-albatross
-grey whale
-killer whale
-dugong
-sea lion
-Chihuahua
-Japanese spaniel
-Maltese dog
-Pekinese
-Shih-Tzu
-Blenheim spaniel
-papillon
-toy terrier
-Rhodesian ridgeback
-Afghan hound
-basset
-beagle
-bloodhound
-bluetick
-black-and-tan coonhound
-Walker hound
-English foxhound
-redbone
-borzoi
-Irish wolfhound
-Italian greyhound
-whippet
-Ibizan hound
-Norwegian elkhound
-otterhound
-Saluki
-Scottish deerhound
-Weimaraner
-Staffordshire bullterrier
-American Staffordshire terrier
-Bedlington terrier
-Border terrier
-Kerry blue terrier
-Irish terrier
-Norfolk terrier
-Norwich terrier
-Yorkshire terrier
-wire-haired fox terrier
-Lakeland terrier
-Sealyham terrier
-Airedale
-cairn
-Australian terrier
-Dandie Dinmont
-Boston bull
-miniature schnauzer
-giant schnauzer
-standard schnauzer
-Scotch terrier
-Tibetan terrier
-silky terrier
-soft-coated wheaten terrier
-West Highland white terrier
-Lhasa
-flat-coated retriever
-curly-coated retriever
-golden retriever
-Labrador retriever
-Chesapeake Bay retriever
-German short-haired pointer
-vizsla
-English setter
-Irish setter
-Gordon setter
-Brittany spaniel
-clumber
-English springer
-Welsh springer spaniel
-cocker spaniel
-Sussex spaniel
-Irish water spaniel
-kuvasz
-schipperke
-groenendael
-malinois
-briard
-kelpie
-komondor
-Old English sheepdog
-Shetland sheepdog
-collie
-Border collie
-Bouvier des Flandres
-Rottweiler
-German shepherd
-Doberman
-miniature pinscher
-Greater Swiss Mountain dog
-Bernese mountain dog
-Appenzeller
-EntleBucher
-boxer
-bull mastiff
-Tibetan mastiff
-French bulldog
-Great Dane
-Saint Bernard
-Eskimo dog
-malamute
-Siberian husky
-dalmatian
-affenpinscher
-basenji
-pug
-Leonberg
-Newfoundland
-Great Pyrenees
-Samoyed
-Pomeranian
-chow
-keeshond
-Brabancon griffon
-Pembroke
-Cardigan
-toy poodle
-miniature poodle
-standard poodle
-Mexican hairless
-timber wolf
-white wolf
-red wolf
-coyote
-dingo
-dhole
-African hunting dog
-hyena
-red fox
-kit fox
-Arctic fox
-grey fox
-tabby
-tiger cat
-Persian cat
-Siamese cat
-Egyptian cat
-cougar
-lynx
-leopard
-snow leopard
-jaguar
-lion
-tiger
-cheetah
-brown bear
-American black bear
-ice bear
-sloth bear
-mongoose
-meerkat
-tiger beetle
-ladybug
-ground beetle
-long-horned beetle
-leaf beetle
-dung beetle
-rhinoceros beetle
-weevil
-fly
-bee
-ant
-grasshopper
-cricket
-walking stick
-cockroach
-mantis
-cicada
-leafhopper
-lacewing
-dragonfly
-damselfly
-admiral
-ringlet
-monarch
-cabbage butterfly
-sulphur butterfly
-lycaenid
-starfish
-sea urchin
-sea cucumber
-wood rabbit
-hare
-Angora
-hamster
-porcupine
-fox squirrel
-marmot
-beaver
-guinea pig
-sorrel
-zebra
-hog
-wild boar
-warthog
-hippopotamus
-ox
-water buffalo
-bison
-ram
-bighorn
-ibex
-hartebeest
-impala
-gazelle
-Arabian camel
-llama
-weasel
-mink
-polecat
-black-footed ferret
-otter
-skunk
-badger
-armadillo
-three-toed sloth
-orangutan
-gorilla
-chimpanzee
-gibbon
-siamang
-guenon
-patas
-baboon
-macaque
-langur
-colobus
-proboscis monkey
-marmoset
-capuchin
-howler monkey
-titi
-spider monkey
-squirrel monkey
-Madagascar cat
-indri
-Indian elephant
-African elephant
-lesser panda
-giant panda
-barracouta
-eel
-coho
-rock beauty
-anemone fish
-sturgeon
-gar
-lionfish
-puffer
-abacus
-abaya
-academic gown
-accordion
-acoustic guitar
-aircraft carrier
-airliner
-airship
-altar
-ambulance
-amphibian
-analog clock
-apiary
-apron
-ashcan
-assault rifle
-backpack
-bakery
-balance beam
-balloon
-ballpoint
-Band Aid
-banjo
-bannister
-barbell
-barber chair
-barbershop
-barn
-barometer
-barrel
-barrow
-baseball
-basketball
-bassinet
-bassoon
-bathing cap
-bath towel
-bathtub
-beach wagon
-beacon
-beaker
-bearskin
-beer bottle
-beer glass
-bell cote
-bib
-bicycle-built-for-two
-bikini
-binder
-binoculars
-birdhouse
-boathouse
-bobsled
-bolo tie
-bonnet
-bookcase
-bookshop
-bottlecap
-bow
-bow tie
-brass
-brassiere
-breakwater
-breastplate
-broom
-bucket
-buckle
-bulletproof vest
-bullet train
-butcher shop
-cab
-caldron
-candle
-cannon
-canoe
-can opener
-cardigan
-car mirror
-carousel
-carpenter's kit
-carton
-car wheel
-cash machine
-cassette
-cassette player
-castle
-catamaran
-CD player
-cello
-cellular telephone
-chain
-chainlink fence
-chain mail
-chain saw
-chest
-chiffonier
-chime
-china cabinet
-Christmas stocking
-church
-cinema
-cleaver
-cliff dwelling
-cloak
-clog
-cocktail shaker
-coffee mug
-coffeepot
-coil
-combination lock
-computer keyboard
-confectionery
-container ship
-convertible
-corkscrew
-cornet
-cowboy boot
-cowboy hat
-cradle
-crane
-crash helmet
-crate
-crib
-Crock Pot
-croquet ball
-crutch
-cuirass
-dam
-desk
-desktop computer
-dial telephone
-diaper
-digital clock
-digital watch
-dining table
-dishrag
-dishwasher
-disk brake
-dock
-dogsled
-dome
-doormat
-drilling platform
-drum
-drumstick
-dumbbell
-Dutch oven
-electric fan
-electric guitar
-electric locomotive
-entertainment center
-envelope
-espresso maker
-face powder
-feather boa
-file
-fireboat
-fire engine
-fire screen
-flagpole
-flute
-folding chair
-football helmet
-forklift
-fountain
-fountain pen
-four-poster
-freight car
-French horn
-frying pan
-fur coat
-garbage truck
-gasmask
-gas pump
-goblet
-go-kart
-golf ball
-golfcart
-gondola
-gong
-gown
-grand piano
-greenhouse
-grille
-grocery store
-guillotine
-hair slide
-hair spray
-half track
-hammer
-hamper
-hand blower
-hand-held computer
-handkerchief
-hard disc
-harmonica
-harp
-harvester
-hatchet
-holster
-home theater
-honeycomb
-hook
-hoopskirt
-horizontal bar
-horse cart
-hourglass
-iPod
-iron
-jack-o'-lantern
-jean
-jeep
-jersey
-jigsaw puzzle
-jinrikisha
-joystick
-kimono
-knee pad
-knot
-lab coat
-ladle
-lampshade
-laptop
-lawn mower
-lens cap
-letter opener
-library
-lifeboat
-lighter
-limousine
-liner
-lipstick
-Loafer
-lotion
-loudspeaker
-loupe
-lumbermill
-magnetic compass
-mailbag
-mailbox
-maillot
-maillot
-manhole cover
-maraca
-marimba
-mask
-matchstick
-maypole
-maze
-measuring cup
-medicine chest
-megalith
-microphone
-microwave
-military uniform
-milk can
-minibus
-miniskirt
-minivan
-missile
-mitten
-mixing bowl
-mobile home
-Model T
-modem
-monastery
-monitor
-moped
-mortar
-mortarboard
-mosque
-mosquito net
-motor scooter
-mountain bike
-mountain tent
-mouse
-mousetrap
-moving van
-muzzle
-nail
-neck brace
-necklace
-nipple
-notebook
-obelisk
-oboe
-ocarina
-odometer
-oil filter
-organ
-oscilloscope
-overskirt
-oxcart
-oxygen mask
-packet
-paddle
-paddlewheel
-padlock
-paintbrush
-pajama
-palace
-panpipe
-paper towel
-parachute
-parallel bars
-park bench
-parking meter
-passenger car
-patio
-pay-phone
-pedestal
-pencil box
-pencil sharpener
-perfume
-Petri dish
-photocopier
-pick
-pickelhaube
-picket fence
-pickup
-pier
-piggy bank
-pill bottle
-pillow
-ping-pong ball
-pinwheel
-pirate
-pitcher
-plane
-planetarium
-plastic bag
-plate rack
-plow
-plunger
-Polaroid camera
-pole
-police van
-poncho
-pool table
-pop bottle
-pot
-potter's wheel
-power drill
-prayer rug
-printer
-prison
-projectile
-projector
-puck
-punching bag
-purse
-quill
-quilt
-racer
-racket
-radiator
-radio
-radio telescope
-rain barrel
-recreational vehicle
-reel
-reflex camera
-refrigerator
-remote control
-restaurant
-revolver
-rifle
-rocking chair
-rotisserie
-rubber eraser
-rugby ball
-rule
-running shoe
-safe
-safety pin
-saltshaker
-sandal
-sarong
-sax
-scabbard
-scale
-school bus
-schooner
-scoreboard
-screen
-screw
-screwdriver
-seat belt
-sewing machine
-shield
-shoe shop
-shoji
-shopping basket
-shopping cart
-shovel
-shower cap
-shower curtain
-ski
-ski mask
-sleeping bag
-slide rule
-sliding door
-slot
-snorkel
-snowmobile
-snowplow
-soap dispenser
-soccer ball
-sock
-solar dish
-sombrero
-soup bowl
-space bar
-space heater
-space shuttle
-spatula
-speedboat
-spider web
-spindle
-sports car
-spotlight
-stage
-steam locomotive
-steel arch bridge
-steel drum
-stethoscope
-stole
-stone wall
-stopwatch
-stove
-strainer
-streetcar
-stretcher
-studio couch
-stupa
-submarine
-suit
-sundial
-sunglass
-sunglasses
-sunscreen
-suspension bridge
-swab
-sweatshirt
-swimming trunks
-swing
-switch
-syringe
-table lamp
-tank
-tape player
-teapot
-teddy
-television
-tennis ball
-thatch
-theater curtain
-thimble
-thresher
-throne
-tile roof
-toaster
-tobacco shop
-toilet seat
-torch
-totem pole
-tow truck
-toyshop
-tractor
-trailer truck
-tray
-trench coat
-tricycle
-trimaran
-tripod
-triumphal arch
-trolleybus
-trombone
-tub
-turnstile
-typewriter keyboard
-umbrella
-unicycle
-upright
-vacuum
-vase
-vault
-velvet
-vending machine
-vestment
-viaduct
-violin
-volleyball
-waffle iron
-wall clock
-wallet
-wardrobe
-warplane
-washbasin
-washer
-water bottle
-water jug
-water tower
-whiskey jug
-whistle
-wig
-window screen
-window shade
-Windsor tie
-wine bottle
-wing
-wok
-wooden spoon
-wool
-worm fence
-wreck
-yawl
-yurt
-web site
-comic book
-crossword puzzle
-street sign
-traffic light
-book jacket
-menu
-plate
-guacamole
-consomme
-hot pot
-trifle
-ice cream
-ice lolly
-French loaf
-bagel
-pretzel
-cheeseburger
-hotdog
-mashed potato
-head cabbage
-broccoli
-cauliflower
-zucchini
-spaghetti squash
-acorn squash
-butternut squash
-cucumber
-artichoke
-bell pepper
-cardoon
-mushroom
-Granny Smith
-strawberry
-orange
-lemon
-fig
-pineapple
-banana
-jackfruit
-custard apple
-pomegranate
-hay
-carbonara
-chocolate sauce
-dough
-meat loaf
-pizza
-potpie
-burrito
-red wine
-espresso
-cup
-eggnog
-alp
-bubble
-cliff
-coral reef
-geyser
-lakeside
-promontory
-sandbar
-seashore
-valley
-volcano
-ballplayer
-groom
-scuba diver
-rapeseed
-daisy
-yellow lady's slipper
-corn
-acorn
-hip
-buckeye
-coral fungus
-agaric
-gyromitra
-stinkhorn
-earthstar
-hen-of-the-woods
-bolete
-ear
-toilet tissue
+background
+tench
+goldfish
+great white shark
+tiger shark
+hammerhead
+electric ray
+stingray
+cock
+hen
+ostrich
+brambling
+goldfinch
+house finch
+junco
+indigo bunting
+robin
+bulbul
+jay
+magpie
+chickadee
+water ouzel
+kite
+bald eagle
+vulture
+great grey owl
+European fire salamander
+common newt
+eft
+spotted salamander
+axolotl
+bullfrog
+tree frog
+tailed frog
+loggerhead
+leatherback turtle
+mud turtle
+terrapin
+box turtle
+banded gecko
+common iguana
+American chameleon
+whiptail
+agama
+frilled lizard
+alligator lizard
+Gila monster
+green lizard
+African chameleon
+Komodo dragon
+African crocodile
+American alligator
+triceratops
+thunder snake
+ringneck snake
+hognose snake
+green snake
+king snake
+garter snake
+water snake
+vine snake
+night snake
+boa constrictor
+rock python
+Indian cobra
+green mamba
+sea snake
+horned viper
+diamondback
+sidewinder
+trilobite
+harvestman
+scorpion
+black and gold garden spider
+barn spider
+garden spider
+black widow
+tarantula
+wolf spider
+tick
+centipede
+black grouse
+ptarmigan
+ruffed grouse
+prairie chicken
+peacock
+quail
+partridge
+African grey
+macaw
+sulphur-crested cockatoo
+lorikeet
+coucal
+bee eater
+hornbill
+hummingbird
+jacamar
+toucan
+drake
+red-breasted merganser
+goose
+black swan
+tusker
+echidna
+platypus
+wallaby
+koala
+wombat
+jellyfish
+sea anemone
+brain coral
+flatworm
+nematode
+conch
+snail
+slug
+sea slug
+chiton
+chambered nautilus
+Dungeness crab
+rock crab
+fiddler crab
+king crab
+American lobster
+spiny lobster
+crayfish
+hermit crab
+isopod
+white stork
+black stork
+spoonbill
+flamingo
+little blue heron
+American egret
+bittern
+crane
+limpkin
+European gallinule
+American coot
+bustard
+ruddy turnstone
+red-backed sandpiper
+redshank
+dowitcher
+oystercatcher
+pelican
+king penguin
+albatross
+grey whale
+killer whale
+dugong
+sea lion
+Chihuahua
+Japanese spaniel
+Maltese dog
+Pekinese
+Shih-Tzu
+Blenheim spaniel
+papillon
+toy terrier
+Rhodesian ridgeback
+Afghan hound
+basset
+beagle
+bloodhound
+bluetick
+black-and-tan coonhound
+Walker hound
+English foxhound
+redbone
+borzoi
+Irish wolfhound
+Italian greyhound
+whippet
+Ibizan hound
+Norwegian elkhound
+otterhound
+Saluki
+Scottish deerhound
+Weimaraner
+Staffordshire bullterrier
+American Staffordshire terrier
+Bedlington terrier
+Border terrier
+Kerry blue terrier
+Irish terrier
+Norfolk terrier
+Norwich terrier
+Yorkshire terrier
+wire-haired fox terrier
+Lakeland terrier
+Sealyham terrier
+Airedale
+cairn
+Australian terrier
+Dandie Dinmont
+Boston bull
+miniature schnauzer
+giant schnauzer
+standard schnauzer
+Scotch terrier
+Tibetan terrier
+silky terrier
+soft-coated wheaten terrier
+West Highland white terrier
+Lhasa
+flat-coated retriever
+curly-coated retriever
+golden retriever
+Labrador retriever
+Chesapeake Bay retriever
+German short-haired pointer
+vizsla
+English setter
+Irish setter
+Gordon setter
+Brittany spaniel
+clumber
+English springer
+Welsh springer spaniel
+cocker spaniel
+Sussex spaniel
+Irish water spaniel
+kuvasz
+schipperke
+groenendael
+malinois
+briard
+kelpie
+komondor
+Old English sheepdog
+Shetland sheepdog
+collie
+Border collie
+Bouvier des Flandres
+Rottweiler
+German shepherd
+Doberman
+miniature pinscher
+Greater Swiss Mountain dog
+Bernese mountain dog
+Appenzeller
+EntleBucher
+boxer
+bull mastiff
+Tibetan mastiff
+French bulldog
+Great Dane
+Saint Bernard
+Eskimo dog
+malamute
+Siberian husky
+dalmatian
+affenpinscher
+basenji
+pug
+Leonberg
+Newfoundland
+Great Pyrenees
+Samoyed
+Pomeranian
+chow
+keeshond
+Brabancon griffon
+Pembroke
+Cardigan
+toy poodle
+miniature poodle
+standard poodle
+Mexican hairless
+timber wolf
+white wolf
+red wolf
+coyote
+dingo
+dhole
+African hunting dog
+hyena
+red fox
+kit fox
+Arctic fox
+grey fox
+tabby
+tiger cat
+Persian cat
+Siamese cat
+Egyptian cat
+cougar
+lynx
+leopard
+snow leopard
+jaguar
+lion
+tiger
+cheetah
+brown bear
+American black bear
+ice bear
+sloth bear
+mongoose
+meerkat
+tiger beetle
+ladybug
+ground beetle
+long-horned beetle
+leaf beetle
+dung beetle
+rhinoceros beetle
+weevil
+fly
+bee
+ant
+grasshopper
+cricket
+walking stick
+cockroach
+mantis
+cicada
+leafhopper
+lacewing
+dragonfly
+damselfly
+admiral
+ringlet
+monarch
+cabbage butterfly
+sulphur butterfly
+lycaenid
+starfish
+sea urchin
+sea cucumber
+wood rabbit
+hare
+Angora
+hamster
+porcupine
+fox squirrel
+marmot
+beaver
+guinea pig
+sorrel
+zebra
+hog
+wild boar
+warthog
+hippopotamus
+ox
+water buffalo
+bison
+ram
+bighorn
+ibex
+hartebeest
+impala
+gazelle
+Arabian camel
+llama
+weasel
+mink
+polecat
+black-footed ferret
+otter
+skunk
+badger
+armadillo
+three-toed sloth
+orangutan
+gorilla
+chimpanzee
+gibbon
+siamang
+guenon
+patas
+baboon
+macaque
+langur
+colobus
+proboscis monkey
+marmoset
+capuchin
+howler monkey
+titi
+spider monkey
+squirrel monkey
+Madagascar cat
+indri
+Indian elephant
+African elephant
+lesser panda
+giant panda
+barracouta
+eel
+coho
+rock beauty
+anemone fish
+sturgeon
+gar
+lionfish
+puffer
+abacus
+abaya
+academic gown
+accordion
+acoustic guitar
+aircraft carrier
+airliner
+airship
+altar
+ambulance
+amphibian
+analog clock
+apiary
+apron
+ashcan
+assault rifle
+backpack
+bakery
+balance beam
+balloon
+ballpoint
+Band Aid
+banjo
+bannister
+barbell
+barber chair
+barbershop
+barn
+barometer
+barrel
+barrow
+baseball
+basketball
+bassinet
+bassoon
+bathing cap
+bath towel
+bathtub
+beach wagon
+beacon
+beaker
+bearskin
+beer bottle
+beer glass
+bell cote
+bib
+bicycle-built-for-two
+bikini
+binder
+binoculars
+birdhouse
+boathouse
+bobsled
+bolo tie
+bonnet
+bookcase
+bookshop
+bottlecap
+bow
+bow tie
+brass
+brassiere
+breakwater
+breastplate
+broom
+bucket
+buckle
+bulletproof vest
+bullet train
+butcher shop
+cab
+caldron
+candle
+cannon
+canoe
+can opener
+cardigan
+car mirror
+carousel
+carpenter's kit
+carton
+car wheel
+cash machine
+cassette
+cassette player
+castle
+catamaran
+CD player
+cello
+cellular telephone
+chain
+chainlink fence
+chain mail
+chain saw
+chest
+chiffonier
+chime
+china cabinet
+Christmas stocking
+church
+cinema
+cleaver
+cliff dwelling
+cloak
+clog
+cocktail shaker
+coffee mug
+coffeepot
+coil
+combination lock
+computer keyboard
+confectionery
+container ship
+convertible
+corkscrew
+cornet
+cowboy boot
+cowboy hat
+cradle
+crane
+crash helmet
+crate
+crib
+Crock Pot
+croquet ball
+crutch
+cuirass
+dam
+desk
+desktop computer
+dial telephone
+diaper
+digital clock
+digital watch
+dining table
+dishrag
+dishwasher
+disk brake
+dock
+dogsled
+dome
+doormat
+drilling platform
+drum
+drumstick
+dumbbell
+Dutch oven
+electric fan
+electric guitar
+electric locomotive
+entertainment center
+envelope
+espresso maker
+face powder
+feather boa
+file
+fireboat
+fire engine
+fire screen
+flagpole
+flute
+folding chair
+football helmet
+forklift
+fountain
+fountain pen
+four-poster
+freight car
+French horn
+frying pan
+fur coat
+garbage truck
+gasmask
+gas pump
+goblet
+go-kart
+golf ball
+golfcart
+gondola
+gong
+gown
+grand piano
+greenhouse
+grille
+grocery store
+guillotine
+hair slide
+hair spray
+half track
+hammer
+hamper
+hand blower
+hand-held computer
+handkerchief
+hard disc
+harmonica
+harp
+harvester
+hatchet
+holster
+home theater
+honeycomb
+hook
+hoopskirt
+horizontal bar
+horse cart
+hourglass
+iPod
+iron
+jack-o'-lantern
+jean
+jeep
+jersey
+jigsaw puzzle
+jinrikisha
+joystick
+kimono
+knee pad
+knot
+lab coat
+ladle
+lampshade
+laptop
+lawn mower
+lens cap
+letter opener
+library
+lifeboat
+lighter
+limousine
+liner
+lipstick
+Loafer
+lotion
+loudspeaker
+loupe
+lumbermill
+magnetic compass
+mailbag
+mailbox
+maillot
+maillot
+manhole cover
+maraca
+marimba
+mask
+matchstick
+maypole
+maze
+measuring cup
+medicine chest
+megalith
+microphone
+microwave
+military uniform
+milk can
+minibus
+miniskirt
+minivan
+missile
+mitten
+mixing bowl
+mobile home
+Model T
+modem
+monastery
+monitor
+moped
+mortar
+mortarboard
+mosque
+mosquito net
+motor scooter
+mountain bike
+mountain tent
+mouse
+mousetrap
+moving van
+muzzle
+nail
+neck brace
+necklace
+nipple
+notebook
+obelisk
+oboe
+ocarina
+odometer
+oil filter
+organ
+oscilloscope
+overskirt
+oxcart
+oxygen mask
+packet
+paddle
+paddlewheel
+padlock
+paintbrush
+pajama
+palace
+panpipe
+paper towel
+parachute
+parallel bars
+park bench
+parking meter
+passenger car
+patio
+pay-phone
+pedestal
+pencil box
+pencil sharpener
+perfume
+Petri dish
+photocopier
+pick
+pickelhaube
+picket fence
+pickup
+pier
+piggy bank
+pill bottle
+pillow
+ping-pong ball
+pinwheel
+pirate
+pitcher
+plane
+planetarium
+plastic bag
+plate rack
+plow
+plunger
+Polaroid camera
+pole
+police van
+poncho
+pool table
+pop bottle
+pot
+potter's wheel
+power drill
+prayer rug
+printer
+prison
+projectile
+projector
+puck
+punching bag
+purse
+quill
+quilt
+racer
+racket
+radiator
+radio
+radio telescope
+rain barrel
+recreational vehicle
+reel
+reflex camera
+refrigerator
+remote control
+restaurant
+revolver
+rifle
+rocking chair
+rotisserie
+rubber eraser
+rugby ball
+rule
+running shoe
+safe
+safety pin
+saltshaker
+sandal
+sarong
+sax
+scabbard
+scale
+school bus
+schooner
+scoreboard
+screen
+screw
+screwdriver
+seat belt
+sewing machine
+shield
+shoe shop
+shoji
+shopping basket
+shopping cart
+shovel
+shower cap
+shower curtain
+ski
+ski mask
+sleeping bag
+slide rule
+sliding door
+slot
+snorkel
+snowmobile
+snowplow
+soap dispenser
+soccer ball
+sock
+solar dish
+sombrero
+soup bowl
+space bar
+space heater
+space shuttle
+spatula
+speedboat
+spider web
+spindle
+sports car
+spotlight
+stage
+steam locomotive
+steel arch bridge
+steel drum
+stethoscope
+stole
+stone wall
+stopwatch
+stove
+strainer
+streetcar
+stretcher
+studio couch
+stupa
+submarine
+suit
+sundial
+sunglass
+sunglasses
+sunscreen
+suspension bridge
+swab
+sweatshirt
+swimming trunks
+swing
+switch
+syringe
+table lamp
+tank
+tape player
+teapot
+teddy
+television
+tennis ball
+thatch
+theater curtain
+thimble
+thresher
+throne
+tile roof
+toaster
+tobacco shop
+toilet seat
+torch
+totem pole
+tow truck
+toyshop
+tractor
+trailer truck
+tray
+trench coat
+tricycle
+trimaran
+tripod
+triumphal arch
+trolleybus
+trombone
+tub
+turnstile
+typewriter keyboard
+umbrella
+unicycle
+upright
+vacuum
+vase
+vault
+velvet
+vending machine
+vestment
+viaduct
+violin
+volleyball
+waffle iron
+wall clock
+wallet
+wardrobe
+warplane
+washbasin
+washer
+water bottle
+water jug
+water tower
+whiskey jug
+whistle
+wig
+window screen
+window shade
+Windsor tie
+wine bottle
+wing
+wok
+wooden spoon
+wool
+worm fence
+wreck
+yawl
+yurt
+web site
+comic book
+crossword puzzle
+street sign
+traffic light
+book jacket
+menu
+plate
+guacamole
+consomme
+hot pot
+trifle
+ice cream
+ice lolly
+French loaf
+bagel
+pretzel
+cheeseburger
+hotdog
+mashed potato
+head cabbage
+broccoli
+cauliflower
+zucchini
+spaghetti squash
+acorn squash
+butternut squash
+cucumber
+artichoke
+bell pepper
+cardoon
+mushroom
+Granny Smith
+strawberry
+orange
+lemon
+fig
+pineapple
+banana
+jackfruit
+custard apple
+pomegranate
+hay
+carbonara
+chocolate sauce
+dough
+meat loaf
+pizza
+potpie
+burrito
+red wine
+espresso
+cup
+eggnog
+alp
+bubble
+cliff
+coral reef
+geyser
+lakeside
+promontory
+sandbar
+seashore
+valley
+volcano
+ballplayer
+groom
+scuba diver
+rapeseed
+daisy
+yellow lady's slipper
+corn
+acorn
+hip
+buckeye
+coral fungus
+agaric
+gyromitra
+stinkhorn
+earthstar
+hen-of-the-woods
+bolete
+ear
+toilet tissue
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/BitmapUtils.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/BitmapUtils.java
index 24ddb34..3c7381f 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/BitmapUtils.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/BitmapUtils.java
@@ -1,406 +1,406 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.annotation.TargetApi;
-import android.content.ContentResolver;
-import android.content.Context;
-import android.graphics.Bitmap;
-import android.graphics.BitmapFactory;
-import android.graphics.ImageFormat;
-import android.graphics.Matrix;
-import android.graphics.Rect;
-import android.graphics.YuvImage;
-import android.media.Image;
-import android.media.Image.Plane;
-import android.net.Uri;
-import android.os.Build.VERSION_CODES;
-import android.provider.MediaStore;
-import android.util.Log;
-
-import androidx.annotation.Nullable;
-import androidx.annotation.RequiresApi;
-import androidx.camera.core.ImageProxy;
-import androidx.exifinterface.media.ExifInterface;
-
-import java.io.ByteArrayOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.nio.ByteBuffer;
-
-/**
- * Utils functions for bitmap conversions.
- */
-public class BitmapUtils {
-    private static final String TAG = "BitmapUtils";
-
-    /**
-     * Converts NV21 format byte buffer to bitmap.
-     */
-    @Nullable
-    public static Bitmap getBitmap(ByteBuffer data, FrameMetadata metadata) {
-        data.rewind();
-        byte[] imageInBuffer = new byte[data.limit()];
-        data.get(imageInBuffer, 0, imageInBuffer.length);
-        try {
-            YuvImage image =
-                    new YuvImage(
-                            imageInBuffer, ImageFormat.NV21, metadata.getWidth(), metadata.getHeight(), null);
-            ByteArrayOutputStream stream = new ByteArrayOutputStream();
-            image.compressToJpeg(new Rect(0, 0, metadata.getWidth(), metadata.getHeight()), 80, stream);
-
-            Bitmap bmp = BitmapFactory.decodeByteArray(stream.toByteArray(), 0, stream.size());
-
-            stream.close();
-            return rotateBitmap(bmp, metadata.getRotation(), false, false);
-        } catch (Exception e) {
-            Log.e("VisionProcessorBase", "Error: " + e.getMessage());
-        }
-        return null;
-    }
-
-    /**
-     * Converts a YUV_420_888 image from CameraX API to a bitmap.
-     */
-    @RequiresApi(VERSION_CODES.KITKAT)
-    @Nullable
-    public static Bitmap getBitmap(ImageProxy image) {
-        FrameMetadata frameMetadata = new FrameMetadata.Builder()
-                .setWidth(image.getWidth())
-                .setHeight(image.getHeight())
-                .setRotation(image.getImageInfo().getRotationDegrees())
-                .build();
-
-        ByteBuffer nv21Buffer = yuv420ThreePlanesToNV21(
-                image.getImage().getPlanes(), image.getWidth(), image.getHeight());
-        return getBitmap(nv21Buffer, frameMetadata);
-    }
-
-    /**
-     * Rotates a bitmap if it is converted from a bytebuffer.
-     */
-    private static Bitmap rotateBitmap(
-            Bitmap bitmap, int rotationDegrees, boolean flipX, boolean flipY) {
-        Matrix matrix = new Matrix();
-
-        // Rotate the image back to straight.
-        matrix.postRotate(rotationDegrees);
-
-        // Mirror the image along the X or Y axis.
-        matrix.postScale(flipX ? -1.0f : 1.0f, flipY ? -1.0f : 1.0f);
-        Bitmap rotatedBitmap =
-                Bitmap.createBitmap(bitmap, 0, 0, bitmap.getWidth(), bitmap.getHeight(), matrix, true);
-
-        // Recycle the old bitmap if it has changed.
-        if (rotatedBitmap != bitmap) {
-            bitmap.recycle();
-        }
-        return rotatedBitmap;
-    }
-
-    @Nullable
-    public static Bitmap getBitmapFromAsset(Context context, String fileName) {
-        InputStream inputStream = null;
-        try {
-            inputStream = context.getAssets().open(fileName);
-            return BitmapFactory.decodeStream(inputStream);
-        } catch (IOException e) {
-            Log.e(TAG, "Error reading asset: " + fileName, e);
-        } finally {
-            if (inputStream != null) {
-                try {
-                    inputStream.close();
-                } catch (IOException e) {
-                    Log.e(TAG, "Failed to close input stream: ", e);
-                }
-            }
-        }
-
-        return null;
-    }
-
-    @Nullable
-    public static Bitmap getBitmapFromContentUri(ContentResolver contentResolver, Uri imageUri)
-            throws IOException {
-        Bitmap decodedBitmap = MediaStore.Images.Media.getBitmap(contentResolver, imageUri);
-        if (decodedBitmap==null) {
-            return null;
-        }
-        int orientation = getExifOrientationTag(contentResolver, imageUri);
-
-        int rotationDegrees = 0;
-        boolean flipX = false;
-        boolean flipY = false;
-        // See e.g. https://magnushoff.com/articles/jpeg-orientation/ for a detailed explanation on each
-        // orientation.
-        switch (orientation) {
-            case ExifInterface.ORIENTATION_FLIP_HORIZONTAL:
-                flipX = true;
-                break;
-            case ExifInterface.ORIENTATION_ROTATE_90:
-                rotationDegrees = 90;
-                break;
-            case ExifInterface.ORIENTATION_TRANSPOSE:
-                rotationDegrees = 90;
-                flipX = true;
-                break;
-            case ExifInterface.ORIENTATION_ROTATE_180:
-                rotationDegrees = 180;
-                break;
-            case ExifInterface.ORIENTATION_FLIP_VERTICAL:
-                flipY = true;
-                break;
-            case ExifInterface.ORIENTATION_ROTATE_270:
-                rotationDegrees = -90;
-                break;
-            case ExifInterface.ORIENTATION_TRANSVERSE:
-                rotationDegrees = -90;
-                flipX = true;
-                break;
-            case ExifInterface.ORIENTATION_UNDEFINED:
-            case ExifInterface.ORIENTATION_NORMAL:
-            default:
-                // No transformations necessary in this case.
-        }
-
-        return rotateBitmap(decodedBitmap, rotationDegrees, flipX, flipY);
-    }
-
-    private static int getExifOrientationTag(ContentResolver resolver, Uri imageUri) {
-        // We only support parsing EXIF orientation tag from local file on the device.
-        // See also:
-        // https://android-developers.googleblog.com/2016/12/introducing-the-exifinterface-support-library.html
-        if (!ContentResolver.SCHEME_CONTENT.equals(imageUri.getScheme())
-                && !ContentResolver.SCHEME_FILE.equals(imageUri.getScheme())) {
-            return 0;
-        }
-
-        ExifInterface exif;
-        try (InputStream inputStream = resolver.openInputStream(imageUri)) {
-            if (inputStream == null) {
-                return 0;
-            }
-
-            exif = new ExifInterface(inputStream);
-        } catch (IOException e) {
-            Log.e(TAG, "failed to open file to read rotation meta data: " + imageUri, e);
-            return 0;
-        }
-
-        return exif.getAttributeInt(ExifInterface.TAG_ORIENTATION, ExifInterface.ORIENTATION_NORMAL);
-    }
-
-    public static ByteBuffer convertBitmapToNv21Buffer(Bitmap bitmap) {
-        return ByteBuffer.wrap(convertBitmapToNv21Bytes(bitmap));
-    }
-
-    public static byte[] convertBitmapToNv21Bytes(Bitmap bitmap) {
-        int inputWidth = bitmap.getWidth();
-        int inputHeight = bitmap.getHeight();
-        int[] argb = new int[inputWidth * inputHeight];
-
-        bitmap.getPixels(argb, 0, inputWidth, 0, 0, inputWidth, inputHeight);
-
-        byte[] nv21Bytes =
-                new byte
-                        [inputHeight * inputWidth
-                        + 2 * (int) Math.ceil(inputHeight / 2.0) * (int) Math.ceil(inputWidth / 2.0)];
-        encodeToNv21(nv21Bytes, argb, inputWidth, inputHeight);
-        return nv21Bytes;
-    }
-
-    private static void encodeToNv21(byte[] nv21Bytes, int[] argb, int width, int height) {
-        int frameSize = width * height;
-
-        int yIndex = 0;
-        int uvIndex = frameSize;
-
-        int red;
-        int green;
-        int blue;
-        int y;
-        int u;
-        int v;
-        int index = 0;
-        for (int j = 0; j < height; j++) {
-            for (int i = 0; i < width; i++) {
-
-                // first byte is alpha, but is unused
-                red = (argb[index] & 0xff0000) >> 16;
-                green = (argb[index] & 0xff00) >> 8;
-                blue = (argb[index] & 0xff) >> 0;
-
-                // well known RGB to YUV algorithm
-                y = ((66 * red + 129 * green + 25 * blue + 128) >> 8) + 16;
-                u = ((-38 * red - 74 * green + 112 * blue + 128) >> 8) + 128;
-                v = ((112 * red - 94 * green - 18 * blue + 128) >> 8) + 128;
-
-                // NV21 has a plane of Y and interleaved planes of VU each sampled by a factor of 2
-                // meaning for every 4 Y pixels there are 1 V and 1 U.  Note the sampling is every other
-                // pixel AND every other scanline.
-                nv21Bytes[yIndex++] = (byte) ((y < 0) ? 0 : ((y > 255) ? 255 : y));
-                if (j % 2 == 0 && index % 2 == 0) {
-                    nv21Bytes[uvIndex++] = (byte) ((v < 0) ? 0 : ((v > 255) ? 255 : v));
-                    nv21Bytes[uvIndex++] = (byte) ((u < 0) ? 0 : ((u > 255) ? 255 : u));
-                }
-
-                index++;
-            }
-        }
-    }
-
-    public static ByteBuffer convertBitmapToYv12Buffer(Bitmap bitmap) {
-        return ByteBuffer.wrap(convertBitmapToYv12Bytes(bitmap));
-    }
-
-    public static byte[] convertBitmapToYv12Bytes(Bitmap bitmap) {
-        byte[] nv21Bytes = convertBitmapToNv21Bytes(bitmap);
-        return nv21Toyv12(nv21Bytes);
-    }
-
-    /**
-     * Converts nv21 byte[] to yv12 byte[].
-     *
-     * <p>NV21 (4:2:0) Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y V U V U V U V U V U V U
-     *
-     * <p>YV12 (4:2:0) Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y V V V V V V U U U U U U
-     */
-    private static byte[] nv21Toyv12(byte[] nv21Bytes) {
-        int totalBytes = nv21Bytes.length;
-        int rowSize = totalBytes / 6; // 4+2+0
-        byte[] yv12Bytes = new byte[totalBytes];
-        System.arraycopy(nv21Bytes, 0, yv12Bytes, 0, rowSize * 4);
-        int offSet = totalBytes / 6 * 4;
-        for (int i = 0; i < rowSize; i++) {
-            yv12Bytes[offSet + i] = nv21Bytes[offSet + 2 * i]; // V
-            yv12Bytes[offSet + rowSize + i] = nv21Bytes[offSet + 2 * i + 1]; // U
-        }
-
-        return yv12Bytes;
-    }
-
-    /**
-     * Converts YUV_420_888 to NV21 bytebuffer.
-     *
-     * <p>The NV21 format consists of a single byte array containing the Y, U and V values. For an
-     * image of size S, the first S positions of the array contain all the Y values. The remaining
-     * positions contain interleaved V and U values. U and V are subsampled by a factor of 2 in both
-     * dimensions, so there are S/4 U values and S/4 V values. In summary, the NV21 array will contain
-     * S Y values followed by S/4 VU values: YYYYYYYYYYYYYY(...)YVUVUVUVU(...)VU
-     *
-     * <p>YUV_420_888 is a generic format that can describe any YUV image where U and V are subsampled
-     * by a factor of 2 in both dimensions. {@link Image#getPlanes} returns an array with the Y, U and
-     * V planes. The Y plane is guaranteed not to be interleaved, so we can just copy its values into
-     * the first part of the NV21 array. The U and V planes may already have the representation in the
-     * NV21 format. This happens if the planes share the same buffer, the V buffer is one position
-     * before the U buffer and the planes have a pixelStride of 2. If this is case, we can just copy
-     * them to the NV21 array.
-     */
-    @RequiresApi(VERSION_CODES.KITKAT)
-    private static ByteBuffer yuv420ThreePlanesToNV21(
-            Plane[] yuv420888planes, int width, int height) {
-        int imageSize = width * height;
-        byte[] out = new byte[imageSize + 2 * (imageSize / 4)];
-
-        if (areUVPlanesNV21(yuv420888planes, width, height)) {
-            // Copy the Y values.
-            yuv420888planes[0].getBuffer().get(out, 0, imageSize);
-
-            ByteBuffer uBuffer = yuv420888planes[1].getBuffer();
-            ByteBuffer vBuffer = yuv420888planes[2].getBuffer();
-            // Get the first V value from the V buffer, since the U buffer does not contain it.
-            vBuffer.get(out, imageSize, 1);
-            // Copy the first U value and the remaining VU values from the U buffer.
-            uBuffer.get(out, imageSize + 1, 2 * imageSize / 4 - 1);
-        } else {
-            // Fallback to copying the UV values one by one, which is slower but also works.
-            // Unpack Y.
-            unpackPlane(yuv420888planes[0], width, height, out, 0, 1);
-            // Unpack U.
-            unpackPlane(yuv420888planes[1], width, height, out, imageSize + 1, 2);
-            // Unpack V.
-            unpackPlane(yuv420888planes[2], width, height, out, imageSize, 2);
-        }
-
-        return ByteBuffer.wrap(out);
-    }
-
-    /**
-     * Checks if the UV plane buffers of a YUV_420_888 image are in the NV21 format.
-     */
-    @RequiresApi(VERSION_CODES.KITKAT)
-    private static boolean areUVPlanesNV21(Plane[] planes, int width, int height) {
-        int imageSize = width * height;
-
-        ByteBuffer uBuffer = planes[1].getBuffer();
-        ByteBuffer vBuffer = planes[2].getBuffer();
-
-        // Backup buffer properties.
-        int vBufferPosition = vBuffer.position();
-        int uBufferLimit = uBuffer.limit();
-
-        // Advance the V buffer by 1 byte, since the U buffer will not contain the first V value.
-        vBuffer.position(vBufferPosition + 1);
-        // Chop off the last byte of the U buffer, since the V buffer will not contain the last U value.
-        uBuffer.limit(uBufferLimit - 1);
-
-        // Check that the buffers are equal and have the expected number of elements.
-        boolean areNV21 =
-                (vBuffer.remaining() == (2 * imageSize / 4 - 2)) && (vBuffer.compareTo(uBuffer) == 0);
-
-        // Restore buffers to their initial state.
-        vBuffer.position(vBufferPosition);
-        uBuffer.limit(uBufferLimit);
-
-        return areNV21;
-    }
-
-    /**
-     * Unpack an image plane into a byte array.
-     *
-     * <p>The input plane data will be copied in 'out', starting at 'offset' and every pixel will be
-     * spaced by 'pixelStride'. Note that there is no row padding on the output.
-     */
-    @TargetApi(VERSION_CODES.KITKAT)
-    private static void unpackPlane(
-            Plane plane, int width, int height, byte[] out, int offset, int pixelStride) {
-        ByteBuffer buffer = plane.getBuffer();
-        buffer.rewind();
-
-        // Compute the size of the current plane.
-        // We assume that it has the aspect ratio as the original image.
-        int numRow = (buffer.limit() + plane.getRowStride() - 1) / plane.getRowStride();
-        if (numRow == 0) {
-            return;
-        }
-        int scaleFactor = height / numRow;
-        int numCol = width / scaleFactor;
-
-        // Extract the data in the output buffer.
-        int outputPos = offset;
-        int rowStart = 0;
-        for (int row = 0; row < numRow; row++) {
-            int inputPos = rowStart;
-            for (int col = 0; col < numCol; col++) {
-                out[outputPos] = buffer.get(inputPos);
-                outputPos += pixelStride;
-                inputPos += plane.getPixelStride();
-            }
-            rowStart += plane.getRowStride();
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.annotation.TargetApi;
+import android.content.ContentResolver;
+import android.content.Context;
+import android.graphics.Bitmap;
+import android.graphics.BitmapFactory;
+import android.graphics.ImageFormat;
+import android.graphics.Matrix;
+import android.graphics.Rect;
+import android.graphics.YuvImage;
+import android.media.Image;
+import android.media.Image.Plane;
+import android.net.Uri;
+import android.os.Build.VERSION_CODES;
+import android.provider.MediaStore;
+import android.util.Log;
+
+import androidx.annotation.Nullable;
+import androidx.annotation.RequiresApi;
+import androidx.camera.core.ImageProxy;
+import androidx.exifinterface.media.ExifInterface;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.ByteBuffer;
+
+/**
+ * Utils functions for bitmap conversions.
+ */
+public class BitmapUtils {
+    private static final String TAG = "BitmapUtils";
+
+    /**
+     * Converts NV21 format byte buffer to bitmap.
+     */
+    @Nullable
+    public static Bitmap getBitmap(ByteBuffer data, FrameMetadata metadata) {
+        data.rewind();
+        byte[] imageInBuffer = new byte[data.limit()];
+        data.get(imageInBuffer, 0, imageInBuffer.length);
+        try {
+            YuvImage image =
+                    new YuvImage(
+                            imageInBuffer, ImageFormat.NV21, metadata.getWidth(), metadata.getHeight(), null);
+            ByteArrayOutputStream stream = new ByteArrayOutputStream();
+            image.compressToJpeg(new Rect(0, 0, metadata.getWidth(), metadata.getHeight()), 80, stream);
+
+            Bitmap bmp = BitmapFactory.decodeByteArray(stream.toByteArray(), 0, stream.size());
+
+            stream.close();
+            return rotateBitmap(bmp, metadata.getRotation(), false, false);
+        } catch (Exception e) {
+            Log.e("VisionProcessorBase", "Error: " + e.getMessage());
+        }
+        return null;
+    }
+
+    /**
+     * Converts a YUV_420_888 image from CameraX API to a bitmap.
+     */
+    @RequiresApi(VERSION_CODES.KITKAT)
+    @Nullable
+    public static Bitmap getBitmap(ImageProxy image) {
+        FrameMetadata frameMetadata = new FrameMetadata.Builder()
+                .setWidth(image.getWidth())
+                .setHeight(image.getHeight())
+                .setRotation(image.getImageInfo().getRotationDegrees())
+                .build();
+
+        ByteBuffer nv21Buffer = yuv420ThreePlanesToNV21(
+                image.getImage().getPlanes(), image.getWidth(), image.getHeight());
+        return getBitmap(nv21Buffer, frameMetadata);
+    }
+
+    /**
+     * Rotates a bitmap if it is converted from a bytebuffer.
+     */
+    private static Bitmap rotateBitmap(
+            Bitmap bitmap, int rotationDegrees, boolean flipX, boolean flipY) {
+        Matrix matrix = new Matrix();
+
+        // Rotate the image back to straight.
+        matrix.postRotate(rotationDegrees);
+
+        // Mirror the image along the X or Y axis.
+        matrix.postScale(flipX ? -1.0f : 1.0f, flipY ? -1.0f : 1.0f);
+        Bitmap rotatedBitmap =
+                Bitmap.createBitmap(bitmap, 0, 0, bitmap.getWidth(), bitmap.getHeight(), matrix, true);
+
+        // Recycle the old bitmap if it has changed.
+        if (rotatedBitmap != bitmap) {
+            bitmap.recycle();
+        }
+        return rotatedBitmap;
+    }
+
+    @Nullable
+    public static Bitmap getBitmapFromAsset(Context context, String fileName) {
+        InputStream inputStream = null;
+        try {
+            inputStream = context.getAssets().open(fileName);
+            return BitmapFactory.decodeStream(inputStream);
+        } catch (IOException e) {
+            Log.e(TAG, "Error reading asset: " + fileName, e);
+        } finally {
+            if (inputStream != null) {
+                try {
+                    inputStream.close();
+                } catch (IOException e) {
+                    Log.e(TAG, "Failed to close input stream: ", e);
+                }
+            }
+        }
+
+        return null;
+    }
+
+    @Nullable
+    public static Bitmap getBitmapFromContentUri(ContentResolver contentResolver, Uri imageUri)
+            throws IOException {
+        Bitmap decodedBitmap = MediaStore.Images.Media.getBitmap(contentResolver, imageUri);
+        if (decodedBitmap==null) {
+            return null;
+        }
+        int orientation = getExifOrientationTag(contentResolver, imageUri);
+
+        int rotationDegrees = 0;
+        boolean flipX = false;
+        boolean flipY = false;
+        // See e.g. https://magnushoff.com/articles/jpeg-orientation/ for a detailed explanation on each
+        // orientation.
+        switch (orientation) {
+            case ExifInterface.ORIENTATION_FLIP_HORIZONTAL:
+                flipX = true;
+                break;
+            case ExifInterface.ORIENTATION_ROTATE_90:
+                rotationDegrees = 90;
+                break;
+            case ExifInterface.ORIENTATION_TRANSPOSE:
+                rotationDegrees = 90;
+                flipX = true;
+                break;
+            case ExifInterface.ORIENTATION_ROTATE_180:
+                rotationDegrees = 180;
+                break;
+            case ExifInterface.ORIENTATION_FLIP_VERTICAL:
+                flipY = true;
+                break;
+            case ExifInterface.ORIENTATION_ROTATE_270:
+                rotationDegrees = -90;
+                break;
+            case ExifInterface.ORIENTATION_TRANSVERSE:
+                rotationDegrees = -90;
+                flipX = true;
+                break;
+            case ExifInterface.ORIENTATION_UNDEFINED:
+            case ExifInterface.ORIENTATION_NORMAL:
+            default:
+                // No transformations necessary in this case.
+        }
+
+        return rotateBitmap(decodedBitmap, rotationDegrees, flipX, flipY);
+    }
+
+    private static int getExifOrientationTag(ContentResolver resolver, Uri imageUri) {
+        // We only support parsing EXIF orientation tag from local file on the device.
+        // See also:
+        // https://android-developers.googleblog.com/2016/12/introducing-the-exifinterface-support-library.html
+        if (!ContentResolver.SCHEME_CONTENT.equals(imageUri.getScheme())
+                && !ContentResolver.SCHEME_FILE.equals(imageUri.getScheme())) {
+            return 0;
+        }
+
+        ExifInterface exif;
+        try (InputStream inputStream = resolver.openInputStream(imageUri)) {
+            if (inputStream == null) {
+                return 0;
+            }
+
+            exif = new ExifInterface(inputStream);
+        } catch (IOException e) {
+            Log.e(TAG, "failed to open file to read rotation meta data: " + imageUri, e);
+            return 0;
+        }
+
+        return exif.getAttributeInt(ExifInterface.TAG_ORIENTATION, ExifInterface.ORIENTATION_NORMAL);
+    }
+
+    public static ByteBuffer convertBitmapToNv21Buffer(Bitmap bitmap) {
+        return ByteBuffer.wrap(convertBitmapToNv21Bytes(bitmap));
+    }
+
+    public static byte[] convertBitmapToNv21Bytes(Bitmap bitmap) {
+        int inputWidth = bitmap.getWidth();
+        int inputHeight = bitmap.getHeight();
+        int[] argb = new int[inputWidth * inputHeight];
+
+        bitmap.getPixels(argb, 0, inputWidth, 0, 0, inputWidth, inputHeight);
+
+        byte[] nv21Bytes =
+                new byte
+                        [inputHeight * inputWidth
+                        + 2 * (int) Math.ceil(inputHeight / 2.0) * (int) Math.ceil(inputWidth / 2.0)];
+        encodeToNv21(nv21Bytes, argb, inputWidth, inputHeight);
+        return nv21Bytes;
+    }
+
+    private static void encodeToNv21(byte[] nv21Bytes, int[] argb, int width, int height) {
+        int frameSize = width * height;
+
+        int yIndex = 0;
+        int uvIndex = frameSize;
+
+        int red;
+        int green;
+        int blue;
+        int y;
+        int u;
+        int v;
+        int index = 0;
+        for (int j = 0; j < height; j++) {
+            for (int i = 0; i < width; i++) {
+
+                // first byte is alpha, but is unused
+                red = (argb[index] & 0xff0000) >> 16;
+                green = (argb[index] & 0xff00) >> 8;
+                blue = (argb[index] & 0xff) >> 0;
+
+                // well known RGB to YUV algorithm
+                y = ((66 * red + 129 * green + 25 * blue + 128) >> 8) + 16;
+                u = ((-38 * red - 74 * green + 112 * blue + 128) >> 8) + 128;
+                v = ((112 * red - 94 * green - 18 * blue + 128) >> 8) + 128;
+
+                // NV21 has a plane of Y and interleaved planes of VU each sampled by a factor of 2
+                // meaning for every 4 Y pixels there are 1 V and 1 U.  Note the sampling is every other
+                // pixel AND every other scanline.
+                nv21Bytes[yIndex++] = (byte) ((y < 0) ? 0 : ((y > 255) ? 255 : y));
+                if (j % 2 == 0 && index % 2 == 0) {
+                    nv21Bytes[uvIndex++] = (byte) ((v < 0) ? 0 : ((v > 255) ? 255 : v));
+                    nv21Bytes[uvIndex++] = (byte) ((u < 0) ? 0 : ((u > 255) ? 255 : u));
+                }
+
+                index++;
+            }
+        }
+    }
+
+    public static ByteBuffer convertBitmapToYv12Buffer(Bitmap bitmap) {
+        return ByteBuffer.wrap(convertBitmapToYv12Bytes(bitmap));
+    }
+
+    public static byte[] convertBitmapToYv12Bytes(Bitmap bitmap) {
+        byte[] nv21Bytes = convertBitmapToNv21Bytes(bitmap);
+        return nv21Toyv12(nv21Bytes);
+    }
+
+    /**
+     * Converts nv21 byte[] to yv12 byte[].
+     *
+     * <p>NV21 (4:2:0) Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y V U V U V U V U V U V U
+     *
+     * <p>YV12 (4:2:0) Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y V V V V V V U U U U U U
+     */
+    private static byte[] nv21Toyv12(byte[] nv21Bytes) {
+        int totalBytes = nv21Bytes.length;
+        int rowSize = totalBytes / 6; // 4+2+0
+        byte[] yv12Bytes = new byte[totalBytes];
+        System.arraycopy(nv21Bytes, 0, yv12Bytes, 0, rowSize * 4);
+        int offSet = totalBytes / 6 * 4;
+        for (int i = 0; i < rowSize; i++) {
+            yv12Bytes[offSet + i] = nv21Bytes[offSet + 2 * i]; // V
+            yv12Bytes[offSet + rowSize + i] = nv21Bytes[offSet + 2 * i + 1]; // U
+        }
+
+        return yv12Bytes;
+    }
+
+    /**
+     * Converts YUV_420_888 to NV21 bytebuffer.
+     *
+     * <p>The NV21 format consists of a single byte array containing the Y, U and V values. For an
+     * image of size S, the first S positions of the array contain all the Y values. The remaining
+     * positions contain interleaved V and U values. U and V are subsampled by a factor of 2 in both
+     * dimensions, so there are S/4 U values and S/4 V values. In summary, the NV21 array will contain
+     * S Y values followed by S/4 VU values: YYYYYYYYYYYYYY(...)YVUVUVUVU(...)VU
+     *
+     * <p>YUV_420_888 is a generic format that can describe any YUV image where U and V are subsampled
+     * by a factor of 2 in both dimensions. {@link Image#getPlanes} returns an array with the Y, U and
+     * V planes. The Y plane is guaranteed not to be interleaved, so we can just copy its values into
+     * the first part of the NV21 array. The U and V planes may already have the representation in the
+     * NV21 format. This happens if the planes share the same buffer, the V buffer is one position
+     * before the U buffer and the planes have a pixelStride of 2. If this is case, we can just copy
+     * them to the NV21 array.
+     */
+    @RequiresApi(VERSION_CODES.KITKAT)
+    private static ByteBuffer yuv420ThreePlanesToNV21(
+            Plane[] yuv420888planes, int width, int height) {
+        int imageSize = width * height;
+        byte[] out = new byte[imageSize + 2 * (imageSize / 4)];
+
+        if (areUVPlanesNV21(yuv420888planes, width, height)) {
+            // Copy the Y values.
+            yuv420888planes[0].getBuffer().get(out, 0, imageSize);
+
+            ByteBuffer uBuffer = yuv420888planes[1].getBuffer();
+            ByteBuffer vBuffer = yuv420888planes[2].getBuffer();
+            // Get the first V value from the V buffer, since the U buffer does not contain it.
+            vBuffer.get(out, imageSize, 1);
+            // Copy the first U value and the remaining VU values from the U buffer.
+            uBuffer.get(out, imageSize + 1, 2 * imageSize / 4 - 1);
+        } else {
+            // Fallback to copying the UV values one by one, which is slower but also works.
+            // Unpack Y.
+            unpackPlane(yuv420888planes[0], width, height, out, 0, 1);
+            // Unpack U.
+            unpackPlane(yuv420888planes[1], width, height, out, imageSize + 1, 2);
+            // Unpack V.
+            unpackPlane(yuv420888planes[2], width, height, out, imageSize, 2);
+        }
+
+        return ByteBuffer.wrap(out);
+    }
+
+    /**
+     * Checks if the UV plane buffers of a YUV_420_888 image are in the NV21 format.
+     */
+    @RequiresApi(VERSION_CODES.KITKAT)
+    private static boolean areUVPlanesNV21(Plane[] planes, int width, int height) {
+        int imageSize = width * height;
+
+        ByteBuffer uBuffer = planes[1].getBuffer();
+        ByteBuffer vBuffer = planes[2].getBuffer();
+
+        // Backup buffer properties.
+        int vBufferPosition = vBuffer.position();
+        int uBufferLimit = uBuffer.limit();
+
+        // Advance the V buffer by 1 byte, since the U buffer will not contain the first V value.
+        vBuffer.position(vBufferPosition + 1);
+        // Chop off the last byte of the U buffer, since the V buffer will not contain the last U value.
+        uBuffer.limit(uBufferLimit - 1);
+
+        // Check that the buffers are equal and have the expected number of elements.
+        boolean areNV21 =
+                (vBuffer.remaining() == (2 * imageSize / 4 - 2)) && (vBuffer.compareTo(uBuffer) == 0);
+
+        // Restore buffers to their initial state.
+        vBuffer.position(vBufferPosition);
+        uBuffer.limit(uBufferLimit);
+
+        return areNV21;
+    }
+
+    /**
+     * Unpack an image plane into a byte array.
+     *
+     * <p>The input plane data will be copied in 'out', starting at 'offset' and every pixel will be
+     * spaced by 'pixelStride'. Note that there is no row padding on the output.
+     */
+    @TargetApi(VERSION_CODES.KITKAT)
+    private static void unpackPlane(
+            Plane plane, int width, int height, byte[] out, int offset, int pixelStride) {
+        ByteBuffer buffer = plane.getBuffer();
+        buffer.rewind();
+
+        // Compute the size of the current plane.
+        // We assume that it has the aspect ratio as the original image.
+        int numRow = (buffer.limit() + plane.getRowStride() - 1) / plane.getRowStride();
+        if (numRow == 0) {
+            return;
+        }
+        int scaleFactor = height / numRow;
+        int numCol = width / scaleFactor;
+
+        // Extract the data in the output buffer.
+        int outputPos = offset;
+        int rowStart = 0;
+        for (int row = 0; row < numRow; row++) {
+            int inputPos = rowStart;
+            for (int col = 0; col < numCol; col++) {
+                out[outputPos] = buffer.get(inputPos);
+                outputPos += pixelStride;
+                inputPos += plane.getPixelStride();
+            }
+            rowStart += plane.getRowStride();
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraImageGraphic.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraImageGraphic.java
index 22edfdf..4d215bf 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraImageGraphic.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraImageGraphic.java
@@ -1,40 +1,40 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.graphics.Bitmap;
-import android.graphics.Canvas;
-
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic;
-
-/**
- * Draw camera image to background.
- */
-public class CameraImageGraphic extends Graphic {
-
-    private final Bitmap bitmap;
-
-    public CameraImageGraphic(GraphicOverlay overlay, Bitmap bitmap) {
-        super(overlay);
-        this.bitmap = bitmap;
-    }
-
-    @Override
-    public void draw(Canvas canvas) {
-        canvas.drawBitmap(bitmap, getTransformationMatrix(), null);
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.graphics.Bitmap;
+import android.graphics.Canvas;
+
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic;
+
+/**
+ * Draw camera image to background.
+ */
+public class CameraImageGraphic extends Graphic {
+
+    private final Bitmap bitmap;
+
+    public CameraImageGraphic(GraphicOverlay overlay, Bitmap bitmap) {
+        super(overlay);
+        this.bitmap = bitmap;
+    }
+
+    @Override
+    public void draw(Canvas canvas) {
+        canvas.drawBitmap(bitmap, getTransformationMatrix(), null);
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraSource.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraSource.java
index 4456f2f..c49e203 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraSource.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraSource.java
@@ -1,753 +1,764 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.Manifest;
-import android.annotation.SuppressLint;
-import android.app.Activity;
-import android.content.Context;
-import android.graphics.ImageFormat;
-import android.graphics.SurfaceTexture;
-import android.hardware.Camera;
-import android.hardware.Camera.CameraInfo;
-import android.util.Log;
-import android.view.Surface;
-import android.view.SurfaceHolder;
-import android.view.WindowManager;
-
-import androidx.annotation.Nullable;
-import androidx.annotation.RequiresPermission;
-
-import com.google.android.gms.common.images.Size;
-import com.google.mlkit.vision.demo.preference.PreferenceUtils;
-
-import java.io.IOException;
-import java.lang.Thread.State;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.IdentityHashMap;
-import java.util.List;
-import java.util.Map;
-
-/**
- * Manages the camera and allows UI updates on top of it (e.g. overlaying extra Graphics or
- * displaying extra information). This receives preview frames from the camera at a specified rate,
- * sending those frames to child classes' detectors / classifiers as fast as it is able to process.
- */
-public class CameraSource {
-    @SuppressLint("InlinedApi")
-    public static final int CAMERA_FACING_BACK = CameraInfo.CAMERA_FACING_BACK;
-
-    @SuppressLint("InlinedApi")
-    public static final int CAMERA_FACING_FRONT = CameraInfo.CAMERA_FACING_FRONT;
-
-    public static final int IMAGE_FORMAT = ImageFormat.NV21;
-    public static final int DEFAULT_REQUESTED_CAMERA_PREVIEW_WIDTH = 480;
-    public static final int DEFAULT_REQUESTED_CAMERA_PREVIEW_HEIGHT = 360;
-
-    private static final String TAG = "MIDemoApp:CameraSource";
-
-    /**
-     * The dummy surface texture must be assigned a chosen name. Since we never use an OpenGL context,
-     * we can choose any ID we want here. The dummy surface texture is not a crazy hack - it is
-     * actually how the camera team recommends using the camera without a preview.
-     */
-    private static final int DUMMY_TEXTURE_NAME = 100;
-
-    /**
-     * If the absolute difference between a preview size aspect ratio and a picture size aspect ratio
-     * is less than this tolerance, they are considered to be the same aspect ratio.
-     */
-    private static final float ASPECT_RATIO_TOLERANCE = 0.01f;
-
-    protected Activity activity;
-
-    private Camera camera;
-
-    private int facing = CAMERA_FACING_BACK;
-
-    /**
-     * Rotation of the device, and thus the associated preview images captured from the device.
-     */
-    private int rotationDegrees;
-
-    private Size previewSize;
-
-    private final float requestedFps = 30.0f;
-    private final boolean requestedAutoFocus = true;
-
-    // These instances need to be held onto to avoid GC of their underlying resources.  Even though
-    // these aren't used outside of the method that creates them, they still must have hard
-    // references maintained to them.
-    private SurfaceTexture dummySurfaceTexture;
-    private final GraphicOverlay graphicOverlay;
-
-    // True if a SurfaceTexture is being used for the preview, false if a SurfaceHolder is being
-    // used for the preview.  We want to be compatible back to Gingerbread, but SurfaceTexture
-    // wasn't introduced until Honeycomb.  Since the interface cannot use a SurfaceTexture, if the
-    // developer wants to display a preview we must use a SurfaceHolder.  If the developer doesn't
-    // want to display a preview we use a SurfaceTexture if we are running at least Honeycomb.
-    private boolean usingSurfaceTexture;
-
-    /**
-     * Dedicated thread and associated runnable for calling into the detector with frames, as the
-     * frames become available from the camera.
-     */
-    private Thread processingThread;
-
-    private final FrameProcessingRunnable processingRunnable;
-
-    private final Object processorLock = new Object();
-    // TODO(b/74400062) Re-enable the annotaion
-    // @GuardedBy("processorLock")
-    private VisionImageProcessor frameProcessor;
-
-    /**
-     * Map to convert between a byte array, received from the camera, and its associated byte buffer.
-     * We use byte buffers internally because this is a more efficient way to call into native code
-     * later (avoids a potential copy).
-     *
-     * <p><b>Note:</b> uses IdentityHashMap here instead of HashMap because the behavior of an array's
-     * equals, hashCode and toString methods is both useless and unexpected. IdentityHashMap enforces
-     * identity ('==') check on the keys.
-     */
-    private final Map<byte[], ByteBuffer> bytesToByteBuffer = new IdentityHashMap<>();
-
-    public CameraSource(Activity activity, GraphicOverlay overlay) {
-        this.activity = activity;
-        graphicOverlay = overlay;
-        graphicOverlay.clear();
-        processingRunnable = new FrameProcessingRunnable();
-    }
-
-    // ==============================================================================================
-    // Public
-    // ==============================================================================================
-
-    /**
-     * Stops the camera and releases the resources of the camera and underlying detector.
-     */
-    public void release() {
-        synchronized (processorLock) {
-            stop();
-            processingRunnable.release();
-            cleanScreen();
-
-            if (frameProcessor != null) {
-                frameProcessor.stop();
-            }
-        }
-    }
-
-    /**
-     * Opens the camera and starts sending preview frames to the underlying detector. The preview
-     * frames are not displayed.
-     *
-     * @throws IOException if the camera's preview texture or display could not be initialized
-     */
-    @RequiresPermission(Manifest.permission.CAMERA)
-    public synchronized CameraSource start() throws IOException {
-        if (camera != null) {
-            return this;
-        }
-
-        camera = createCamera();
-        dummySurfaceTexture = new SurfaceTexture(DUMMY_TEXTURE_NAME);
-        camera.setPreviewTexture(dummySurfaceTexture);
-        usingSurfaceTexture = true;
-        camera.startPreview();
-
-        processingThread = new Thread(processingRunnable);
-        processingRunnable.setActive(true);
-        processingThread.start();
-        return this;
-    }
-
-    /**
-     * Opens the camera and starts sending preview frames to the underlying detector. The supplied
-     * surface holder is used for the preview so frames can be displayed to the user.
-     *
-     * @param surfaceHolder the surface holder to use for the preview frames
-     * @throws IOException if the supplied surface holder could not be used as the preview display
-     */
-    @RequiresPermission(Manifest.permission.CAMERA)
-    public synchronized CameraSource start(SurfaceHolder surfaceHolder) throws IOException {
-        if (camera != null) {
-            return this;
-        }
-
-        camera = createCamera();
-        camera.setPreviewDisplay(surfaceHolder);
-        camera.startPreview();
-
-        processingThread = new Thread(processingRunnable);
-        processingRunnable.setActive(true);
-        processingThread.start();
-
-        usingSurfaceTexture = false;
-        return this;
-    }
-
-    /**
-     * Closes the camera and stops sending frames to the underlying frame detector.
-     *
-     * <p>This camera source may be restarted again by calling {@link #start()} or {@link
-     * #start(SurfaceHolder)}.
-     *
-     * <p>Call {@link #release()} instead to completely shut down this camera source and release the
-     * resources of the underlying detector.
-     */
-    public synchronized void stop() {
-        processingRunnable.setActive(false);
-        if (processingThread != null) {
-            try {
-                // Wait for the thread to complete to ensure that we can't have multiple threads
-                // executing at the same time (i.e., which would happen if we called start too
-                // quickly after stop).
-                processingThread.join();
-            } catch (InterruptedException e) {
-                Log.d(TAG, "Frame processing thread interrupted on release.");
-            }
-            processingThread = null;
-        }
-
-        if (camera != null) {
-            camera.stopPreview();
-            camera.setPreviewCallbackWithBuffer(null);
-            try {
-                if (usingSurfaceTexture) {
-                    camera.setPreviewTexture(null);
-                } else {
-                    camera.setPreviewDisplay(null);
-                }
-            } catch (Exception e) {
-                Log.e(TAG, "Failed to clear camera preview: " + e);
-            }
-            camera.release();
-            camera = null;
-        }
-
-        // Release the reference to any image buffers, since these will no longer be in use.
-        bytesToByteBuffer.clear();
-    }
-
-    /**
-     * Changes the facing of the camera.
-     */
-    public synchronized void setFacing(int facing) {
-        if ((facing != CAMERA_FACING_BACK) && (facing != CAMERA_FACING_FRONT)) {
-            throw new IllegalArgumentException("Invalid camera: " + facing);
-        }
-        this.facing = facing;
-    }
-
-    /**
-     * Returns the preview size that is currently in use by the underlying camera.
-     */
-    public Size getPreviewSize() {
-        return previewSize;
-    }
-
-    /**
-     * Returns the selected camera; one of {@link #CAMERA_FACING_BACK} or {@link
-     * #CAMERA_FACING_FRONT}.
-     */
-    public int getCameraFacing() {
-        return facing;
-    }
-
-    /**
-     * Opens the camera and applies the user settings.
-     *
-     * @throws IOException if camera cannot be found or preview cannot be processed
-     */
-    @SuppressLint("InlinedApi")
-    private Camera createCamera() throws IOException {
-        int requestedCameraId = getIdForRequestedCamera(facing);
-        if (requestedCameraId == -1) {
-            throw new IOException("Could not find requested camera.");
-        }
-        Camera camera = Camera.open(requestedCameraId);
-
-        SizePair sizePair = PreferenceUtils.getCameraPreviewSizePair(activity, requestedCameraId);
-        if (sizePair == null) {
-            sizePair =
-                    selectSizePair(
-                            camera,
-                            DEFAULT_REQUESTED_CAMERA_PREVIEW_WIDTH,
-                            DEFAULT_REQUESTED_CAMERA_PREVIEW_HEIGHT);
-        }
-
-        if (sizePair == null) {
-            throw new IOException("Could not find suitable preview size.");
-        }
-
-        previewSize = sizePair.preview;
-        Log.v(TAG, "Camera preview size: " + previewSize);
-
-        int[] previewFpsRange = selectPreviewFpsRange(camera, requestedFps);
-        if (previewFpsRange == null) {
-            throw new IOException("Could not find suitable preview frames per second range.");
-        }
-
-        Camera.Parameters parameters = camera.getParameters();
-
-        Size pictureSize = sizePair.picture;
-        if (pictureSize != null) {
-            Log.v(TAG, "Camera picture size: " + pictureSize);
-            parameters.setPictureSize(pictureSize.getWidth(), pictureSize.getHeight());
-        }
-        parameters.setPreviewSize(previewSize.getWidth(), previewSize.getHeight());
-        parameters.setPreviewFpsRange(
-                previewFpsRange[Camera.Parameters.PREVIEW_FPS_MIN_INDEX],
-                previewFpsRange[Camera.Parameters.PREVIEW_FPS_MAX_INDEX]);
-        // Use YV12 so that we can exercise YV12->NV21 auto-conversion logic for OCR detection
-        parameters.setPreviewFormat(IMAGE_FORMAT);
-
-        setRotation(camera, parameters, requestedCameraId);
-
-        if (requestedAutoFocus) {
-            if (parameters
-                    .getSupportedFocusModes()
-                    .contains(Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO)) {
-                parameters.setFocusMode(Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO);
-            } else {
-                Log.i(TAG, "Camera auto focus is not supported on this device.");
-            }
-        }
-
-        camera.setParameters(parameters);
-
-        // Four frame buffers are needed for working with the camera:
-        //
-        //   one for the frame that is currently being executed upon in doing detection
-        //   one for the next pending frame to process immediately upon completing detection
-        //   two for the frames that the camera uses to populate future preview images
-        //
-        // Through trial and error it appears that two free buffers, in addition to the two buffers
-        // used in this code, are needed for the camera to work properly.  Perhaps the camera has
-        // one thread for acquiring images, and another thread for calling into user code.  If only
-        // three buffers are used, then the camera will spew thousands of warning messages when
-        // detection takes a non-trivial amount of time.
-        camera.setPreviewCallbackWithBuffer(new CameraPreviewCallback());
-        camera.addCallbackBuffer(createPreviewBuffer(previewSize));
-        camera.addCallbackBuffer(createPreviewBuffer(previewSize));
-        camera.addCallbackBuffer(createPreviewBuffer(previewSize));
-        camera.addCallbackBuffer(createPreviewBuffer(previewSize));
-
-        return camera;
-    }
-
-    /**
-     * Gets the id for the camera specified by the direction it is facing. Returns -1 if no such
-     * camera was found.
-     *
-     * @param facing the desired camera (front-facing or rear-facing)
-     */
-    private static int getIdForRequestedCamera(int facing) {
-        CameraInfo cameraInfo = new CameraInfo();
-        for (int i = 0; i < Camera.getNumberOfCameras(); ++i) {
-            Camera.getCameraInfo(i, cameraInfo);
-            if (cameraInfo.facing == facing) {
-                return i;
-            }
-        }
-        return -1;
-    }
-
-    /**
-     * Selects the most suitable preview and picture size, given the desired width and height.
-     *
-     * <p>Even though we only need to find the preview size, it's necessary to find both the preview
-     * size and the picture size of the camera together, because these need to have the same aspect
-     * ratio. On some hardware, if you would only set the preview size, you will get a distorted
-     * image.
-     *
-     * @param camera        the camera to select a preview size from
-     * @param desiredWidth  the desired width of the camera preview frames
-     * @param desiredHeight the desired height of the camera preview frames
-     * @return the selected preview and picture size pair
-     */
-    public static SizePair selectSizePair(Camera camera, int desiredWidth, int desiredHeight) {
-        List<SizePair> validPreviewSizes = generateValidPreviewSizeList(camera);
-
-        // The method for selecting the best size is to minimize the sum of the differences between
-        // the desired values and the actual values for width and height.  This is certainly not the
-        // only way to select the best size, but it provides a decent tradeoff between using the
-        // closest aspect ratio vs. using the closest pixel area.
-        SizePair selectedPair = null;
-        int minDiff = Integer.MAX_VALUE;
-        for (SizePair sizePair : validPreviewSizes) {
-            Size size = sizePair.preview;
-            int diff =
-                    Math.abs(size.getWidth() - desiredWidth) + Math.abs(size.getHeight() - desiredHeight);
-            if (diff < minDiff) {
-                selectedPair = sizePair;
-                minDiff = diff;
-            }
-        }
-
-        return selectedPair;
-    }
-
-    /**
-     * Stores a preview size and a corresponding same-aspect-ratio picture size. To avoid distorted
-     * preview images on some devices, the picture size must be set to a size that is the same aspect
-     * ratio as the preview size or the preview may end up being distorted. If the picture size is
-     * null, then there is no picture size with the same aspect ratio as the preview size.
-     */
-    public static class SizePair {
-        public final Size preview;
-        @Nullable
-        public final Size picture;
-
-        SizePair(
-                Camera.Size previewSize,
-                @Nullable Camera.Size pictureSize) {
-            preview = new Size(previewSize.width, previewSize.height);
-            picture = pictureSize != null ? new Size(pictureSize.width, pictureSize.height) : null;
-        }
-
-        public SizePair(Size previewSize, @Nullable Size pictureSize) {
-            preview = previewSize;
-            picture = pictureSize;
-        }
-    }
-
-    /**
-     * Generates a list of acceptable preview sizes. Preview sizes are not acceptable if there is not
-     * a corresponding picture size of the same aspect ratio. If there is a corresponding picture size
-     * of the same aspect ratio, the picture size is paired up with the preview size.
-     *
-     * <p>This is necessary because even if we don't use still pictures, the still picture size must
-     * be set to a size that is the same aspect ratio as the preview size we choose. Otherwise, the
-     * preview images may be distorted on some devices.
-     */
-    public static List<SizePair> generateValidPreviewSizeList(Camera camera) {
-        Camera.Parameters parameters = camera.getParameters();
-        List<Camera.Size> supportedPreviewSizes =
-                parameters.getSupportedPreviewSizes();
-        List<Camera.Size> supportedPictureSizes =
-                parameters.getSupportedPictureSizes();
-        List<SizePair> validPreviewSizes = new ArrayList<>();
-        for (Camera.Size previewSize : supportedPreviewSizes) {
-            float previewAspectRatio = (float) previewSize.width / (float) previewSize.height;
-
-            // By looping through the picture sizes in order, we favor the higher resolutions.
-            // We choose the highest resolution in order to support taking the full resolution
-            // picture later.
-            for (Camera.Size pictureSize : supportedPictureSizes) {
-                float pictureAspectRatio = (float) pictureSize.width / (float) pictureSize.height;
-                if (Math.abs(previewAspectRatio - pictureAspectRatio) < ASPECT_RATIO_TOLERANCE) {
-                    validPreviewSizes.add(new SizePair(previewSize, pictureSize));
-                    break;
-                }
-            }
-        }
-
-        // If there are no picture sizes with the same aspect ratio as any preview sizes, allow all
-        // of the preview sizes and hope that the camera can handle it.  Probably unlikely, but we
-        // still account for it.
-        if (validPreviewSizes.size() == 0) {
-            Log.w(TAG, "No preview sizes have a corresponding same-aspect-ratio picture size");
-            for (Camera.Size previewSize : supportedPreviewSizes) {
-                // The null picture size will let us know that we shouldn't set a picture size.
-                validPreviewSizes.add(new SizePair(previewSize, null));
-            }
-        }
-
-        return validPreviewSizes;
-    }
-
-    /**
-     * Selects the most suitable preview frames per second range, given the desired frames per second.
-     *
-     * @param camera            the camera to select a frames per second range from
-     * @param desiredPreviewFps the desired frames per second for the camera preview frames
-     * @return the selected preview frames per second range
-     */
-    @SuppressLint("InlinedApi")
-    private static int[] selectPreviewFpsRange(Camera camera, float desiredPreviewFps) {
-        // The camera API uses integers scaled by a factor of 1000 instead of floating-point frame
-        // rates.
-        int desiredPreviewFpsScaled = (int) (desiredPreviewFps * 1000.0f);
-
-        // The method for selecting the best range is to minimize the sum of the differences between
-        // the desired value and the upper and lower bounds of the range.  This may select a range
-        // that the desired value is outside of, but this is often preferred.  For example, if the
-        // desired frame rate is 29.97, the range (30, 30) is probably more desirable than the
-        // range (15, 30).
-        int[] selectedFpsRange = null;
-        int minDiff = Integer.MAX_VALUE;
-        List<int[]> previewFpsRangeList = camera.getParameters().getSupportedPreviewFpsRange();
-        for (int[] range : previewFpsRangeList) {
-            int deltaMin = desiredPreviewFpsScaled - range[Camera.Parameters.PREVIEW_FPS_MIN_INDEX];
-            int deltaMax = desiredPreviewFpsScaled - range[Camera.Parameters.PREVIEW_FPS_MAX_INDEX];
-            int diff = Math.abs(deltaMin) + Math.abs(deltaMax);
-            if (diff < minDiff) {
-                selectedFpsRange = range;
-                minDiff = diff;
-            }
-        }
-        return selectedFpsRange;
-    }
-
-    /**
-     * Calculates the correct rotation for the given camera id and sets the rotation in the
-     * parameters. It also sets the camera's display orientation and rotation.
-     *
-     * @param parameters the camera parameters for which to set the rotation
-     * @param cameraId   the camera id to set rotation based on
-     */
-    private void setRotation(Camera camera, Camera.Parameters parameters, int cameraId) {
-        WindowManager windowManager = (WindowManager) activity.getSystemService(Context.WINDOW_SERVICE);
-        int degrees = 0;
-        int rotation = windowManager.getDefaultDisplay().getRotation();
-        switch (rotation) {
-            case Surface.ROTATION_0:
-                degrees = 0;
-                break;
-            case Surface.ROTATION_90:
-                degrees = 90;
-                break;
-            case Surface.ROTATION_180:
-                degrees = 180;
-                break;
-            case Surface.ROTATION_270:
-                degrees = 270;
-                break;
-            default:
-                Log.e(TAG, "Bad rotation value: " + rotation);
-        }
-
-        CameraInfo cameraInfo = new CameraInfo();
-        Camera.getCameraInfo(cameraId, cameraInfo);
-
-        int displayAngle;
-        if (cameraInfo.facing == CameraInfo.CAMERA_FACING_FRONT) {
-            this.rotationDegrees = (cameraInfo.orientation + degrees) % 360;
-            displayAngle = (360 - this.rotationDegrees) % 360; // compensate for it being mirrored
-        } else { // back-facing
-            this.rotationDegrees = (cameraInfo.orientation - degrees + 360) % 360;
-            displayAngle = this.rotationDegrees;
-        }
-        Log.d(TAG, "Display rotation is: " + rotation);
-        Log.d(TAG, "Camera face is: " + cameraInfo.facing);
-        Log.d(TAG, "Camera rotation is: " + cameraInfo.orientation);
-        // This value should be one of the degrees that ImageMetadata accepts: 0, 90, 180 or 270.
-        Log.d(TAG, "RotationDegrees is: " + this.rotationDegrees);
-
-        camera.setDisplayOrientation(displayAngle);
-        parameters.setRotation(this.rotationDegrees);
-    }
-
-    /**
-     * Creates one buffer for the camera preview callback. The size of the buffer is based off of the
-     * camera preview size and the format of the camera image.
-     *
-     * @return a new preview buffer of the appropriate size for the current camera settings
-     */
-    @SuppressLint("InlinedApi")
-    private byte[] createPreviewBuffer(Size previewSize) {
-        int bitsPerPixel = ImageFormat.getBitsPerPixel(IMAGE_FORMAT);
-        long sizeInBits = (long) previewSize.getHeight() * previewSize.getWidth() * bitsPerPixel;
-        int bufferSize = (int) Math.ceil(sizeInBits / 8.0d) + 1;
-
-        // Creating the byte array this way and wrapping it, as opposed to using .allocate(),
-        // should guarantee that there will be an array to work with.
-        byte[] byteArray = new byte[bufferSize];
-        ByteBuffer buffer = ByteBuffer.wrap(byteArray);
-        if (!buffer.hasArray() || (buffer.array() != byteArray)) {
-            // I don't think that this will ever happen.  But if it does, then we wouldn't be
-            // passing the preview content to the underlying detector later.
-            throw new IllegalStateException("Failed to create valid buffer for camera source.");
-        }
-
-        bytesToByteBuffer.put(byteArray, buffer);
-        return byteArray;
-    }
-
-    // ==============================================================================================
-    // Frame processing
-    // ==============================================================================================
-
-    /**
-     * Called when the camera has a new preview frame.
-     */
-    private class CameraPreviewCallback implements Camera.PreviewCallback {
-        @Override
-        public void onPreviewFrame(byte[] data, Camera camera) {
-            processingRunnable.setNextFrame(data, camera);
-        }
-    }
-
-    public void setMachineLearningFrameProcessor(VisionImageProcessor processor) {
-        synchronized (processorLock) {
-            cleanScreen();
-            if (frameProcessor != null) {
-                frameProcessor.stop();
-            }
-            frameProcessor = processor;
-        }
-    }
-
-    /**
-     * This runnable controls access to the underlying receiver, calling it to process frames when
-     * available from the camera. This is designed to run detection on frames as fast as possible
-     * (i.e., without unnecessary context switching or waiting on the next frame).
-     *
-     * <p>While detection is running on a frame, new frames may be received from the camera. As these
-     * frames come in, the most recent frame is held onto as pending. As soon as detection and its
-     * associated processing is done for the previous frame, detection on the mostly recently received
-     * frame will immediately start on the same thread.
-     */
-    private class FrameProcessingRunnable implements Runnable {
-
-        // This lock guards all of the member variables below.
-        private final Object lock = new Object();
-        private boolean active = true;
-
-        // These pending variables hold the state associated with the new frame awaiting processing.
-        private ByteBuffer pendingFrameData;
-
-        FrameProcessingRunnable() {
-        }
-
-        /**
-         * Releases the underlying receiver. This is only safe to do after the associated thread has
-         * completed, which is managed in camera source's release method above.
-         */
-        @SuppressLint("Assert")
-        void release() {
-            assert (processingThread.getState() == State.TERMINATED);
-        }
-
-        /**
-         * Marks the runnable as active/not active. Signals any blocked threads to continue.
-         */
-        void setActive(boolean active) {
-            synchronized (lock) {
-                this.active = active;
-                lock.notifyAll();
-            }
-        }
-
-        /**
-         * Sets the frame data received from the camera. This adds the previous unused frame buffer (if
-         * present) back to the camera, and keeps a pending reference to the frame data for future use.
-         */
-        @SuppressWarnings("ByteBufferBackingArray")
-        void setNextFrame(byte[] data, Camera camera) {
-            synchronized (lock) {
-                if (pendingFrameData != null) {
-                    camera.addCallbackBuffer(pendingFrameData.array());
-                    pendingFrameData = null;
-                }
-
-                if (!bytesToByteBuffer.containsKey(data)) {
-                    Log.d(
-                            TAG,
-                            "Skipping frame. Could not find ByteBuffer associated with the image "
-                                    + "data from the camera.");
-                    return;
-                }
-
-                pendingFrameData = bytesToByteBuffer.get(data);
-
-                // Notify the processor thread if it is waiting on the next frame (see below).
-                lock.notifyAll();
-            }
-        }
-
-        /**
-         * As long as the processing thread is active, this executes detection on frames continuously.
-         * The next pending frame is either immediately available or hasn't been received yet. Once it
-         * is available, we transfer the frame info to local variables and run detection on that frame.
-         * It immediately loops back for the next frame without pausing.
-         *
-         * <p>If detection takes longer than the time in between new frames from the camera, this will
-         * mean that this loop will run without ever waiting on a frame, avoiding any context switching
-         * or frame acquisition time latency.
-         *
-         * <p>If you find that this is using more CPU than you'd like, you should probably decrease the
-         * FPS setting above to allow for some idle time in between frames.
-         */
-        @SuppressLint("InlinedApi")
-        @SuppressWarnings({"GuardedBy", "ByteBufferBackingArray"})
-        @Override
-        public void run() {
-            ByteBuffer data;
-
-            while (true) {
-                synchronized (lock) {
-                    while (active && (pendingFrameData == null)) {
-                        try {
-                            // Wait for the next frame to be received from the camera, since we
-                            // don't have it yet.
-                            lock.wait();
-                        } catch (InterruptedException e) {
-                            Log.d(TAG, "Frame processing loop terminated.", e);
-                            return;
-                        }
-                    }
-
-                    if (!active) {
-                        // Exit the loop once this camera source is stopped or released.  We check
-                        // this here, immediately after the wait() above, to handle the case where
-                        // setActive(false) had been called, triggering the termination of this
-                        // loop.
-                        return;
-                    }
-
-                    // Hold onto the frame data locally, so that we can use this for detection
-                    // below.  We need to clear pendingFrameData to ensure that this buffer isn't
-                    // recycled back to the camera before we are done using that data.
-                    data = pendingFrameData;
-                    pendingFrameData = null;
-                }
-
-                // The code below needs to run outside of synchronization, because this will allow
-                // the camera to add pending frame(s) while we are running detection on the current
-                // frame.
-
-                try {
-                    synchronized (processorLock) {
-                        frameProcessor.processByteBuffer(
-                                data,
-                                new FrameMetadata.Builder()
-                                        .setWidth(previewSize.getWidth())
-                                        .setHeight(previewSize.getHeight())
-                                        .setRotation(rotationDegrees)
-                                        .build(),
-                                graphicOverlay);
-                    }
-                } catch (Exception t) {
-                    Log.e(TAG, "Exception thrown from receiver.", t);
-                } finally {
-                    camera.addCallbackBuffer(data.array());
-                }
-            }
-        }
-    }
-
-    /**
-     * Cleans up graphicOverlay and child classes can do their cleanups as well .
-     */
-    private void cleanScreen() {
-        graphicOverlay.clear();
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.Manifest;
+import android.annotation.SuppressLint;
+import android.app.Activity;
+import android.content.Context;
+import android.graphics.ImageFormat;
+import android.graphics.SurfaceTexture;
+import android.hardware.Camera;
+import android.hardware.Camera.CameraInfo;
+import android.util.Log;
+import android.view.Surface;
+import android.view.SurfaceHolder;
+import android.view.WindowManager;
+
+import androidx.annotation.Nullable;
+import androidx.annotation.RequiresPermission;
+
+import com.google.android.gms.common.images.Size;
+import com.google.mlkit.vision.demo.preference.PreferenceUtils;
+
+import java.io.IOException;
+import java.lang.Thread.State;
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
+import java.util.IdentityHashMap;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * Manages the camera and allows UI updates on top of it (e.g. overlaying extra Graphics or
+ * displaying extra information). This receives preview frames from the camera at a specified rate,
+ * sending those frames to child classes' detectors / classifiers as fast as it is able to process.
+ */
+public class CameraSource {
+    @SuppressLint("InlinedApi")
+    public static final int CAMERA_FACING_BACK = CameraInfo.CAMERA_FACING_BACK;
+
+    @SuppressLint("InlinedApi")
+    public static final int CAMERA_FACING_FRONT = CameraInfo.CAMERA_FACING_FRONT;
+
+    public static final int IMAGE_FORMAT = ImageFormat.NV21;
+    public static final int DEFAULT_REQUESTED_CAMERA_PREVIEW_WIDTH = 480;
+    public static final int DEFAULT_REQUESTED_CAMERA_PREVIEW_HEIGHT = 360;
+
+    private static final String TAG = "MIDemoApp";
+
+    /**
+     * The dummy surface texture must be assigned a chosen name. Since we never use an OpenGL context,
+     * we can choose any ID we want here. The dummy surface texture is not a crazy hack - it is
+     * actually how the camera team recommends using the camera without a preview.
+     */
+    private static final int DUMMY_TEXTURE_NAME = 100;
+
+    /**
+     * If the absolute difference between a preview size aspect ratio and a picture size aspect ratio
+     * is less than this tolerance, they are considered to be the same aspect ratio.
+     */
+    private static final float ASPECT_RATIO_TOLERANCE = 0.01f;
+
+    protected Activity activity;
+
+    private Camera camera;
+
+    private int facing = CAMERA_FACING_BACK;
+
+    /**
+     * Rotation of the device, and thus the associated preview images captured from the device.
+     */
+    private int rotationDegrees;
+
+    private Size previewSize;
+
+    private final float requestedFps = 30.0f;
+    private final boolean requestedAutoFocus = true;
+
+    // These instances need to be held onto to avoid GC of their underlying resources.  Even though
+    // these aren't used outside of the method that creates them, they still must have hard
+    // references maintained to them.
+    private SurfaceTexture dummySurfaceTexture;
+    private final GraphicOverlay graphicOverlay;
+
+    // True if a SurfaceTexture is being used for the preview, false if a SurfaceHolder is being
+    // used for the preview.  We want to be compatible back to Gingerbread, but SurfaceTexture
+    // wasn't introduced until Honeycomb.  Since the interface cannot use a SurfaceTexture, if the
+    // developer wants to display a preview we must use a SurfaceHolder.  If the developer doesn't
+    // want to display a preview we use a SurfaceTexture if we are running at least Honeycomb.
+    private boolean usingSurfaceTexture;
+
+    /**
+     * Dedicated thread and associated runnable for calling into the detector with frames, as the
+     * frames become available from the camera.
+     */
+    private Thread processingThread;
+
+    private final FrameProcessingRunnable processingRunnable;
+
+    private final Object processorLock = new Object();
+    // TODO(b/74400062) Re-enable the annotaion
+    // @GuardedBy("processorLock")
+    private VisionImageProcessor frameProcessor;
+
+    /**
+     * Map to convert between a byte array, received from the camera, and its associated byte buffer.
+     * We use byte buffers internally because this is a more efficient way to call into native code
+     * later (avoids a potential copy).
+     *
+     * <p><b>Note:</b> uses IdentityHashMap here instead of HashMap because the behavior of an array's
+     * equals, hashCode and toString methods is both useless and unexpected. IdentityHashMap enforces
+     * identity ('==') check on the keys.
+     */
+    private final Map<byte[], ByteBuffer> bytesToByteBuffer = new IdentityHashMap<>();
+
+    public CameraSource(Activity activity, GraphicOverlay overlay) {
+        this.activity = activity;
+        graphicOverlay = overlay;
+        graphicOverlay.clear();
+        processingRunnable = new FrameProcessingRunnable();
+    }
+
+    // ==============================================================================================
+    // Public
+    // ==============================================================================================
+
+    /**
+     * Stops the camera and releases the resources of the camera and underlying detector.
+     */
+    public void release() {
+        synchronized (processorLock) {
+            stop();
+            processingRunnable.release();
+            cleanScreen();
+
+            if (frameProcessor != null) {
+                frameProcessor.stop();
+            }
+        }
+    }
+
+    /**
+     * Opens the camera and starts sending preview frames to the underlying detector. The preview
+     * frames are not displayed.
+     *
+     * @throws IOException if the camera's preview texture or display could not be initialized
+     */
+    @RequiresPermission(Manifest.permission.CAMERA)
+    public synchronized CameraSource start() throws IOException {
+        if (camera != null) {
+            return this;
+        }
+
+        camera = createCamera();
+        dummySurfaceTexture = new SurfaceTexture(DUMMY_TEXTURE_NAME);
+        camera.setPreviewTexture(dummySurfaceTexture);
+        usingSurfaceTexture = true;
+        camera.startPreview();
+
+        processingThread = new Thread(processingRunnable);
+        processingRunnable.setActive(true);
+        processingThread.start();
+        return this;
+    }
+
+    /**
+     * Opens the camera and starts sending preview frames to the underlying detector. The supplied
+     * surface holder is used for the preview so frames can be displayed to the user.
+     *
+     * @param surfaceHolder the surface holder to use for the preview frames
+     * @throws IOException if the supplied surface holder could not be used as the preview display
+     */
+    @RequiresPermission(Manifest.permission.CAMERA)
+    public synchronized CameraSource start(SurfaceHolder surfaceHolder) throws IOException {
+        if (camera != null) {
+            return this;
+        }
+
+        camera = createCamera();
+        camera.setPreviewDisplay(surfaceHolder);
+        camera.startPreview();
+
+        processingThread = new Thread(processingRunnable);
+        processingRunnable.setActive(true);
+        processingThread.start();
+
+        usingSurfaceTexture = false;
+        return this;
+    }
+
+    /**
+     * Closes the camera and stops sending frames to the underlying frame detector.
+     *
+     * <p>This camera source may be restarted again by calling {@link #start()} or {@link
+     * #start(SurfaceHolder)}.
+     *
+     * <p>Call {@link #release()} instead to completely shut down this camera source and release the
+     * resources of the underlying detector.
+     */
+    public synchronized void stop() {
+        processingRunnable.setActive(false);
+        if (processingThread != null) {
+            try {
+                // Wait for the thread to complete to ensure that we can't have multiple threads
+                // executing at the same time (i.e., which would happen if we called start too
+                // quickly after stop).
+                processingThread.join();
+            } catch (InterruptedException e) {
+                Log.d(TAG, "Frame processing thread interrupted on release.");
+            }
+            processingThread = null;
+        }
+
+        if (camera != null) {
+            camera.stopPreview();
+            camera.setPreviewCallbackWithBuffer(null);
+            try {
+                if (usingSurfaceTexture) {
+                    camera.setPreviewTexture(null);
+                } else {
+                    camera.setPreviewDisplay(null);
+                }
+            } catch (Exception e) {
+                Log.e(TAG, "Failed to clear camera preview: " + e);
+            }
+            camera.release();
+            camera = null;
+        }
+
+        // Release the reference to any image buffers, since these will no longer be in use.
+        bytesToByteBuffer.clear();
+    }
+
+    /**
+     * Changes the facing of the camera.
+     */
+    public synchronized void setFacing(int facing) {
+        if ((facing != CAMERA_FACING_BACK) && (facing != CAMERA_FACING_FRONT)) {
+            throw new IllegalArgumentException("Invalid camera: " + facing);
+        }
+        this.facing = facing;
+    }
+
+    /**
+     * Returns the preview size that is currently in use by the underlying camera.
+     */
+    public Size getPreviewSize() {
+        return previewSize;
+    }
+
+    /**
+     * Returns the selected camera; one of {@link #CAMERA_FACING_BACK} or {@link
+     * #CAMERA_FACING_FRONT}.
+     */
+    public int getCameraFacing() {
+        return facing;
+    }
+
+    /**
+     * Opens the camera and applies the user settings.
+     *
+     * @throws IOException if camera cannot be found or preview cannot be processed
+     */
+    @SuppressLint("InlinedApi")
+    private Camera createCamera() throws IOException {
+        int requestedCameraId = getIdForRequestedCamera(facing);
+        if (requestedCameraId == -1) {
+            throw new IOException("Could not find requested camera. requestedCameraId:"+requestedCameraId);
+        }
+
+        Camera camera = Camera.open(requestedCameraId);
+//        Camera camera = Camera.open(1);
+        Log.i(TAG, "createCamera()");
+
+        SizePair sizePair = PreferenceUtils.getCameraPreviewSizePair(activity, requestedCameraId);
+        if (sizePair == null) {
+            sizePair =
+                    selectSizePair(
+                            camera,
+                            DEFAULT_REQUESTED_CAMERA_PREVIEW_WIDTH,
+                            DEFAULT_REQUESTED_CAMERA_PREVIEW_HEIGHT);
+        }
+
+        if (sizePair == null) {
+            throw new IOException("Could not find suitable preview size.");
+        }
+
+        previewSize = sizePair.preview;
+        Log.v(TAG, "Camera preview size: " + previewSize);
+
+        int[] previewFpsRange = selectPreviewFpsRange(camera, requestedFps);
+        if (previewFpsRange == null) {
+            throw new IOException("Could not find suitable preview frames per second range.");
+        }
+
+        Camera.Parameters parameters = camera.getParameters();
+
+        Size pictureSize = sizePair.picture;
+        if (pictureSize != null) {
+            Log.v(TAG, "Camera picture size: " + pictureSize);
+            parameters.setPictureSize(pictureSize.getWidth(), pictureSize.getHeight());
+        }
+        parameters.setPreviewSize(previewSize.getWidth(), previewSize.getHeight());
+        parameters.setPreviewFpsRange(
+                previewFpsRange[Camera.Parameters.PREVIEW_FPS_MIN_INDEX],
+                previewFpsRange[Camera.Parameters.PREVIEW_FPS_MAX_INDEX]);
+        // Use YV12 so that we can exercise YV12->NV21 auto-conversion logic for OCR detection
+        parameters.setPreviewFormat(IMAGE_FORMAT);
+
+        setRotation(camera, parameters, requestedCameraId);
+
+        if (requestedAutoFocus) {
+            if (parameters
+                    .getSupportedFocusModes()
+                    .contains(Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO)) {
+                parameters.setFocusMode(Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO);
+            } else {
+                Log.i(TAG, "Camera auto focus is not supported on this device.");
+            }
+        }
+
+        camera.setParameters(parameters);
+
+        // Four frame buffers are needed for working with the camera:
+        //
+        //   one for the frame that is currently being executed upon in doing detection
+        //   one for the next pending frame to process immediately upon completing detection
+        //   two for the frames that the camera uses to populate future preview images
+        //
+        // Through trial and error it appears that two free buffers, in addition to the two buffers
+        // used in this code, are needed for the camera to work properly.  Perhaps the camera has
+        // one thread for acquiring images, and another thread for calling into user code.  If only
+        // three buffers are used, then the camera will spew thousands of warning messages when
+        // detection takes a non-trivial amount of time.
+        camera.setPreviewCallbackWithBuffer(new CameraPreviewCallback());
+        camera.addCallbackBuffer(createPreviewBuffer(previewSize));
+        camera.addCallbackBuffer(createPreviewBuffer(previewSize));
+        camera.addCallbackBuffer(createPreviewBuffer(previewSize));
+        camera.addCallbackBuffer(createPreviewBuffer(previewSize));
+
+        return camera;
+    }
+
+    /**
+     * Gets the id for the camera specified by the direction it is facing. Returns -1 if no such
+     * camera was found.
+     *
+     * @param facing the desired camera (front-facing or rear-facing)
+     */
+    private static int getIdForRequestedCamera(int facing) {
+        if (facing==CAMERA_FACING_FRONT)
+            return 1;
+
+        CameraInfo cameraInfo = new CameraInfo();
+        for (int i = 0; i < Camera.getNumberOfCameras(); ++i) {
+            Camera.getCameraInfo(i, cameraInfo);
+            if (cameraInfo.facing == facing) {
+                return i;
+            }
+        }
+        return -1;
+    }
+
+    /**
+     * Selects the most suitable preview and picture size, given the desired width and height.
+     *
+     * <p>Even though we only need to find the preview size, it's necessary to find both the preview
+     * size and the picture size of the camera together, because these need to have the same aspect
+     * ratio. On some hardware, if you would only set the preview size, you will get a distorted
+     * image.
+     *
+     * @param camera        the camera to select a preview size from
+     * @param desiredWidth  the desired width of the camera preview frames
+     * @param desiredHeight the desired height of the camera preview frames
+     * @return the selected preview and picture size pair
+     */
+    public static SizePair selectSizePair(Camera camera, int desiredWidth, int desiredHeight) {
+        List<SizePair> validPreviewSizes = generateValidPreviewSizeList(camera);
+
+        // The method for selecting the best size is to minimize the sum of the differences between
+        // the desired values and the actual values for width and height.  This is certainly not the
+        // only way to select the best size, but it provides a decent tradeoff between using the
+        // closest aspect ratio vs. using the closest pixel area.
+        SizePair selectedPair = null;
+        int minDiff = Integer.MAX_VALUE;
+        for (SizePair sizePair : validPreviewSizes) {
+            Size size = sizePair.preview;
+            int diff =
+                    Math.abs(size.getWidth() - desiredWidth) + Math.abs(size.getHeight() - desiredHeight);
+            if (diff < minDiff) {
+                selectedPair = sizePair;
+                minDiff = diff;
+            }
+        }
+
+        return selectedPair;
+    }
+
+    /**
+     * Stores a preview size and a corresponding same-aspect-ratio picture size. To avoid distorted
+     * preview images on some devices, the picture size must be set to a size that is the same aspect
+     * ratio as the preview size or the preview may end up being distorted. If the picture size is
+     * null, then there is no picture size with the same aspect ratio as the preview size.
+     */
+    public static class SizePair {
+        public final Size preview;
+        @Nullable
+        public final Size picture;
+
+        SizePair(
+                Camera.Size previewSize,
+                @Nullable Camera.Size pictureSize) {
+            preview = new Size(previewSize.width, previewSize.height);
+            picture = pictureSize != null ? new Size(pictureSize.width, pictureSize.height) : null;
+        }
+
+        public SizePair(Size previewSize, @Nullable Size pictureSize) {
+            preview = previewSize;
+            picture = pictureSize;
+        }
+    }
+
+    /**
+     * Generates a list of acceptable preview sizes. Preview sizes are not acceptable if there is not
+     * a corresponding picture size of the same aspect ratio. If there is a corresponding picture size
+     * of the same aspect ratio, the picture size is paired up with the preview size.
+     *
+     * <p>This is necessary because even if we don't use still pictures, the still picture size must
+     * be set to a size that is the same aspect ratio as the preview size we choose. Otherwise, the
+     * preview images may be distorted on some devices.
+     */
+    public static List<SizePair> generateValidPreviewSizeList(Camera camera) {
+        Camera.Parameters parameters = camera.getParameters();
+        List<Camera.Size> supportedPreviewSizes =
+                parameters.getSupportedPreviewSizes();
+        List<Camera.Size> supportedPictureSizes =
+                parameters.getSupportedPictureSizes();
+        List<SizePair> validPreviewSizes = new ArrayList<>();
+        for (Camera.Size previewSize : supportedPreviewSizes) {
+            float previewAspectRatio = (float) previewSize.width / (float) previewSize.height;
+
+            // By looping through the picture sizes in order, we favor the higher resolutions.
+            // We choose the highest resolution in order to support taking the full resolution
+            // picture later.
+            for (Camera.Size pictureSize : supportedPictureSizes) {
+                float pictureAspectRatio = (float) pictureSize.width / (float) pictureSize.height;
+                if (Math.abs(previewAspectRatio - pictureAspectRatio) < ASPECT_RATIO_TOLERANCE) {
+                    validPreviewSizes.add(new SizePair(previewSize, pictureSize));
+                    break;
+                }
+            }
+        }
+
+        // If there are no picture sizes with the same aspect ratio as any preview sizes, allow all
+        // of the preview sizes and hope that the camera can handle it.  Probably unlikely, but we
+        // still account for it.
+        if (validPreviewSizes.size() == 0) {
+            Log.w(TAG, "No preview sizes have a corresponding same-aspect-ratio picture size");
+            for (Camera.Size previewSize : supportedPreviewSizes) {
+                // The null picture size will let us know that we shouldn't set a picture size.
+                validPreviewSizes.add(new SizePair(previewSize, null));
+            }
+        }
+
+        return validPreviewSizes;
+    }
+
+    /**
+     * Selects the most suitable preview frames per second range, given the desired frames per second.
+     *
+     * @param camera            the camera to select a frames per second range from
+     * @param desiredPreviewFps the desired frames per second for the camera preview frames
+     * @return the selected preview frames per second range
+     */
+    @SuppressLint("InlinedApi")
+    private static int[] selectPreviewFpsRange(Camera camera, float desiredPreviewFps) {
+        // The camera API uses integers scaled by a factor of 1000 instead of floating-point frame
+        // rates.
+        int desiredPreviewFpsScaled = (int) (desiredPreviewFps * 1000.0f);
+
+        // The method for selecting the best range is to minimize the sum of the differences between
+        // the desired value and the upper and lower bounds of the range.  This may select a range
+        // that the desired value is outside of, but this is often preferred.  For example, if the
+        // desired frame rate is 29.97, the range (30, 30) is probably more desirable than the
+        // range (15, 30).
+        int[] selectedFpsRange = null;
+        int minDiff = Integer.MAX_VALUE;
+        List<int[]> previewFpsRangeList = camera.getParameters().getSupportedPreviewFpsRange();
+        for (int[] range : previewFpsRangeList) {
+            int deltaMin = desiredPreviewFpsScaled - range[Camera.Parameters.PREVIEW_FPS_MIN_INDEX];
+            int deltaMax = desiredPreviewFpsScaled - range[Camera.Parameters.PREVIEW_FPS_MAX_INDEX];
+            int diff = Math.abs(deltaMin) + Math.abs(deltaMax);
+            if (diff < minDiff) {
+                selectedFpsRange = range;
+                minDiff = diff;
+            }
+        }
+        return selectedFpsRange;
+    }
+
+    /**
+     * Calculates the correct rotation for the given camera id and sets the rotation in the
+     * parameters. It also sets the camera's display orientation and rotation.
+     *
+     * @param parameters the camera parameters for which to set the rotation
+     * @param cameraId   the camera id to set rotation based on
+     */
+    private void setRotation(Camera camera, Camera.Parameters parameters, int cameraId) {
+        WindowManager windowManager = (WindowManager) activity.getSystemService(Context.WINDOW_SERVICE);
+        int degrees = 0;
+        int rotation = windowManager.getDefaultDisplay().getRotation();
+        switch (rotation) {
+            case Surface.ROTATION_0:
+                degrees = 0;
+                break;
+            case Surface.ROTATION_90:
+                degrees = 90;
+                break;
+            case Surface.ROTATION_180:
+                degrees = 180;
+                break;
+            case Surface.ROTATION_270:
+                degrees = 270;
+                break;
+            default:
+                Log.e(TAG, "Bad rotation value: " + rotation);
+        }
+
+        CameraInfo cameraInfo = new CameraInfo();
+        Camera.getCameraInfo(cameraId, cameraInfo);
+
+        int displayAngle=0;
+        if (cameraInfo.facing == CameraInfo.CAMERA_FACING_FRONT) {
+            this.rotationDegrees = (cameraInfo.orientation + degrees) % 360;
+            displayAngle = (360 - this.rotationDegrees) % 360; // compensate for it being mirrored
+
+            this.rotationDegrees=0;
+            displayAngle=0;
+            //cameraInfo.facing=CAMERA_FACING_BACK;
+
+        } else { // back-facing
+            this.rotationDegrees = (cameraInfo.orientation - degrees + 360) % 360;
+            displayAngle = this.rotationDegrees;
+        }
+        Log.d(TAG, "degrees: "+ degrees);
+        Log.d(TAG, "Display rotation is: " + rotation);
+        Log.d(TAG, "Camera face is: " + cameraInfo.facing);
+        Log.d(TAG, "Camera rotation is: " + cameraInfo.orientation);
+        Log.d(TAG, "RotationDegrees is: " + this.rotationDegrees);
+
+        camera.setDisplayOrientation(displayAngle);
+        parameters.setRotation(this.rotationDegrees);
+    }
+
+    /**
+     * Creates one buffer for the camera preview callback. The size of the buffer is based off of the
+     * camera preview size and the format of the camera image.
+     *
+     * @return a new preview buffer of the appropriate size for the current camera settings
+     */
+    @SuppressLint("InlinedApi")
+    private byte[] createPreviewBuffer(Size previewSize) {
+        int bitsPerPixel = ImageFormat.getBitsPerPixel(IMAGE_FORMAT);
+        long sizeInBits = (long) previewSize.getHeight() * previewSize.getWidth() * bitsPerPixel;
+        int bufferSize = (int) Math.ceil(sizeInBits / 8.0d) + 1;
+
+        // Creating the byte array this way and wrapping it, as opposed to using .allocate(),
+        // should guarantee that there will be an array to work with.
+        byte[] byteArray = new byte[bufferSize];
+        ByteBuffer buffer = ByteBuffer.wrap(byteArray);
+        if (!buffer.hasArray() || (buffer.array() != byteArray)) {
+            // I don't think that this will ever happen.  But if it does, then we wouldn't be
+            // passing the preview content to the underlying detector later.
+            throw new IllegalStateException("Failed to create valid buffer for camera source.");
+        }
+
+        bytesToByteBuffer.put(byteArray, buffer);
+        return byteArray;
+    }
+
+    // ==============================================================================================
+    // Frame processing
+    // ==============================================================================================
+
+    /**
+     * Called when the camera has a new preview frame.
+     */
+    private class CameraPreviewCallback implements Camera.PreviewCallback {
+        @Override
+        public void onPreviewFrame(byte[] data, Camera camera) {
+            processingRunnable.setNextFrame(data, camera);
+        }
+    }
+
+    public void setMachineLearningFrameProcessor(VisionImageProcessor processor) {
+        synchronized (processorLock) {
+            cleanScreen();
+            if (frameProcessor != null) {
+                frameProcessor.stop();
+            }
+            frameProcessor = processor;
+        }
+    }
+
+    /**
+     * This runnable controls access to the underlying receiver, calling it to process frames when
+     * available from the camera. This is designed to run detection on frames as fast as possible
+     * (i.e., without unnecessary context switching or waiting on the next frame).
+     *
+     * <p>While detection is running on a frame, new frames may be received from the camera. As these
+     * frames come in, the most recent frame is held onto as pending. As soon as detection and its
+     * associated processing is done for the previous frame, detection on the mostly recently received
+     * frame will immediately start on the same thread.
+     */
+    private class FrameProcessingRunnable implements Runnable {
+
+        // This lock guards all of the member variables below.
+        private final Object lock = new Object();
+        private boolean active = true;
+
+        // These pending variables hold the state associated with the new frame awaiting processing.
+        private ByteBuffer pendingFrameData;
+
+        FrameProcessingRunnable() {
+        }
+
+        /**
+         * Releases the underlying receiver. This is only safe to do after the associated thread has
+         * completed, which is managed in camera source's release method above.
+         */
+        @SuppressLint("Assert")
+        void release() {
+            assert (processingThread.getState() == State.TERMINATED);
+        }
+
+        /**
+         * Marks the runnable as active/not active. Signals any blocked threads to continue.
+         */
+        void setActive(boolean active) {
+            synchronized (lock) {
+                this.active = active;
+                lock.notifyAll();
+            }
+        }
+
+        /**
+         * Sets the frame data received from the camera. This adds the previous unused frame buffer (if
+         * present) back to the camera, and keeps a pending reference to the frame data for future use.
+         */
+        @SuppressWarnings("ByteBufferBackingArray")
+        void setNextFrame(byte[] data, Camera camera) {
+            synchronized (lock) {
+                if (pendingFrameData != null) {
+                    camera.addCallbackBuffer(pendingFrameData.array());
+                    pendingFrameData = null;
+                }
+
+                if (!bytesToByteBuffer.containsKey(data)) {
+                    Log.d(
+                            TAG,
+                            "Skipping frame. Could not find ByteBuffer associated with the image "
+                                    + "data from the camera.");
+                    return;
+                }
+
+                pendingFrameData = bytesToByteBuffer.get(data);
+
+                // Notify the processor thread if it is waiting on the next frame (see below).
+                lock.notifyAll();
+            }
+        }
+
+        /**
+         * As long as the processing thread is active, this executes detection on frames continuously.
+         * The next pending frame is either immediately available or hasn't been received yet. Once it
+         * is available, we transfer the frame info to local variables and run detection on that frame.
+         * It immediately loops back for the next frame without pausing.
+         *
+         * <p>If detection takes longer than the time in between new frames from the camera, this will
+         * mean that this loop will run without ever waiting on a frame, avoiding any context switching
+         * or frame acquisition time latency.
+         *
+         * <p>If you find that this is using more CPU than you'd like, you should probably decrease the
+         * FPS setting above to allow for some idle time in between frames.
+         */
+        @SuppressLint("InlinedApi")
+        @SuppressWarnings({"GuardedBy", "ByteBufferBackingArray"})
+        @Override
+        public void run() {
+            ByteBuffer data;
+
+            while (true) {
+                synchronized (lock) {
+                    while (active && (pendingFrameData == null)) {
+                        try {
+                            // Wait for the next frame to be received from the camera, since we
+                            // don't have it yet.
+                            lock.wait();
+                        } catch (InterruptedException e) {
+                            Log.d(TAG, "Frame processing loop terminated.", e);
+                            return;
+                        }
+                    }
+
+                    if (!active) {
+                        // Exit the loop once this camera source is stopped or released.  We check
+                        // this here, immediately after the wait() above, to handle the case where
+                        // setActive(false) had been called, triggering the termination of this
+                        // loop.
+                        return;
+                    }
+
+                    // Hold onto the frame data locally, so that we can use this for detection
+                    // below.  We need to clear pendingFrameData to ensure that this buffer isn't
+                    // recycled back to the camera before we are done using that data.
+                    data = pendingFrameData;
+                    pendingFrameData = null;
+                }
+
+                // The code below needs to run outside of synchronization, because this will allow
+                // the camera to add pending frame(s) while we are running detection on the current
+                // frame.
+
+                try {
+                    synchronized (processorLock) {
+                        frameProcessor.processByteBuffer(
+                                data,
+                                new FrameMetadata.Builder()
+                                        .setWidth(previewSize.getWidth())
+                                        .setHeight(previewSize.getHeight())
+                                        .setRotation(rotationDegrees)
+                                        .build(),
+                                graphicOverlay);
+                    }
+                } catch (Exception t) {
+                    Log.e(TAG, "Exception thrown from receiver.", t);
+                } finally {
+                    camera.addCallbackBuffer(data.array());
+                }
+            }
+        }
+    }
+
+    /**
+     * Cleans up graphicOverlay and child classes can do their cleanups as well .
+     */
+    private void cleanScreen() {
+        graphicOverlay.clear();
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraSourcePreview.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraSourcePreview.java
index 0832a2e..cf1562a 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraSourcePreview.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraSourcePreview.java
@@ -1,193 +1,194 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.content.Context;
-import android.content.res.Configuration;
-import android.util.AttributeSet;
-import android.util.Log;
-import android.view.SurfaceHolder;
-import android.view.SurfaceView;
-import android.view.ViewGroup;
-
-import com.google.android.gms.common.images.Size;
-import com.google.mlkit.vision.demo.preference.PreferenceUtils;
-
-import java.io.IOException;
-
-/**
- * Preview the camera image in the screen.
- */
-public class CameraSourcePreview extends ViewGroup {
-    private static final String TAG = "MIDemoApp:Preview";
-
-    private final Context context;
-    private final SurfaceView surfaceView;
-    private boolean startRequested;
-    private boolean surfaceAvailable;
-    private CameraSource cameraSource;
-
-    private GraphicOverlay overlay;
-
-    public CameraSourcePreview(Context context, AttributeSet attrs) {
-        super(context, attrs);
-        this.context = context;
-        startRequested = false;
-        surfaceAvailable = false;
-
-        surfaceView = new SurfaceView(context);
-        surfaceView.getHolder().addCallback(new SurfaceCallback());
-        addView(surfaceView);
-    }
-
-    private void start(CameraSource cameraSource) throws IOException {
-        if (cameraSource == null) {
-            stop();
-        }
-
-        this.cameraSource = cameraSource;
-
-        if (this.cameraSource != null) {
-            startRequested = true;
-            startIfReady();
-        }
-    }
-
-    public void start(CameraSource cameraSource, GraphicOverlay overlay) throws IOException {
-        this.overlay = overlay;
-        start(cameraSource);
-    }
-
-    public void stop() {
-        if (cameraSource != null) {
-            cameraSource.stop();
-        }
-    }
-
-    public void release() {
-        if (cameraSource != null) {
-            cameraSource.release();
-            cameraSource = null;
-        }
-        surfaceView.getHolder().getSurface().release();
-    }
-
-    private void startIfReady() throws IOException, SecurityException {
-        if (startRequested && surfaceAvailable) {
-            if (PreferenceUtils.isCameraLiveViewportEnabled(context)) {
-                cameraSource.start(surfaceView.getHolder());
-            } else {
-                cameraSource.start();
-            }
-            requestLayout();
-
-            if (overlay != null) {
-                Size size = cameraSource.getPreviewSize();
-                int min = Math.min(size.getWidth(), size.getHeight());
-                int max = Math.max(size.getWidth(), size.getHeight());
-                boolean isImageFlipped = cameraSource.getCameraFacing() == CameraSource.CAMERA_FACING_FRONT;
-                if (isPortraitMode()) {
-                    // Swap width and height sizes when in portrait, since it will be rotated by 90 degrees.
-                    // The camera preview and the image being processed have the same size.
-                    overlay.setImageSourceInfo(min, max, isImageFlipped);
-                } else {
-                    overlay.setImageSourceInfo(max, min, isImageFlipped);
-                }
-                overlay.clear();
-            }
-            startRequested = false;
-        }
-    }
-
-    private class SurfaceCallback implements SurfaceHolder.Callback {
-        @Override
-        public void surfaceCreated(SurfaceHolder surface) {
-            surfaceAvailable = true;
-            try {
-                startIfReady();
-            } catch (IOException e) {
-                Log.e(TAG, "Could not start camera source.", e);
-            }
-        }
-
-        @Override
-        public void surfaceDestroyed(SurfaceHolder surface) {
-            surfaceAvailable = false;
-        }
-
-        @Override
-        public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) {
-        }
-    }
-
-    @Override
-    protected void onLayout(boolean changed, int left, int top, int right, int bottom) {
-        int width = 320;
-        int height = 240;
-        if (cameraSource != null) {
-            Size size = cameraSource.getPreviewSize();
-            if (size != null) {
-                width = size.getWidth();
-                height = size.getHeight();
-            }
-        }
-
-        // Swap width and height sizes when in portrait, since it will be rotated 90 degrees
-        if (isPortraitMode()) {
-            int tmp = width;
-            width = height;
-            height = tmp;
-        }
-
-        final int layoutWidth = right - left;
-        final int layoutHeight = bottom - top;
-
-        // Computes height and width for potentially doing fit width.
-        int childWidth = layoutWidth;
-        int childHeight = (int) (((float) layoutWidth / (float) width) * height);
-
-        // If height is too tall using fit width, does fit height instead.
-        if (childHeight > layoutHeight) {
-            childHeight = layoutHeight;
-            childWidth = (int) (((float) layoutHeight / (float) height) * width);
-        }
-
-        for (int i = 0; i < getChildCount(); ++i) {
-            getChildAt(i).layout(0, 0, childWidth, childHeight);
-            Log.d(TAG, "Assigned view: " + i);
-        }
-
-        try {
-            startIfReady();
-        } catch (IOException e) {
-            Log.e(TAG, "Could not start camera source.", e);
-        }
-    }
-
-    private boolean isPortraitMode() {
-        int orientation = context.getResources().getConfiguration().orientation;
-        if (orientation == Configuration.ORIENTATION_LANDSCAPE) {
-            return false;
-        }
-        if (orientation == Configuration.ORIENTATION_PORTRAIT) {
-            return true;
-        }
-
-        Log.d(TAG, "isPortraitMode returning false by default");
-        return false;
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.content.Context;
+import android.content.res.Configuration;
+import android.util.AttributeSet;
+import android.util.Log;
+import android.view.SurfaceHolder;
+import android.view.SurfaceView;
+import android.view.ViewGroup;
+
+import com.google.android.gms.common.images.Size;
+import com.google.mlkit.vision.demo.preference.PreferenceUtils;
+
+import java.io.IOException;
+
+/**
+ * Preview the camera image in the screen.
+ */
+public class CameraSourcePreview extends ViewGroup {
+    private static final String TAG = "MIDemoApp:Preview";
+
+    private final Context context;
+    private final SurfaceView surfaceView;
+    private boolean startRequested;
+    private boolean surfaceAvailable;
+    private CameraSource cameraSource;
+
+    private GraphicOverlay overlay;
+
+    public CameraSourcePreview(Context context, AttributeSet attrs) {
+        super(context, attrs);
+        this.context = context;
+        startRequested = false;
+        surfaceAvailable = false;
+
+        surfaceView = new SurfaceView(context);
+        surfaceView.getHolder().addCallback(new SurfaceCallback());
+        addView(surfaceView);
+    }
+
+    private void start(CameraSource cameraSource) throws IOException {
+        if (cameraSource == null) {
+            stop();
+        }
+
+        this.cameraSource = cameraSource;
+
+        if (this.cameraSource != null) {
+            startRequested = true;
+            startIfReady();
+        }
+    }
+
+    public void start(CameraSource cameraSource, GraphicOverlay overlay) throws IOException {
+        this.overlay = overlay;
+        start(cameraSource);
+    }
+
+    public void stop() {
+        if (cameraSource != null) {
+            cameraSource.stop();
+        }
+    }
+
+    public void release() {
+        if (cameraSource != null) {
+            cameraSource.release();
+            cameraSource = null;
+        }
+        surfaceView.getHolder().getSurface().release();
+    }
+
+    private void startIfReady() throws IOException, SecurityException {
+        if (startRequested && surfaceAvailable) {
+            if (PreferenceUtils.isCameraLiveViewportEnabled(context)) {
+                cameraSource.start(surfaceView.getHolder());
+            } else {
+                cameraSource.start();
+            }
+            requestLayout();
+
+            if (overlay != null) {
+                Size size = cameraSource.getPreviewSize();
+                int min = Math.min(size.getWidth(), size.getHeight());
+                int max = Math.max(size.getWidth(), size.getHeight());
+                boolean isImageFlipped = cameraSource.getCameraFacing() == CameraSource.CAMERA_FACING_FRONT;
+                isImageFlipped=false;//chandler
+                if (isPortraitMode()) {
+                    // Swap width and height sizes when in portrait, since it will be rotated by 90 degrees.
+                    // The camera preview and the image being processed have the same size.
+                    overlay.setImageSourceInfo(min, max, isImageFlipped);
+                } else {
+                    overlay.setImageSourceInfo(max, min, isImageFlipped);
+                }
+                overlay.clear();
+            }
+            startRequested = false;
+        }
+    }
+
+    private class SurfaceCallback implements SurfaceHolder.Callback {
+        @Override
+        public void surfaceCreated(SurfaceHolder surface) {
+            surfaceAvailable = true;
+            try {
+                startIfReady();
+            } catch (IOException e) {
+                Log.e(TAG, "Could not start camera source.", e);
+            }
+        }
+
+        @Override
+        public void surfaceDestroyed(SurfaceHolder surface) {
+            surfaceAvailable = false;
+        }
+
+        @Override
+        public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) {
+        }
+    }
+
+    @Override
+    protected void onLayout(boolean changed, int left, int top, int right, int bottom) {
+        int width = 320;
+        int height = 240;
+        if (cameraSource != null) {
+            Size size = cameraSource.getPreviewSize();
+            if (size != null) {
+                width = size.getWidth();
+                height = size.getHeight();
+            }
+        }
+
+        // Swap width and height sizes when in portrait, since it will be rotated 90 degrees
+        if (isPortraitMode()) {
+            int tmp = width;
+            width = height;
+            height = tmp;
+        }
+
+        final int layoutWidth = right - left;
+        final int layoutHeight = bottom - top;
+
+        // Computes height and width for potentially doing fit width.
+        int childWidth = layoutWidth;
+        int childHeight = (int) (((float) layoutWidth / (float) width) * height);
+
+        // If height is too tall using fit width, does fit height instead.
+        if (childHeight > layoutHeight) {
+            childHeight = layoutHeight;
+            childWidth = (int) (((float) layoutHeight / (float) height) * width);
+        }
+
+        for (int i = 0; i < getChildCount(); ++i) {
+            getChildAt(i).layout(0, 0, childWidth, childHeight);
+            Log.d(TAG, "Assigned view: " + i);
+        }
+
+        try {
+            startIfReady();
+        } catch (IOException e) {
+            Log.e(TAG, "Could not start camera source.", e);
+        }
+    }
+
+    private boolean isPortraitMode() {
+        int orientation = context.getResources().getConfiguration().orientation;
+        if (orientation == Configuration.ORIENTATION_LANDSCAPE) {
+            return false;
+        }
+        if (orientation == Configuration.ORIENTATION_PORTRAIT) {
+            return true;
+        }
+
+        Log.d(TAG, "isPortraitMode returning false by default");
+        return false;
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraXLivePreviewActivity.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraXLivePreviewActivity.java
index 2c7bdca..f663228 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraXLivePreviewActivity.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraXLivePreviewActivity.java
@@ -1,480 +1,480 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import androidx.lifecycle.ViewModelProvider;
-import androidx.lifecycle.ViewModelProvider.AndroidViewModelFactory;
-
-import android.content.Context;
-import android.content.Intent;
-import android.content.pm.PackageInfo;
-import android.content.pm.PackageManager;
-import android.os.Build.VERSION;
-import android.os.Build.VERSION_CODES;
-import android.os.Bundle;
-
-import androidx.core.app.ActivityCompat;
-import androidx.core.app.ActivityCompat.OnRequestPermissionsResultCallback;
-import androidx.core.content.ContextCompat;
-import androidx.appcompat.app.AppCompatActivity;
-
-import android.util.Log;
-import android.util.Size;
-import android.view.Menu;
-import android.view.MenuItem;
-import android.view.View;
-import android.widget.AdapterView;
-import android.widget.AdapterView.OnItemSelectedListener;
-import android.widget.ArrayAdapter;
-import android.widget.CompoundButton;
-import android.widget.ImageView;
-import android.widget.Spinner;
-import android.widget.Toast;
-import android.widget.ToggleButton;
-
-import androidx.annotation.NonNull;
-import androidx.annotation.Nullable;
-import androidx.annotation.RequiresApi;
-import androidx.camera.core.CameraInfoUnavailableException;
-import androidx.camera.core.CameraSelector;
-import androidx.camera.core.ImageAnalysis;
-import androidx.camera.core.Preview;
-import androidx.camera.lifecycle.ProcessCameraProvider;
-import androidx.camera.view.PreviewView;
-
-import com.google.android.gms.common.annotation.KeepName;
-import com.google.mlkit.common.MlKitException;
-import com.google.mlkit.common.model.LocalModel;
-import com.google.mlkit.vision.demo.automl.AutoMLImageLabelerProcessor;
-import com.google.mlkit.vision.demo.barcodescanner.BarcodeScannerProcessor;
-import com.google.mlkit.vision.demo.facedetector.FaceDetectorProcessor;
-import com.google.mlkit.vision.demo.labeldetector.LabelDetectorProcessor;
-import com.google.mlkit.vision.demo.objectdetector.ObjectDetectorProcessor;
-import com.google.mlkit.vision.demo.preference.PreferenceUtils;
-import com.google.mlkit.vision.demo.preference.SettingsActivity;
-import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource;
-import com.google.mlkit.vision.demo.textdetector.TextRecognitionProcessor;
-import com.google.mlkit.vision.face.FaceDetectorOptions;
-import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions;
-import com.google.mlkit.vision.label.defaults.ImageLabelerOptions;
-import com.google.mlkit.vision.objects.custom.CustomObjectDetectorOptions;
-import com.google.mlkit.vision.objects.defaults.ObjectDetectorOptions;
-
-import java.util.ArrayList;
-import java.util.List;
-
-/**
- * Live preview demo app for ML Kit APIs using CameraX.
- */
-@KeepName
-@RequiresApi(VERSION_CODES.LOLLIPOP)
-public final class CameraXLivePreviewActivity extends AppCompatActivity
-        implements OnRequestPermissionsResultCallback,
-        OnItemSelectedListener,
-        CompoundButton.OnCheckedChangeListener {
-    private static final String TAG = "CameraXLivePreview";
-    private static final int PERMISSION_REQUESTS = 1;
-
-    private static final String OBJECT_DETECTION = "Object Detection";
-    private static final String OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Bird)";
-    private static final String FACE_DETECTION = "Face Detection";
-    private static final String TEXT_RECOGNITION = "Text Recognition";
-    private static final String BARCODE_SCANNING = "Barcode Scanning";
-    private static final String IMAGE_LABELING = "Image Labeling";
-    private static final String IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Bird)";
-    private static final String AUTOML_LABELING = "AutoML Image Labeling";
-
-    private static final String STATE_SELECTED_MODEL = "selected_model";
-    private static final String STATE_LENS_FACING = "lens_facing";
-
-    private PreviewView previewView;
-    private GraphicOverlay graphicOverlay;
-
-    @Nullable
-    private ProcessCameraProvider cameraProvider;
-    @Nullable
-    private Preview previewUseCase;
-    @Nullable
-    private ImageAnalysis analysisUseCase;
-    @Nullable
-    private VisionImageProcessor imageProcessor;
-    private boolean needUpdateGraphicOverlayImageSourceInfo;
-
-    private String selectedModel = OBJECT_DETECTION;
-    private int lensFacing = CameraSelector.LENS_FACING_BACK;
-    private CameraSelector cameraSelector;
-
-    @Override
-    protected void onCreate(Bundle savedInstanceState) {
-        super.onCreate(savedInstanceState);
-        Log.d(TAG, "onCreate");
-
-        if (VERSION.SDK_INT < VERSION_CODES.LOLLIPOP) {
-            Toast.makeText(
-                    getApplicationContext(),
-                    "CameraX is only supported on SDK version >=21. Current SDK version is "
-                            + VERSION.SDK_INT,
-                    Toast.LENGTH_LONG)
-                    .show();
-            return;
-        }
-
-        if (savedInstanceState != null) {
-            selectedModel = savedInstanceState.getString(STATE_SELECTED_MODEL, OBJECT_DETECTION);
-            lensFacing = savedInstanceState.getInt(STATE_LENS_FACING, CameraSelector.LENS_FACING_BACK);
-        }
-        cameraSelector = new CameraSelector.Builder().requireLensFacing(lensFacing).build();
-
-        setContentView(R.layout.activity_camerax_live_preview);
-        previewView = findViewById(R.id.preview_view);
-        if (previewView == null) {
-            Log.d(TAG, "previewView is null");
-        }
-        graphicOverlay = findViewById(R.id.graphic_overlay);
-        if (graphicOverlay == null) {
-            Log.d(TAG, "graphicOverlay is null");
-        }
-
-        Spinner spinner = findViewById(R.id.spinner);
-        List<String> options = new ArrayList<>();
-        options.add(OBJECT_DETECTION);
-        options.add(OBJECT_DETECTION_CUSTOM);
-        options.add(FACE_DETECTION);
-        options.add(TEXT_RECOGNITION);
-        options.add(BARCODE_SCANNING);
-        options.add(IMAGE_LABELING);
-        options.add(IMAGE_LABELING_CUSTOM);
-        options.add(AUTOML_LABELING);
-        // Creating adapter for spinner
-        ArrayAdapter<String> dataAdapter = new ArrayAdapter<>(this, R.layout.spinner_style, options);
-        // Drop down layout style - list view with radio button
-        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
-        // attaching data adapter to spinner
-        spinner.setAdapter(dataAdapter);
-        spinner.setOnItemSelectedListener(this);
-
-        ToggleButton facingSwitch = findViewById(R.id.facing_switch);
-        facingSwitch.setOnCheckedChangeListener(this);
-
-        new ViewModelProvider(this, AndroidViewModelFactory.getInstance(getApplication()))
-                .get(CameraXViewModel.class)
-                .getProcessCameraProvider()
-                .observe(
-                        this,
-                        provider -> {
-                            cameraProvider = provider;
-                            if (allPermissionsGranted()) {
-                                bindAllCameraUseCases();
-                            }
-                        });
-
-        ImageView settingsButton = findViewById(R.id.settings_button);
-        settingsButton.setOnClickListener(
-                v -> {
-                    Intent intent = new Intent(getApplicationContext(), SettingsActivity.class);
-                    intent.putExtra(
-                            SettingsActivity.EXTRA_LAUNCH_SOURCE,
-                            SettingsActivity.LaunchSource.CAMERAX_LIVE_PREVIEW);
-                    startActivity(intent);
-                });
-
-        if (!allPermissionsGranted()) {
-            getRuntimePermissions();
-        }
-    }
-
-    @Override
-    protected void onSaveInstanceState(@NonNull Bundle bundle) {
-        super.onSaveInstanceState(bundle);
-        bundle.putString(STATE_SELECTED_MODEL, selectedModel);
-        bundle.putInt(STATE_LENS_FACING, lensFacing);
-    }
-
-    @Override
-    public synchronized void onItemSelected(AdapterView<?> parent, View view, int pos, long id) {
-        // An item was selected. You can retrieve the selected item using
-        // parent.getItemAtPosition(pos)
-        selectedModel = parent.getItemAtPosition(pos).toString();
-        Log.d(TAG, "Selected model: " + selectedModel);
-        bindAnalysisUseCase();
-    }
-
-    @Override
-    public void onNothingSelected(AdapterView<?> parent) {
-        // Do nothing.
-    }
-
-    @Override
-    public void onCheckedChanged(CompoundButton buttonView, boolean isChecked) {
-        Log.d(TAG, "Set facing");
-        if (cameraProvider == null) {
-            return;
-        }
-
-        int newLensFacing =
-                lensFacing == CameraSelector.LENS_FACING_FRONT
-                        ? CameraSelector.LENS_FACING_BACK
-                        : CameraSelector.LENS_FACING_FRONT;
-        CameraSelector newCameraSelector =
-                new CameraSelector.Builder().requireLensFacing(newLensFacing).build();
-        try {
-            if (cameraProvider.hasCamera(newCameraSelector)) {
-                lensFacing = newLensFacing;
-                cameraSelector = newCameraSelector;
-                bindAllCameraUseCases();
-                return;
-            }
-        } catch (CameraInfoUnavailableException e) {
-            // Falls through
-        }
-        Toast.makeText(
-                getApplicationContext(),
-                "This device does not have lens with facing: " + newLensFacing,
-                Toast.LENGTH_SHORT)
-                .show();
-    }
-
-    @Override
-    public boolean onCreateOptionsMenu(Menu menu) {
-        getMenuInflater().inflate(R.menu.live_preview_menu, menu);
-        return true;
-    }
-
-    @Override
-    public boolean onOptionsItemSelected(MenuItem item) {
-        if (item.getItemId() == R.id.settings) {
-            Intent intent = new Intent(this, SettingsActivity.class);
-            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE, LaunchSource.CAMERAX_LIVE_PREVIEW);
-            startActivity(intent);
-            return true;
-        }
-
-        return super.onOptionsItemSelected(item);
-    }
-
-    @Override
-    public void onResume() {
-        super.onResume();
-        bindAllCameraUseCases();
-    }
-
-    @Override
-    protected void onPause() {
-        super.onPause();
-        if (imageProcessor != null) {
-            imageProcessor.stop();
-        }
-    }
-
-    @Override
-    public void onDestroy() {
-        super.onDestroy();
-        if (imageProcessor != null) {
-            imageProcessor.stop();
-        }
-    }
-
-    private void bindAllCameraUseCases() {
-        bindPreviewUseCase();
-        bindAnalysisUseCase();
-    }
-
-    private void bindPreviewUseCase() {
-        if (!PreferenceUtils.isCameraLiveViewportEnabled(this)) {
-            return;
-        }
-        if (cameraProvider == null) {
-            return;
-        }
-        if (previewUseCase != null) {
-            cameraProvider.unbind(previewUseCase);
-        }
-
-        previewUseCase = new Preview.Builder().build();
-        previewUseCase.setSurfaceProvider(previewView.createSurfaceProvider());
-        cameraProvider.bindToLifecycle(/* lifecycleOwner= */ this, cameraSelector, previewUseCase);
-    }
-
-    private void bindAnalysisUseCase() {
-        if (cameraProvider == null) {
-            return;
-        }
-        if (analysisUseCase != null) {
-            cameraProvider.unbind(analysisUseCase);
-        }
-        if (imageProcessor != null) {
-            imageProcessor.stop();
-        }
-
-        try {
-            switch (selectedModel) {
-                case OBJECT_DETECTION:
-                    Log.i(TAG, "Using Object Detector Processor");
-                    ObjectDetectorOptions objectDetectorOptions =
-                            PreferenceUtils.getObjectDetectorOptionsForLivePreview(this);
-                    imageProcessor = new ObjectDetectorProcessor(this, objectDetectorOptions);
-                    break;
-                case OBJECT_DETECTION_CUSTOM:
-                    Log.i(TAG, "Using Custom Object Detector (Bird) Processor");
-                    LocalModel localModel =
-                            new LocalModel.Builder()
-                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
-                                    .build();
-                    CustomObjectDetectorOptions customObjectDetectorOptions =
-                            PreferenceUtils.getCustomObjectDetectorOptionsForLivePreview(this, localModel);
-                    imageProcessor = new ObjectDetectorProcessor(this, customObjectDetectorOptions);
-                    break;
-                case TEXT_RECOGNITION:
-                    Log.i(TAG, "Using on-device Text recognition Processor");
-                    imageProcessor = new TextRecognitionProcessor(this);
-                    break;
-                case FACE_DETECTION:
-                    Log.i(TAG, "Using Face Detector Processor");
-                    FaceDetectorOptions faceDetectorOptions =
-                            PreferenceUtils.getFaceDetectorOptionsForLivePreview(this);
-                    imageProcessor = new FaceDetectorProcessor(this, faceDetectorOptions);
-                    break;
-                case BARCODE_SCANNING:
-                    Log.i(TAG, "Using Barcode Detector Processor");
-                    imageProcessor = new BarcodeScannerProcessor(this);
-                    break;
-                case IMAGE_LABELING:
-                    Log.i(TAG, "Using Image Label Detector Processor");
-                    imageProcessor = new LabelDetectorProcessor(this, ImageLabelerOptions.DEFAULT_OPTIONS);
-                    break;
-                case IMAGE_LABELING_CUSTOM:
-                    Log.i(TAG, "Using Custom Image Label (Bird) Detector Processor");
-                    LocalModel localClassifier =
-                            new LocalModel.Builder()
-                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
-                                    .build();
-                    CustomImageLabelerOptions customImageLabelerOptions =
-                            new CustomImageLabelerOptions.Builder(localClassifier).build();
-                    imageProcessor = new LabelDetectorProcessor(this, customImageLabelerOptions);
-                    break;
-                case AUTOML_LABELING:
-                    imageProcessor = new AutoMLImageLabelerProcessor(this);
-                    break;
-                default:
-                    throw new IllegalStateException("Invalid model name");
-            }
-        } catch (Exception e) {
-            Log.e(TAG, "Can not create image processor: " + selectedModel, e);
-            Toast.makeText(
-                    getApplicationContext(),
-                    "Can not create image processor: " + e.getLocalizedMessage(),
-                    Toast.LENGTH_LONG)
-                    .show();
-            return;
-        }
-
-        ImageAnalysis.Builder builder = new ImageAnalysis.Builder();
-        Size targetAnalysisSize = PreferenceUtils.getCameraXTargetAnalysisSize(this);
-        if (targetAnalysisSize != null) {
-            builder.setTargetResolution(targetAnalysisSize);
-        }
-        analysisUseCase = builder.build();
-
-        needUpdateGraphicOverlayImageSourceInfo = true;
-        analysisUseCase.setAnalyzer(
-                // imageProcessor.processImageProxy will use another thread to run the detection underneath,
-                // thus we can just runs the analyzer itself on main thread.
-                ContextCompat.getMainExecutor(this),
-                imageProxy -> {
-                    if (needUpdateGraphicOverlayImageSourceInfo) {
-                        boolean isImageFlipped = lensFacing == CameraSelector.LENS_FACING_FRONT;
-                        int rotationDegrees = imageProxy.getImageInfo().getRotationDegrees();
-                        if (rotationDegrees == 0 || rotationDegrees == 180) {
-                            graphicOverlay.setImageSourceInfo(
-                                    imageProxy.getWidth(), imageProxy.getHeight(), isImageFlipped);
-                        } else {
-                            graphicOverlay.setImageSourceInfo(
-                                    imageProxy.getHeight(), imageProxy.getWidth(), isImageFlipped);
-                        }
-                        needUpdateGraphicOverlayImageSourceInfo = false;
-                    }
-                    try {
-                        imageProcessor.processImageProxy(imageProxy, graphicOverlay);
-                    } catch (MlKitException e) {
-                        Log.e(TAG, "Failed to process image. Error: " + e.getLocalizedMessage());
-                        Toast.makeText(getApplicationContext(), e.getLocalizedMessage(), Toast.LENGTH_SHORT)
-                                .show();
-                    }
-                });
-
-        cameraProvider.bindToLifecycle(/* lifecycleOwner= */ this, cameraSelector, analysisUseCase);
-    }
-
-    private String[] getRequiredPermissions() {
-        try {
-            PackageInfo info =
-                    this.getPackageManager()
-                            .getPackageInfo(this.getPackageName(), PackageManager.GET_PERMISSIONS);
-            String[] ps = info.requestedPermissions;
-            if (ps != null && ps.length > 0) {
-                return ps;
-            } else {
-                return new String[0];
-            }
-        } catch (Exception e) {
-            return new String[0];
-        }
-    }
-
-    private boolean allPermissionsGranted() {
-        for (String permission : getRequiredPermissions()) {
-            if (!isPermissionGranted(this, permission)) {
-                return false;
-            }
-        }
-        return true;
-    }
-
-    private void getRuntimePermissions() {
-        List<String> allNeededPermissions = new ArrayList<>();
-        for (String permission : getRequiredPermissions()) {
-            if (!isPermissionGranted(this, permission)) {
-                allNeededPermissions.add(permission);
-            }
-        }
-
-        if (!allNeededPermissions.isEmpty()) {
-            ActivityCompat.requestPermissions(
-                    this, allNeededPermissions.toArray(new String[0]), PERMISSION_REQUESTS);
-        }
-    }
-
-    @Override
-    public void onRequestPermissionsResult(
-            int requestCode, String[] permissions, int[] grantResults) {
-        Log.i(TAG, "Permission granted!");
-        if (allPermissionsGranted()) {
-            bindAllCameraUseCases();
-        }
-        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
-    }
-
-    private static boolean isPermissionGranted(Context context, String permission) {
-        if (ContextCompat.checkSelfPermission(context, permission)
-                == PackageManager.PERMISSION_GRANTED) {
-            Log.i(TAG, "Permission granted: " + permission);
-            return true;
-        }
-        Log.i(TAG, "Permission NOT granted: " + permission);
-        return false;
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import androidx.lifecycle.ViewModelProvider;
+import androidx.lifecycle.ViewModelProvider.AndroidViewModelFactory;
+
+import android.content.Context;
+import android.content.Intent;
+import android.content.pm.PackageInfo;
+import android.content.pm.PackageManager;
+import android.os.Build.VERSION;
+import android.os.Build.VERSION_CODES;
+import android.os.Bundle;
+
+import androidx.core.app.ActivityCompat;
+import androidx.core.app.ActivityCompat.OnRequestPermissionsResultCallback;
+import androidx.core.content.ContextCompat;
+import androidx.appcompat.app.AppCompatActivity;
+
+import android.util.Log;
+import android.util.Size;
+import android.view.Menu;
+import android.view.MenuItem;
+import android.view.View;
+import android.widget.AdapterView;
+import android.widget.AdapterView.OnItemSelectedListener;
+import android.widget.ArrayAdapter;
+import android.widget.CompoundButton;
+import android.widget.ImageView;
+import android.widget.Spinner;
+import android.widget.Toast;
+import android.widget.ToggleButton;
+
+import androidx.annotation.NonNull;
+import androidx.annotation.Nullable;
+import androidx.annotation.RequiresApi;
+import androidx.camera.core.CameraInfoUnavailableException;
+import androidx.camera.core.CameraSelector;
+import androidx.camera.core.ImageAnalysis;
+import androidx.camera.core.Preview;
+import androidx.camera.lifecycle.ProcessCameraProvider;
+import androidx.camera.view.PreviewView;
+
+import com.google.android.gms.common.annotation.KeepName;
+import com.google.mlkit.common.MlKitException;
+import com.google.mlkit.common.model.LocalModel;
+import com.google.mlkit.vision.demo.automl.AutoMLImageLabelerProcessor;
+import com.google.mlkit.vision.demo.barcodescanner.BarcodeScannerProcessor;
+import com.google.mlkit.vision.demo.facedetector.FaceDetectorProcessor;
+import com.google.mlkit.vision.demo.labeldetector.LabelDetectorProcessor;
+import com.google.mlkit.vision.demo.objectdetector.ObjectDetectorProcessor;
+import com.google.mlkit.vision.demo.preference.PreferenceUtils;
+import com.google.mlkit.vision.demo.preference.SettingsActivity;
+import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource;
+import com.google.mlkit.vision.demo.textdetector.TextRecognitionProcessor;
+import com.google.mlkit.vision.face.FaceDetectorOptions;
+import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions;
+import com.google.mlkit.vision.label.defaults.ImageLabelerOptions;
+import com.google.mlkit.vision.objects.custom.CustomObjectDetectorOptions;
+import com.google.mlkit.vision.objects.defaults.ObjectDetectorOptions;
+
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * Live preview demo app for ML Kit APIs using CameraX.
+ */
+@KeepName
+@RequiresApi(VERSION_CODES.LOLLIPOP)
+public final class CameraXLivePreviewActivity extends AppCompatActivity
+        implements OnRequestPermissionsResultCallback,
+        OnItemSelectedListener,
+        CompoundButton.OnCheckedChangeListener {
+    private static final String TAG = "CameraXLivePreview";
+    private static final int PERMISSION_REQUESTS = 1;
+
+    private static final String OBJECT_DETECTION = "Object Detection";
+    private static final String OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Bird)";
+    private static final String FACE_DETECTION = "Face Detection";
+    private static final String TEXT_RECOGNITION = "Text Recognition";
+    private static final String BARCODE_SCANNING = "Barcode Scanning";
+    private static final String IMAGE_LABELING = "Image Labeling";
+    private static final String IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Bird)";
+    private static final String AUTOML_LABELING = "AutoML Image Labeling";
+
+    private static final String STATE_SELECTED_MODEL = "selected_model";
+    private static final String STATE_LENS_FACING = "lens_facing";
+
+    private PreviewView previewView;
+    private GraphicOverlay graphicOverlay;
+
+    @Nullable
+    private ProcessCameraProvider cameraProvider;
+    @Nullable
+    private Preview previewUseCase;
+    @Nullable
+    private ImageAnalysis analysisUseCase;
+    @Nullable
+    private VisionImageProcessor imageProcessor;
+    private boolean needUpdateGraphicOverlayImageSourceInfo;
+
+    private String selectedModel = OBJECT_DETECTION;
+    private int lensFacing = CameraSelector.LENS_FACING_BACK;
+    private CameraSelector cameraSelector;
+
+    @Override
+    protected void onCreate(Bundle savedInstanceState) {
+        super.onCreate(savedInstanceState);
+        Log.d(TAG, "onCreate");
+
+        if (VERSION.SDK_INT < VERSION_CODES.LOLLIPOP) {
+            Toast.makeText(
+                    getApplicationContext(),
+                    "CameraX is only supported on SDK version >=21. Current SDK version is "
+                            + VERSION.SDK_INT,
+                    Toast.LENGTH_LONG)
+                    .show();
+            return;
+        }
+
+        if (savedInstanceState != null) {
+            selectedModel = savedInstanceState.getString(STATE_SELECTED_MODEL, OBJECT_DETECTION);
+            lensFacing = savedInstanceState.getInt(STATE_LENS_FACING, CameraSelector.LENS_FACING_BACK);
+        }
+        cameraSelector = new CameraSelector.Builder().requireLensFacing(lensFacing).build();
+
+        setContentView(R.layout.activity_camerax_live_preview);
+        previewView = findViewById(R.id.preview_view);
+        if (previewView == null) {
+            Log.d(TAG, "previewView is null");
+        }
+        graphicOverlay = findViewById(R.id.graphic_overlay);
+        if (graphicOverlay == null) {
+            Log.d(TAG, "graphicOverlay is null");
+        }
+
+        Spinner spinner = findViewById(R.id.spinner);
+        List<String> options = new ArrayList<>();
+        options.add(OBJECT_DETECTION);
+        options.add(OBJECT_DETECTION_CUSTOM);
+        options.add(FACE_DETECTION);
+        options.add(TEXT_RECOGNITION);
+        options.add(BARCODE_SCANNING);
+        options.add(IMAGE_LABELING);
+        options.add(IMAGE_LABELING_CUSTOM);
+        options.add(AUTOML_LABELING);
+        // Creating adapter for spinner
+        ArrayAdapter<String> dataAdapter = new ArrayAdapter<>(this, R.layout.spinner_style, options);
+        // Drop down layout style - list view with radio button
+        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
+        // attaching data adapter to spinner
+        spinner.setAdapter(dataAdapter);
+        spinner.setOnItemSelectedListener(this);
+
+        ToggleButton facingSwitch = findViewById(R.id.facing_switch);
+        facingSwitch.setOnCheckedChangeListener(this);
+
+        new ViewModelProvider(this, AndroidViewModelFactory.getInstance(getApplication()))
+                .get(CameraXViewModel.class)
+                .getProcessCameraProvider()
+                .observe(
+                        this,
+                        provider -> {
+                            cameraProvider = provider;
+                            if (allPermissionsGranted()) {
+                                bindAllCameraUseCases();
+                            }
+                        });
+
+        ImageView settingsButton = findViewById(R.id.settings_button);
+        settingsButton.setOnClickListener(
+                v -> {
+                    Intent intent = new Intent(getApplicationContext(), SettingsActivity.class);
+                    intent.putExtra(
+                            SettingsActivity.EXTRA_LAUNCH_SOURCE,
+                            SettingsActivity.LaunchSource.CAMERAX_LIVE_PREVIEW);
+                    startActivity(intent);
+                });
+
+        if (!allPermissionsGranted()) {
+            getRuntimePermissions();
+        }
+    }
+
+    @Override
+    protected void onSaveInstanceState(@NonNull Bundle bundle) {
+        super.onSaveInstanceState(bundle);
+        bundle.putString(STATE_SELECTED_MODEL, selectedModel);
+        bundle.putInt(STATE_LENS_FACING, lensFacing);
+    }
+
+    @Override
+    public synchronized void onItemSelected(AdapterView<?> parent, View view, int pos, long id) {
+        // An item was selected. You can retrieve the selected item using
+        // parent.getItemAtPosition(pos)
+        selectedModel = parent.getItemAtPosition(pos).toString();
+        Log.d(TAG, "Selected model: " + selectedModel);
+        bindAnalysisUseCase();
+    }
+
+    @Override
+    public void onNothingSelected(AdapterView<?> parent) {
+        // Do nothing.
+    }
+
+    @Override
+    public void onCheckedChanged(CompoundButton buttonView, boolean isChecked) {
+        Log.d(TAG, "Set facing");
+        if (cameraProvider == null) {
+            return;
+        }
+
+        int newLensFacing =
+                lensFacing == CameraSelector.LENS_FACING_FRONT
+                        ? CameraSelector.LENS_FACING_BACK
+                        : CameraSelector.LENS_FACING_FRONT;
+        CameraSelector newCameraSelector =
+                new CameraSelector.Builder().requireLensFacing(newLensFacing).build();
+        try {
+            if (cameraProvider.hasCamera(newCameraSelector)) {
+                lensFacing = newLensFacing;
+                cameraSelector = newCameraSelector;
+                bindAllCameraUseCases();
+                return;
+            }
+        } catch (CameraInfoUnavailableException e) {
+            // Falls through
+        }
+        Toast.makeText(
+                getApplicationContext(),
+                "This device does not have lens with facing: " + newLensFacing,
+                Toast.LENGTH_SHORT)
+                .show();
+    }
+
+    @Override
+    public boolean onCreateOptionsMenu(Menu menu) {
+        getMenuInflater().inflate(R.menu.live_preview_menu, menu);
+        return true;
+    }
+
+    @Override
+    public boolean onOptionsItemSelected(MenuItem item) {
+        if (item.getItemId() == R.id.settings) {
+            Intent intent = new Intent(this, SettingsActivity.class);
+            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE, LaunchSource.CAMERAX_LIVE_PREVIEW);
+            startActivity(intent);
+            return true;
+        }
+
+        return super.onOptionsItemSelected(item);
+    }
+
+    @Override
+    public void onResume() {
+        super.onResume();
+        bindAllCameraUseCases();
+    }
+
+    @Override
+    protected void onPause() {
+        super.onPause();
+        if (imageProcessor != null) {
+            imageProcessor.stop();
+        }
+    }
+
+    @Override
+    public void onDestroy() {
+        super.onDestroy();
+        if (imageProcessor != null) {
+            imageProcessor.stop();
+        }
+    }
+
+    private void bindAllCameraUseCases() {
+        bindPreviewUseCase();
+        bindAnalysisUseCase();
+    }
+
+    private void bindPreviewUseCase() {
+        if (!PreferenceUtils.isCameraLiveViewportEnabled(this)) {
+            return;
+        }
+        if (cameraProvider == null) {
+            return;
+        }
+        if (previewUseCase != null) {
+            cameraProvider.unbind(previewUseCase);
+        }
+
+        previewUseCase = new Preview.Builder().build();
+        previewUseCase.setSurfaceProvider(previewView.createSurfaceProvider());
+        cameraProvider.bindToLifecycle(/* lifecycleOwner= */ this, cameraSelector, previewUseCase);
+    }
+
+    private void bindAnalysisUseCase() {
+        if (cameraProvider == null) {
+            return;
+        }
+        if (analysisUseCase != null) {
+            cameraProvider.unbind(analysisUseCase);
+        }
+        if (imageProcessor != null) {
+            imageProcessor.stop();
+        }
+
+        try {
+            switch (selectedModel) {
+                case OBJECT_DETECTION:
+                    Log.i(TAG, "Using Object Detector Processor");
+                    ObjectDetectorOptions objectDetectorOptions =
+                            PreferenceUtils.getObjectDetectorOptionsForLivePreview(this);
+                    imageProcessor = new ObjectDetectorProcessor(this, objectDetectorOptions);
+                    break;
+                case OBJECT_DETECTION_CUSTOM:
+                    Log.i(TAG, "Using Custom Object Detector (Bird) Processor");
+                    LocalModel localModel =
+                            new LocalModel.Builder()
+                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
+                                    .build();
+                    CustomObjectDetectorOptions customObjectDetectorOptions =
+                            PreferenceUtils.getCustomObjectDetectorOptionsForLivePreview(this, localModel);
+                    imageProcessor = new ObjectDetectorProcessor(this, customObjectDetectorOptions);
+                    break;
+                case TEXT_RECOGNITION:
+                    Log.i(TAG, "Using on-device Text recognition Processor");
+                    imageProcessor = new TextRecognitionProcessor(this);
+                    break;
+                case FACE_DETECTION:
+                    Log.i(TAG, "Using Face Detector Processor");
+                    FaceDetectorOptions faceDetectorOptions =
+                            PreferenceUtils.getFaceDetectorOptionsForLivePreview(this);
+                    imageProcessor = new FaceDetectorProcessor(this, faceDetectorOptions);
+                    break;
+                case BARCODE_SCANNING:
+                    Log.i(TAG, "Using Barcode Detector Processor");
+                    imageProcessor = new BarcodeScannerProcessor(this);
+                    break;
+                case IMAGE_LABELING:
+                    Log.i(TAG, "Using Image Label Detector Processor");
+                    imageProcessor = new LabelDetectorProcessor(this, ImageLabelerOptions.DEFAULT_OPTIONS);
+                    break;
+                case IMAGE_LABELING_CUSTOM:
+                    Log.i(TAG, "Using Custom Image Label (Bird) Detector Processor");
+                    LocalModel localClassifier =
+                            new LocalModel.Builder()
+                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
+                                    .build();
+                    CustomImageLabelerOptions customImageLabelerOptions =
+                            new CustomImageLabelerOptions.Builder(localClassifier).build();
+                    imageProcessor = new LabelDetectorProcessor(this, customImageLabelerOptions);
+                    break;
+                case AUTOML_LABELING:
+                    imageProcessor = new AutoMLImageLabelerProcessor(this);
+                    break;
+                default:
+                    throw new IllegalStateException("Invalid model name");
+            }
+        } catch (Exception e) {
+            Log.e(TAG, "Can not create image processor: " + selectedModel, e);
+            Toast.makeText(
+                    getApplicationContext(),
+                    "Can not create image processor: " + e.getLocalizedMessage(),
+                    Toast.LENGTH_LONG)
+                    .show();
+            return;
+        }
+
+        ImageAnalysis.Builder builder = new ImageAnalysis.Builder();
+        Size targetAnalysisSize = PreferenceUtils.getCameraXTargetAnalysisSize(this);
+        if (targetAnalysisSize != null) {
+            builder.setTargetResolution(targetAnalysisSize);
+        }
+        analysisUseCase = builder.build();
+
+        needUpdateGraphicOverlayImageSourceInfo = true;
+        analysisUseCase.setAnalyzer(
+                // imageProcessor.processImageProxy will use another thread to run the detection underneath,
+                // thus we can just runs the analyzer itself on main thread.
+                ContextCompat.getMainExecutor(this),
+                imageProxy -> {
+                    if (needUpdateGraphicOverlayImageSourceInfo) {
+                        boolean isImageFlipped = lensFacing == CameraSelector.LENS_FACING_FRONT;
+                        int rotationDegrees = imageProxy.getImageInfo().getRotationDegrees();
+                        if (rotationDegrees == 0 || rotationDegrees == 180) {
+                            graphicOverlay.setImageSourceInfo(
+                                    imageProxy.getWidth(), imageProxy.getHeight(), isImageFlipped);
+                        } else {
+                            graphicOverlay.setImageSourceInfo(
+                                    imageProxy.getHeight(), imageProxy.getWidth(), isImageFlipped);
+                        }
+                        needUpdateGraphicOverlayImageSourceInfo = false;
+                    }
+                    try {
+                        imageProcessor.processImageProxy(imageProxy, graphicOverlay);
+                    } catch (MlKitException e) {
+                        Log.e(TAG, "Failed to process image. Error: " + e.getLocalizedMessage());
+                        Toast.makeText(getApplicationContext(), e.getLocalizedMessage(), Toast.LENGTH_SHORT)
+                                .show();
+                    }
+                });
+
+        cameraProvider.bindToLifecycle(/* lifecycleOwner= */ this, cameraSelector, analysisUseCase);
+    }
+
+    private String[] getRequiredPermissions() {
+        try {
+            PackageInfo info =
+                    this.getPackageManager()
+                            .getPackageInfo(this.getPackageName(), PackageManager.GET_PERMISSIONS);
+            String[] ps = info.requestedPermissions;
+            if (ps != null && ps.length > 0) {
+                return ps;
+            } else {
+                return new String[0];
+            }
+        } catch (Exception e) {
+            return new String[0];
+        }
+    }
+
+    private boolean allPermissionsGranted() {
+        for (String permission : getRequiredPermissions()) {
+            if (!isPermissionGranted(this, permission)) {
+                return false;
+            }
+        }
+        return true;
+    }
+
+    private void getRuntimePermissions() {
+        List<String> allNeededPermissions = new ArrayList<>();
+        for (String permission : getRequiredPermissions()) {
+            if (!isPermissionGranted(this, permission)) {
+                allNeededPermissions.add(permission);
+            }
+        }
+
+        if (!allNeededPermissions.isEmpty()) {
+            ActivityCompat.requestPermissions(
+                    this, allNeededPermissions.toArray(new String[0]), PERMISSION_REQUESTS);
+        }
+    }
+
+    @Override
+    public void onRequestPermissionsResult(
+            int requestCode, String[] permissions, int[] grantResults) {
+        Log.i(TAG, "Permission granted!");
+        if (allPermissionsGranted()) {
+            bindAllCameraUseCases();
+        }
+        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
+    }
+
+    private static boolean isPermissionGranted(Context context, String permission) {
+        if (ContextCompat.checkSelfPermission(context, permission)
+                == PackageManager.PERMISSION_GRANTED) {
+            Log.i(TAG, "Permission granted: " + permission);
+            return true;
+        }
+        Log.i(TAG, "Permission NOT granted: " + permission);
+        return false;
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraXViewModel.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraXViewModel.java
index 1e95399..186d6e0 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraXViewModel.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraXViewModel.java
@@ -1,70 +1,70 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.app.Application;
-
-import androidx.lifecycle.AndroidViewModel;
-import androidx.lifecycle.LiveData;
-import androidx.lifecycle.MutableLiveData;
-import androidx.annotation.NonNull;
-import androidx.core.content.ContextCompat;
-
-import android.util.Log;
-
-import androidx.camera.lifecycle.ProcessCameraProvider;
-
-import com.google.common.util.concurrent.ListenableFuture;
-
-import java.util.concurrent.ExecutionException;
-
-/**
- * View model for interacting with CameraX.
- */
-public final class CameraXViewModel extends AndroidViewModel {
-
-    private static final String TAG = "CameraXViewModel";
-    private MutableLiveData<ProcessCameraProvider> cameraProviderLiveData;
-
-    /**
-     * Create an instance which interacts with the camera service via the given application context.
-     */
-    public CameraXViewModel(@NonNull Application application) {
-        super(application);
-    }
-
-    public LiveData<ProcessCameraProvider> getProcessCameraProvider() {
-        if (cameraProviderLiveData == null) {
-            cameraProviderLiveData = new MutableLiveData<>();
-
-            ListenableFuture<ProcessCameraProvider> cameraProviderFuture =
-                    ProcessCameraProvider.getInstance(getApplication());
-            cameraProviderFuture.addListener(
-                    () -> {
-                        try {
-                            cameraProviderLiveData.setValue(cameraProviderFuture.get());
-                        } catch (ExecutionException | InterruptedException e) {
-                            // Handle any errors (including cancellation) here.
-                            Log.e(TAG, "Unhandled exception", e);
-                        }
-                    },
-                    ContextCompat.getMainExecutor(getApplication()));
-        }
-
-        return cameraProviderLiveData;
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.app.Application;
+
+import androidx.lifecycle.AndroidViewModel;
+import androidx.lifecycle.LiveData;
+import androidx.lifecycle.MutableLiveData;
+import androidx.annotation.NonNull;
+import androidx.core.content.ContextCompat;
+
+import android.util.Log;
+
+import androidx.camera.lifecycle.ProcessCameraProvider;
+
+import com.google.common.util.concurrent.ListenableFuture;
+
+import java.util.concurrent.ExecutionException;
+
+/**
+ * View model for interacting with CameraX.
+ */
+public final class CameraXViewModel extends AndroidViewModel {
+
+    private static final String TAG = "CameraXViewModel";
+    private MutableLiveData<ProcessCameraProvider> cameraProviderLiveData;
+
+    /**
+     * Create an instance which interacts with the camera service via the given application context.
+     */
+    public CameraXViewModel(@NonNull Application application) {
+        super(application);
+    }
+
+    public LiveData<ProcessCameraProvider> getProcessCameraProvider() {
+        if (cameraProviderLiveData == null) {
+            cameraProviderLiveData = new MutableLiveData<>();
+
+            ListenableFuture<ProcessCameraProvider> cameraProviderFuture =
+                    ProcessCameraProvider.getInstance(getApplication());
+            cameraProviderFuture.addListener(
+                    () -> {
+                        try {
+                            cameraProviderLiveData.setValue(cameraProviderFuture.get());
+                        } catch (ExecutionException | InterruptedException e) {
+                            // Handle any errors (including cancellation) here.
+                            Log.e(TAG, "Unhandled exception", e);
+                        }
+                    },
+                    ContextCompat.getMainExecutor(getApplication()));
+        }
+
+        return cameraProviderLiveData;
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/ChooserActivity.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/ChooserActivity.java
index b765ab8..744bc5b 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/ChooserActivity.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/ChooserActivity.java
@@ -1,185 +1,185 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.content.Context;
-import android.content.Intent;
-import android.content.pm.PackageInfo;
-import android.content.pm.PackageManager;
-import android.os.Bundle;
-import android.os.StrictMode;
-
-import androidx.core.app.ActivityCompat;
-import androidx.core.app.ActivityCompat.OnRequestPermissionsResultCallback;
-import androidx.core.content.ContextCompat;
-import androidx.appcompat.app.AppCompatActivity;
-
-import android.util.Log;
-import android.view.LayoutInflater;
-import android.view.View;
-import android.view.ViewGroup;
-import android.widget.AdapterView;
-import android.widget.ArrayAdapter;
-import android.widget.ListView;
-import android.widget.TextView;
-
-import java.util.ArrayList;
-import java.util.List;
-
-/**
- * Demo app chooser which takes care of runtime permission requesting and allow you pick from all
- * available testing Activities.
- */
-public final class ChooserActivity extends AppCompatActivity
-        implements OnRequestPermissionsResultCallback, AdapterView.OnItemClickListener {
-    private static final String TAG = "ChooserActivity";
-    private static final int PERMISSION_REQUESTS = 1;
-
-    private static final Class<?>[] CLASSES =
-            new Class<?>[]{
-                    LivePreviewActivity.class,
-                    StillImageActivity.class,
-                    CameraXLivePreviewActivity.class,
-            };
-
-    private static final int[] DESCRIPTION_IDS =
-            new int[]{
-                    R.string.desc_camera_source_activity,
-                    R.string.desc_still_image_activity,
-                    R.string.desc_camerax_live_preview_activity,
-            };
-
-    @Override
-    protected void onCreate(Bundle savedInstanceState) {
-        if (BuildConfig.DEBUG) {
-            StrictMode.setThreadPolicy(
-                    new StrictMode.ThreadPolicy.Builder().detectAll().penaltyLog().build());
-            StrictMode.setVmPolicy(
-                    new StrictMode.VmPolicy.Builder()
-                            .detectLeakedSqlLiteObjects()
-                            .detectLeakedClosableObjects()
-                            .penaltyLog()
-                            .build());
-        }
-        super.onCreate(savedInstanceState);
-        Log.d(TAG, "onCreate");
-
-        setContentView(R.layout.activity_chooser);
-
-        // Set up ListView and Adapter
-        ListView listView = findViewById(R.id.test_activity_list_view);
-
-        MyArrayAdapter adapter = new MyArrayAdapter(this, android.R.layout.simple_list_item_2, CLASSES);
-        adapter.setDescriptionIds(DESCRIPTION_IDS);
-
-        listView.setAdapter(adapter);
-        listView.setOnItemClickListener(this);
-
-        if (!allPermissionsGranted()) {
-            getRuntimePermissions();
-        }
-    }
-
-    @Override
-    public void onItemClick(AdapterView<?> parent, View view, int position, long id) {
-        Class<?> clicked = CLASSES[position];
-        startActivity(new Intent(this, clicked));
-    }
-
-    private String[] getRequiredPermissions() {
-        try {
-            PackageInfo info =
-                    this.getPackageManager()
-                            .getPackageInfo(this.getPackageName(), PackageManager.GET_PERMISSIONS);
-            String[] ps = info.requestedPermissions;
-            if (ps != null && ps.length > 0) {
-                return ps;
-            } else {
-                return new String[0];
-            }
-        } catch (Exception e) {
-            return new String[0];
-        }
-    }
-
-    private boolean allPermissionsGranted() {
-        for (String permission : getRequiredPermissions()) {
-            if (!isPermissionGranted(this, permission)) {
-                return false;
-            }
-        }
-        return true;
-    }
-
-    private void getRuntimePermissions() {
-        List<String> allNeededPermissions = new ArrayList<>();
-        for (String permission : getRequiredPermissions()) {
-            if (!isPermissionGranted(this, permission)) {
-                allNeededPermissions.add(permission);
-            }
-        }
-
-        if (!allNeededPermissions.isEmpty()) {
-            ActivityCompat.requestPermissions(
-                    this, allNeededPermissions.toArray(new String[0]), PERMISSION_REQUESTS);
-        }
-    }
-
-    private static boolean isPermissionGranted(Context context, String permission) {
-        if (ContextCompat.checkSelfPermission(context, permission)
-                == PackageManager.PERMISSION_GRANTED) {
-            Log.i(TAG, "Permission granted: " + permission);
-            return true;
-        }
-        Log.i(TAG, "Permission NOT granted: " + permission);
-        return false;
-    }
-
-    private static class MyArrayAdapter extends ArrayAdapter<Class<?>> {
-
-        private final Context context;
-        private final Class<?>[] classes;
-        private int[] descriptionIds;
-
-        MyArrayAdapter(Context context, int resource, Class<?>[] objects) {
-            super(context, resource, objects);
-
-            this.context = context;
-            classes = objects;
-        }
-
-        @Override
-        public View getView(int position, View convertView, ViewGroup parent) {
-            View view = convertView;
-
-            if (convertView == null) {
-                LayoutInflater inflater =
-                        (LayoutInflater) context.getSystemService(LAYOUT_INFLATER_SERVICE);
-                view = inflater.inflate(android.R.layout.simple_list_item_2, null);
-            }
-
-            ((TextView) view.findViewById(android.R.id.text1)).setText(classes[position].getSimpleName());
-            ((TextView) view.findViewById(android.R.id.text2)).setText(descriptionIds[position]);
-
-            return view;
-        }
-
-        void setDescriptionIds(int[] descriptionIds) {
-            this.descriptionIds = descriptionIds;
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.content.Context;
+import android.content.Intent;
+import android.content.pm.PackageInfo;
+import android.content.pm.PackageManager;
+import android.os.Bundle;
+import android.os.StrictMode;
+
+import androidx.core.app.ActivityCompat;
+import androidx.core.app.ActivityCompat.OnRequestPermissionsResultCallback;
+import androidx.core.content.ContextCompat;
+import androidx.appcompat.app.AppCompatActivity;
+
+import android.util.Log;
+import android.view.LayoutInflater;
+import android.view.View;
+import android.view.ViewGroup;
+import android.widget.AdapterView;
+import android.widget.ArrayAdapter;
+import android.widget.ListView;
+import android.widget.TextView;
+
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * Demo app chooser which takes care of runtime permission requesting and allow you pick from all
+ * available testing Activities.
+ */
+public final class ChooserActivity extends AppCompatActivity
+        implements OnRequestPermissionsResultCallback, AdapterView.OnItemClickListener {
+    private static final String TAG = "ChooserActivity";
+    private static final int PERMISSION_REQUESTS = 1;
+
+    private static final Class<?>[] CLASSES =
+            new Class<?>[]{
+                    LivePreviewActivity.class,
+                    StillImageActivity.class,
+                    CameraXLivePreviewActivity.class,
+            };
+
+    private static final int[] DESCRIPTION_IDS =
+            new int[]{
+                    R.string.desc_camera_source_activity,
+                    R.string.desc_still_image_activity,
+                    R.string.desc_camerax_live_preview_activity,
+            };
+
+    @Override
+    protected void onCreate(Bundle savedInstanceState) {
+        if (BuildConfig.DEBUG) {
+            StrictMode.setThreadPolicy(
+                    new StrictMode.ThreadPolicy.Builder().detectAll().penaltyLog().build());
+            StrictMode.setVmPolicy(
+                    new StrictMode.VmPolicy.Builder()
+                            .detectLeakedSqlLiteObjects()
+                            .detectLeakedClosableObjects()
+                            .penaltyLog()
+                            .build());
+        }
+        super.onCreate(savedInstanceState);
+        Log.d(TAG, "onCreate");
+
+        setContentView(R.layout.activity_chooser);
+
+        // Set up ListView and Adapter
+        ListView listView = findViewById(R.id.test_activity_list_view);
+
+        MyArrayAdapter adapter = new MyArrayAdapter(this, android.R.layout.simple_list_item_2, CLASSES);
+        adapter.setDescriptionIds(DESCRIPTION_IDS);
+
+        listView.setAdapter(adapter);
+        listView.setOnItemClickListener(this);
+
+        if (!allPermissionsGranted()) {
+            getRuntimePermissions();
+        }
+    }
+
+    @Override
+    public void onItemClick(AdapterView<?> parent, View view, int position, long id) {
+        Class<?> clicked = CLASSES[position];
+        startActivity(new Intent(this, clicked));
+    }
+
+    private String[] getRequiredPermissions() {
+        try {
+            PackageInfo info =
+                    this.getPackageManager()
+                            .getPackageInfo(this.getPackageName(), PackageManager.GET_PERMISSIONS);
+            String[] ps = info.requestedPermissions;
+            if (ps != null && ps.length > 0) {
+                return ps;
+            } else {
+                return new String[0];
+            }
+        } catch (Exception e) {
+            return new String[0];
+        }
+    }
+
+    private boolean allPermissionsGranted() {
+        for (String permission : getRequiredPermissions()) {
+            if (!isPermissionGranted(this, permission)) {
+                return false;
+            }
+        }
+        return true;
+    }
+
+    private void getRuntimePermissions() {
+        List<String> allNeededPermissions = new ArrayList<>();
+        for (String permission : getRequiredPermissions()) {
+            if (!isPermissionGranted(this, permission)) {
+                allNeededPermissions.add(permission);
+            }
+        }
+
+        if (!allNeededPermissions.isEmpty()) {
+            ActivityCompat.requestPermissions(
+                    this, allNeededPermissions.toArray(new String[0]), PERMISSION_REQUESTS);
+        }
+    }
+
+    private static boolean isPermissionGranted(Context context, String permission) {
+        if (ContextCompat.checkSelfPermission(context, permission)
+                == PackageManager.PERMISSION_GRANTED) {
+            Log.i(TAG, "Permission granted: " + permission);
+            return true;
+        }
+        Log.i(TAG, "Permission NOT granted: " + permission);
+        return false;
+    }
+
+    private static class MyArrayAdapter extends ArrayAdapter<Class<?>> {
+
+        private final Context context;
+        private final Class<?>[] classes;
+        private int[] descriptionIds;
+
+        MyArrayAdapter(Context context, int resource, Class<?>[] objects) {
+            super(context, resource, objects);
+
+            this.context = context;
+            classes = objects;
+        }
+
+        @Override
+        public View getView(int position, View convertView, ViewGroup parent) {
+            View view = convertView;
+
+            if (convertView == null) {
+                LayoutInflater inflater =
+                        (LayoutInflater) context.getSystemService(LAYOUT_INFLATER_SERVICE);
+                view = inflater.inflate(android.R.layout.simple_list_item_2, null);
+            }
+
+            ((TextView) view.findViewById(android.R.id.text1)).setText(classes[position].getSimpleName());
+            ((TextView) view.findViewById(android.R.id.text2)).setText(descriptionIds[position]);
+
+            return view;
+        }
+
+        void setDescriptionIds(int[] descriptionIds) {
+            this.descriptionIds = descriptionIds;
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/EntryChoiceActivity.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/EntryChoiceActivity.kt
index e299be6..323b084 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/EntryChoiceActivity.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/EntryChoiceActivity.kt
@@ -1,44 +1,44 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo
-
-import android.content.Intent
-import android.os.Bundle
-import android.widget.TextView
-import androidx.appcompat.app.AppCompatActivity
-
-class EntryChoiceActivity : AppCompatActivity() {
-
-    override fun onCreate(savedInstanceState: Bundle?) {
-        super.onCreate(savedInstanceState)
-        setContentView(R.layout.activity_entry_choice)
-
-        findViewById<TextView>(R.id.java_entry_point).setOnClickListener {
-            val intent = Intent(this@EntryChoiceActivity, ChooserActivity::class.java)
-            startActivity(intent)
-        }
-
-        findViewById<TextView>(R.id.kotlin_entry_point).setOnClickListener {
-            val intent =
-                    Intent(
-                            this@EntryChoiceActivity,
-                            com.google.mlkit.vision.demo.kotlin.ChooserActivity::class.java
-                    )
-            startActivity(intent)
-        }
-    }
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo
+
+import android.content.Intent
+import android.os.Bundle
+import android.widget.TextView
+import androidx.appcompat.app.AppCompatActivity
+
+class EntryChoiceActivity : AppCompatActivity() {
+
+    override fun onCreate(savedInstanceState: Bundle?) {
+        super.onCreate(savedInstanceState)
+        setContentView(R.layout.activity_entry_choice)
+
+        findViewById<TextView>(R.id.java_entry_point).setOnClickListener {
+            val intent = Intent(this@EntryChoiceActivity, ChooserActivity::class.java)
+            startActivity(intent)
+        }
+
+        findViewById<TextView>(R.id.kotlin_entry_point).setOnClickListener {
+            val intent =
+                    Intent(
+                            this@EntryChoiceActivity,
+                            com.google.mlkit.vision.demo.kotlin.ChooserActivity::class.java
+                    )
+            startActivity(intent)
+        }
+    }
 }
\ No newline at end of file
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/FrameMetadata.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/FrameMetadata.java
index 42a521b..c86abfc 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/FrameMetadata.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/FrameMetadata.java
@@ -1,74 +1,74 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-/**
- * Describing a frame info.
- */
-public class FrameMetadata {
-
-    private final int width;
-    private final int height;
-    private final int rotation;
-
-    public int getWidth() {
-        return width;
-    }
-
-    public int getHeight() {
-        return height;
-    }
-
-    public int getRotation() {
-        return rotation;
-    }
-
-    private FrameMetadata(int width, int height, int rotation) {
-        this.width = width;
-        this.height = height;
-        this.rotation = rotation;
-    }
-
-    /**
-     * Builder of {@link FrameMetadata}.
-     */
-    public static class Builder {
-
-        private int width;
-        private int height;
-        private int rotation;
-
-        public Builder setWidth(int width) {
-            this.width = width;
-            return this;
-        }
-
-        public Builder setHeight(int height) {
-            this.height = height;
-            return this;
-        }
-
-        public Builder setRotation(int rotation) {
-            this.rotation = rotation;
-            return this;
-        }
-
-        public FrameMetadata build() {
-            return new FrameMetadata(width, height, rotation);
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+/**
+ * Describing a frame info.
+ */
+public class FrameMetadata {
+
+    private final int width;
+    private final int height;
+    private final int rotation;
+
+    public int getWidth() {
+        return width;
+    }
+
+    public int getHeight() {
+        return height;
+    }
+
+    public int getRotation() {
+        return rotation;
+    }
+
+    private FrameMetadata(int width, int height, int rotation) {
+        this.width = width;
+        this.height = height;
+        this.rotation = rotation;
+    }
+
+    /**
+     * Builder of {@link FrameMetadata}.
+     */
+    public static class Builder {
+
+        private int width;
+        private int height;
+        private int rotation;
+
+        public Builder setWidth(int width) {
+            this.width = width;
+            return this;
+        }
+
+        public Builder setHeight(int height) {
+            this.height = height;
+            return this;
+        }
+
+        public Builder setRotation(int rotation) {
+            this.rotation = rotation;
+            return this;
+        }
+
+        public FrameMetadata build() {
+            return new FrameMetadata(width, height, rotation);
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/GraphicOverlay.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/GraphicOverlay.java
index f526fcd..3b063d9 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/GraphicOverlay.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/GraphicOverlay.java
@@ -1,253 +1,253 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.content.Context;
-import android.graphics.Canvas;
-import android.graphics.Matrix;
-import android.util.AttributeSet;
-import android.view.View;
-
-import com.google.common.base.Preconditions;
-
-import java.util.ArrayList;
-import java.util.List;
-
-/**
- * A view which renders a series of custom graphics to be overlayed on top of an associated preview
- * (i.e., the camera preview). The creator can add graphics objects, update the objects, and remove
- * them, triggering the appropriate drawing and invalidation within the view.
- *
- * <p>Supports scaling and mirroring of the graphics relative the camera's preview properties. The
- * idea is that detection items are expressed in terms of an image size, but need to be scaled up
- * to the full view size, and also mirrored in the case of the front-facing camera.
- *
- * <p>Associated {@link Graphic} items should use the following methods to convert to view
- * coordinates for the graphics that are drawn:
- *
- * <ol>
- *   <li>{@link Graphic#scale(float)} adjusts the size of the supplied value from the image scale
- *       to the view scale.
- *   <li>{@link Graphic#translateX(float)} and {@link Graphic#translateY(float)} adjust the
- *       coordinate from the image's coordinate system to the view coordinate system.
- * </ol>
- */
-public class GraphicOverlay extends View {
-    private final Object lock = new Object();
-    private final List<Graphic> graphics = new ArrayList<>();
-    // Matrix for transforming from image coordinates to overlay view coordinates.
-    private final Matrix transformationMatrix = new Matrix();
-
-    private int imageWidth;
-    private int imageHeight;
-    // The factor of overlay View size to image size. Anything in the image coordinates need to be
-    // scaled by this amount to fit with the area of overlay View.
-    private float scaleFactor = 1.0f;
-    // The number of horizontal pixels needed to be cropped on each side to fit the image with the
-    // area of overlay View after scaling.
-    private float postScaleWidthOffset;
-    // The number of vertical pixels needed to be cropped on each side to fit the image with the
-    // area of overlay View after scaling.
-    private float postScaleHeightOffset;
-    private boolean isImageFlipped;
-    private boolean needUpdateTransformation = true;
-
-    /**
-     * Base class for a custom graphics object to be rendered within the graphic overlay. Subclass
-     * this and implement the {@link Graphic#draw(Canvas)} method to define the graphics element. Add
-     * instances to the overlay using {@link GraphicOverlay#add(Graphic)}.
-     */
-    public abstract static class Graphic {
-        private GraphicOverlay overlay;
-
-        public Graphic(GraphicOverlay overlay) {
-            this.overlay = overlay;
-        }
-
-        /**
-         * Draw the graphic on the supplied canvas. Drawing should use the following methods to convert
-         * to view coordinates for the graphics that are drawn:
-         *
-         * <ol>
-         *   <li>{@link Graphic#scale(float)} adjusts the size of the supplied value from the image
-         *       scale to the view scale.
-         *   <li>{@link Graphic#translateX(float)} and {@link Graphic#translateY(float)} adjust the
-         *       coordinate from the image's coordinate system to the view coordinate system.
-         * </ol>
-         *
-         * @param canvas drawing canvas
-         */
-        public abstract void draw(Canvas canvas);
-
-        /**
-         * Adjusts the supplied value from the image scale to the view scale.
-         */
-        public float scale(float imagePixel) {
-            return imagePixel * overlay.scaleFactor;
-        }
-
-        /**
-         * Returns the application context of the app.
-         */
-        public Context getApplicationContext() {
-            return overlay.getContext().getApplicationContext();
-        }
-
-        public boolean isImageFlipped() {
-            return overlay.isImageFlipped;
-        }
-
-        /**
-         * Adjusts the x coordinate from the image's coordinate system to the view coordinate system.
-         */
-        public float translateX(float x) {
-            if (overlay.isImageFlipped) {
-                return overlay.getWidth() - (scale(x) - overlay.postScaleWidthOffset);
-            } else {
-                return scale(x) - overlay.postScaleWidthOffset;
-            }
-        }
-
-        /**
-         * Adjusts the y coordinate from the image's coordinate system to the view coordinate system.
-         */
-        public float translateY(float y) {
-            return scale(y) - overlay.postScaleHeightOffset;
-        }
-
-        /**
-         * Returns a {@link Matrix} for transforming from image coordinates to overlay view coordinates.
-         */
-        public Matrix getTransformationMatrix() {
-            return overlay.transformationMatrix;
-        }
-
-        public void postInvalidate() {
-            overlay.postInvalidate();
-        }
-    }
-
-    public GraphicOverlay(Context context, AttributeSet attrs) {
-        super(context, attrs);
-        addOnLayoutChangeListener(
-                (view, left, top, right, bottom, oldLeft, oldTop, oldRight, oldBottom) ->
-                        needUpdateTransformation = true);
-    }
-
-    /**
-     * Removes all graphics from the overlay.
-     */
-    public void clear() {
-        synchronized (lock) {
-            graphics.clear();
-        }
-        postInvalidate();
-    }
-
-    /**
-     * Adds a graphic to the overlay.
-     */
-    public void add(Graphic graphic) {
-        synchronized (lock) {
-            graphics.add(graphic);
-        }
-    }
-
-    /**
-     * Removes a graphic from the overlay.
-     */
-    public void remove(Graphic graphic) {
-        synchronized (lock) {
-            graphics.remove(graphic);
-        }
-        postInvalidate();
-    }
-
-    /**
-     * Sets the source information of the image being processed by detectors, including size and
-     * whether it is flipped, which informs how to transform image coordinates later.
-     *
-     * @param imageWidth  the width of the image sent to ML Kit detectors
-     * @param imageHeight the height of the image sent to ML Kit detectors
-     * @param isFlipped   whether the image is flipped. Should set it to true when the image is from the
-     *                    front camera.
-     */
-    public void setImageSourceInfo(int imageWidth, int imageHeight, boolean isFlipped) {
-        Preconditions.checkState(imageWidth > 0, "image width must be positive");
-        Preconditions.checkState(imageHeight > 0, "image height must be positive");
-        synchronized (lock) {
-            this.imageWidth = imageWidth;
-            this.imageHeight = imageHeight;
-            this.isImageFlipped = isFlipped;
-            needUpdateTransformation = true;
-        }
-        postInvalidate();
-    }
-
-    public int getImageWidth() {
-        return imageWidth;
-    }
-
-    public int getImageHeight() {
-        return imageHeight;
-    }
-
-    private void updateTransformationIfNeeded() {
-        if (!needUpdateTransformation || imageWidth <= 0 || imageHeight <= 0) {
-            return;
-        }
-        float viewAspectRatio = (float) getWidth() / getHeight();
-        float imageAspectRatio = (float) imageWidth / imageHeight;
-        postScaleWidthOffset = 0;
-        postScaleHeightOffset = 0;
-        if (viewAspectRatio > imageAspectRatio) {
-            // The image needs to be vertically cropped to be displayed in this view.
-            scaleFactor = (float) getWidth() / imageWidth;
-            postScaleHeightOffset = ((float) getWidth() / imageAspectRatio - getHeight()) / 2;
-        } else {
-            // The image needs to be horizontally cropped to be displayed in this view.
-            scaleFactor = (float) getHeight() / imageHeight;
-            postScaleWidthOffset = ((float) getHeight() * imageAspectRatio - getWidth()) / 2;
-        }
-
-        transformationMatrix.reset();
-        transformationMatrix.setScale(scaleFactor, scaleFactor);
-        transformationMatrix.postTranslate(-postScaleWidthOffset, -postScaleHeightOffset);
-
-        if (isImageFlipped) {
-            transformationMatrix.postScale(-1f, 1f, getWidth() / 2f, getHeight() / 2f);
-        }
-
-        needUpdateTransformation = false;
-    }
-
-    /**
-     * Draws the overlay with its associated graphic objects.
-     */
-    @Override
-    protected void onDraw(Canvas canvas) {
-        super.onDraw(canvas);
-
-        synchronized (lock) {
-            updateTransformationIfNeeded();
-
-            for (Graphic graphic : graphics) {
-                graphic.draw(canvas);
-            }
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.content.Context;
+import android.graphics.Canvas;
+import android.graphics.Matrix;
+import android.util.AttributeSet;
+import android.view.View;
+
+import com.google.common.base.Preconditions;
+
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * A view which renders a series of custom graphics to be overlayed on top of an associated preview
+ * (i.e., the camera preview). The creator can add graphics objects, update the objects, and remove
+ * them, triggering the appropriate drawing and invalidation within the view.
+ *
+ * <p>Supports scaling and mirroring of the graphics relative the camera's preview properties. The
+ * idea is that detection items are expressed in terms of an image size, but need to be scaled up
+ * to the full view size, and also mirrored in the case of the front-facing camera.
+ *
+ * <p>Associated {@link Graphic} items should use the following methods to convert to view
+ * coordinates for the graphics that are drawn:
+ *
+ * <ol>
+ *   <li>{@link Graphic#scale(float)} adjusts the size of the supplied value from the image scale
+ *       to the view scale.
+ *   <li>{@link Graphic#translateX(float)} and {@link Graphic#translateY(float)} adjust the
+ *       coordinate from the image's coordinate system to the view coordinate system.
+ * </ol>
+ */
+public class GraphicOverlay extends View {
+    private final Object lock = new Object();
+    private final List<Graphic> graphics = new ArrayList<>();
+    // Matrix for transforming from image coordinates to overlay view coordinates.
+    private final Matrix transformationMatrix = new Matrix();
+
+    private int imageWidth;
+    private int imageHeight;
+    // The factor of overlay View size to image size. Anything in the image coordinates need to be
+    // scaled by this amount to fit with the area of overlay View.
+    private float scaleFactor = 1.0f;
+    // The number of horizontal pixels needed to be cropped on each side to fit the image with the
+    // area of overlay View after scaling.
+    private float postScaleWidthOffset;
+    // The number of vertical pixels needed to be cropped on each side to fit the image with the
+    // area of overlay View after scaling.
+    private float postScaleHeightOffset;
+    private boolean isImageFlipped;
+    private boolean needUpdateTransformation = true;
+
+    /**
+     * Base class for a custom graphics object to be rendered within the graphic overlay. Subclass
+     * this and implement the {@link Graphic#draw(Canvas)} method to define the graphics element. Add
+     * instances to the overlay using {@link GraphicOverlay#add(Graphic)}.
+     */
+    public abstract static class Graphic {
+        private GraphicOverlay overlay;
+
+        public Graphic(GraphicOverlay overlay) {
+            this.overlay = overlay;
+        }
+
+        /**
+         * Draw the graphic on the supplied canvas. Drawing should use the following methods to convert
+         * to view coordinates for the graphics that are drawn:
+         *
+         * <ol>
+         *   <li>{@link Graphic#scale(float)} adjusts the size of the supplied value from the image
+         *       scale to the view scale.
+         *   <li>{@link Graphic#translateX(float)} and {@link Graphic#translateY(float)} adjust the
+         *       coordinate from the image's coordinate system to the view coordinate system.
+         * </ol>
+         *
+         * @param canvas drawing canvas
+         */
+        public abstract void draw(Canvas canvas);
+
+        /**
+         * Adjusts the supplied value from the image scale to the view scale.
+         */
+        public float scale(float imagePixel) {
+            return imagePixel * overlay.scaleFactor;
+        }
+
+        /**
+         * Returns the application context of the app.
+         */
+        public Context getApplicationContext() {
+            return overlay.getContext().getApplicationContext();
+        }
+
+        public boolean isImageFlipped() {
+            return overlay.isImageFlipped;
+        }
+
+        /**
+         * Adjusts the x coordinate from the image's coordinate system to the view coordinate system.
+         */
+        public float translateX(float x) {
+            if (overlay.isImageFlipped) {
+                return overlay.getWidth() - (scale(x) - overlay.postScaleWidthOffset);
+            } else {
+                return scale(x) - overlay.postScaleWidthOffset;
+            }
+        }
+
+        /**
+         * Adjusts the y coordinate from the image's coordinate system to the view coordinate system.
+         */
+        public float translateY(float y) {
+            return scale(y) - overlay.postScaleHeightOffset;
+        }
+
+        /**
+         * Returns a {@link Matrix} for transforming from image coordinates to overlay view coordinates.
+         */
+        public Matrix getTransformationMatrix() {
+            return overlay.transformationMatrix;
+        }
+
+        public void postInvalidate() {
+            overlay.postInvalidate();
+        }
+    }
+
+    public GraphicOverlay(Context context, AttributeSet attrs) {
+        super(context, attrs);
+        addOnLayoutChangeListener(
+                (view, left, top, right, bottom, oldLeft, oldTop, oldRight, oldBottom) ->
+                        needUpdateTransformation = true);
+    }
+
+    /**
+     * Removes all graphics from the overlay.
+     */
+    public void clear() {
+        synchronized (lock) {
+            graphics.clear();
+        }
+        postInvalidate();
+    }
+
+    /**
+     * Adds a graphic to the overlay.
+     */
+    public void add(Graphic graphic) {
+        synchronized (lock) {
+            graphics.add(graphic);
+        }
+    }
+
+    /**
+     * Removes a graphic from the overlay.
+     */
+    public void remove(Graphic graphic) {
+        synchronized (lock) {
+            graphics.remove(graphic);
+        }
+        postInvalidate();
+    }
+
+    /**
+     * Sets the source information of the image being processed by detectors, including size and
+     * whether it is flipped, which informs how to transform image coordinates later.
+     *
+     * @param imageWidth  the width of the image sent to ML Kit detectors
+     * @param imageHeight the height of the image sent to ML Kit detectors
+     * @param isFlipped   whether the image is flipped. Should set it to true when the image is from the
+     *                    front camera.
+     */
+    public void setImageSourceInfo(int imageWidth, int imageHeight, boolean isFlipped) {
+        Preconditions.checkState(imageWidth > 0, "image width must be positive");
+        Preconditions.checkState(imageHeight > 0, "image height must be positive");
+        synchronized (lock) {
+            this.imageWidth = imageWidth;
+            this.imageHeight = imageHeight;
+            this.isImageFlipped = isFlipped;
+            needUpdateTransformation = true;
+        }
+        postInvalidate();
+    }
+
+    public int getImageWidth() {
+        return imageWidth;
+    }
+
+    public int getImageHeight() {
+        return imageHeight;
+    }
+
+    private void updateTransformationIfNeeded() {
+        if (!needUpdateTransformation || imageWidth <= 0 || imageHeight <= 0) {
+            return;
+        }
+        float viewAspectRatio = (float) getWidth() / getHeight();
+        float imageAspectRatio = (float) imageWidth / imageHeight;
+        postScaleWidthOffset = 0;
+        postScaleHeightOffset = 0;
+        if (viewAspectRatio > imageAspectRatio) {
+            // The image needs to be vertically cropped to be displayed in this view.
+            scaleFactor = (float) getWidth() / imageWidth;
+            postScaleHeightOffset = ((float) getWidth() / imageAspectRatio - getHeight()) / 2;
+        } else {
+            // The image needs to be horizontally cropped to be displayed in this view.
+            scaleFactor = (float) getHeight() / imageHeight;
+            postScaleWidthOffset = ((float) getHeight() * imageAspectRatio - getWidth()) / 2;
+        }
+
+        transformationMatrix.reset();
+        transformationMatrix.setScale(scaleFactor, scaleFactor);
+        transformationMatrix.postTranslate(-postScaleWidthOffset, -postScaleHeightOffset);
+
+        if (isImageFlipped) {
+            transformationMatrix.postScale(-1f, 1f, getWidth() / 2f, getHeight() / 2f);
+        }
+
+        needUpdateTransformation = false;
+    }
+
+    /**
+     * Draws the overlay with its associated graphic objects.
+     */
+    @Override
+    protected void onDraw(Canvas canvas) {
+        super.onDraw(canvas);
+
+        synchronized (lock) {
+            updateTransformationIfNeeded();
+
+            for (Graphic graphic : graphics) {
+                graphic.draw(canvas);
+            }
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/InferenceInfoGraphic.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/InferenceInfoGraphic.java
index 536f166..a0b609c 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/InferenceInfoGraphic.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/InferenceInfoGraphic.java
@@ -1,71 +1,71 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package com.google.mlkit.vision.demo;
-
-import android.graphics.Canvas;
-import android.graphics.Color;
-import android.graphics.Paint;
-
-import androidx.annotation.Nullable;
-
-/**
- * Graphic instance for rendering inference info (latency, FPS, resolution) in an overlay view.
- */
-public class InferenceInfoGraphic extends GraphicOverlay.Graphic {
-
-    private static final int TEXT_COLOR = Color.WHITE;
-    private static final float TEXT_SIZE = 60.0f;
-
-    private final Paint textPaint;
-    private final GraphicOverlay overlay;
-    private final double latency;
-
-    // Only valid when a stream of input images is being processed. Null for single image mode.
-    @Nullable
-    private final Integer framesPerSecond;
-
-    public InferenceInfoGraphic(
-            GraphicOverlay overlay, double latency, @Nullable Integer framesPerSecond) {
-        super(overlay);
-        this.overlay = overlay;
-        this.latency = latency;
-        this.framesPerSecond = framesPerSecond;
-        textPaint = new Paint();
-        textPaint.setColor(TEXT_COLOR);
-        textPaint.setTextSize(TEXT_SIZE);
-        postInvalidate();
-    }
-
-    @Override
-    public synchronized void draw(Canvas canvas) {
-        float x = TEXT_SIZE * 0.5f;
-        float y = TEXT_SIZE * 1.5f;
-
-        canvas.drawText(
-                "InputImage size: " + overlay.getImageWidth() + "x" + overlay.getImageHeight(),
-                x,
-                y,
-                textPaint);
-
-        // Draw FPS (if valid) and inference latency
-        if (framesPerSecond != null) {
-            canvas.drawText(
-                    "FPS: " + framesPerSecond + ", latency: " + latency + " ms", x, y + TEXT_SIZE, textPaint);
-        } else {
-            canvas.drawText("Latency: " + latency + " ms", x, y + TEXT_SIZE, textPaint);
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.mlkit.vision.demo;
+
+import android.graphics.Canvas;
+import android.graphics.Color;
+import android.graphics.Paint;
+
+import androidx.annotation.Nullable;
+
+/**
+ * Graphic instance for rendering inference info (latency, FPS, resolution) in an overlay view.
+ */
+public class InferenceInfoGraphic extends GraphicOverlay.Graphic {
+
+    private static final int TEXT_COLOR = Color.WHITE;
+    private static final float TEXT_SIZE = 60.0f;
+
+    private final Paint textPaint;
+    private final GraphicOverlay overlay;
+    private final double latency;
+
+    // Only valid when a stream of input images is being processed. Null for single image mode.
+    @Nullable
+    private final Integer framesPerSecond;
+
+    public InferenceInfoGraphic(
+            GraphicOverlay overlay, double latency, @Nullable Integer framesPerSecond) {
+        super(overlay);
+        this.overlay = overlay;
+        this.latency = latency;
+        this.framesPerSecond = framesPerSecond;
+        textPaint = new Paint();
+        textPaint.setColor(TEXT_COLOR);
+        textPaint.setTextSize(TEXT_SIZE);
+        postInvalidate();
+    }
+
+    @Override
+    public synchronized void draw(Canvas canvas) {
+        float x = TEXT_SIZE * 0.5f;
+        float y = TEXT_SIZE * 1.5f;
+
+        canvas.drawText(
+                "InputImage size: " + overlay.getImageWidth() + "x" + overlay.getImageHeight(),
+                x,
+                y,
+                textPaint);
+
+        // Draw FPS (if valid) and inference latency
+        if (framesPerSecond != null) {
+            canvas.drawText(
+                    "FPS: " + framesPerSecond + ", latency: " + latency + " ms", x, y + TEXT_SIZE, textPaint);
+        } else {
+            canvas.drawText("Latency: " + latency + " ms", x, y + TEXT_SIZE, textPaint);
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/LivePreviewActivity.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/LivePreviewActivity.java
index 4b0bdb5..2069a3c 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/LivePreviewActivity.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/LivePreviewActivity.java
@@ -1,373 +1,374 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.content.Context;
-import android.content.Intent;
-import android.content.pm.PackageInfo;
-import android.content.pm.PackageManager;
-import android.os.Bundle;
-
-import androidx.core.app.ActivityCompat;
-import androidx.core.app.ActivityCompat.OnRequestPermissionsResultCallback;
-import androidx.core.content.ContextCompat;
-import androidx.appcompat.app.AppCompatActivity;
-
-import android.util.Log;
-import android.view.Menu;
-import android.view.MenuItem;
-import android.view.View;
-import android.widget.AdapterView;
-import android.widget.AdapterView.OnItemSelectedListener;
-import android.widget.ArrayAdapter;
-import android.widget.CompoundButton;
-import android.widget.ImageView;
-import android.widget.Spinner;
-import android.widget.Toast;
-import android.widget.ToggleButton;
-
-import com.google.android.gms.common.annotation.KeepName;
-import com.google.mlkit.common.model.LocalModel;
-import com.google.mlkit.vision.demo.automl.AutoMLImageLabelerProcessor;
-import com.google.mlkit.vision.demo.barcodescanner.BarcodeScannerProcessor;
-import com.google.mlkit.vision.demo.facedetector.FaceDetectorProcessor;
-import com.google.mlkit.vision.demo.labeldetector.LabelDetectorProcessor;
-import com.google.mlkit.vision.demo.objectdetector.ObjectDetectorProcessor;
-import com.google.mlkit.vision.demo.preference.PreferenceUtils;
-import com.google.mlkit.vision.demo.preference.SettingsActivity;
-import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource;
-import com.google.mlkit.vision.demo.textdetector.TextRecognitionProcessor;
-import com.google.mlkit.vision.face.FaceDetectorOptions;
-import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions;
-import com.google.mlkit.vision.label.defaults.ImageLabelerOptions;
-import com.google.mlkit.vision.objects.custom.CustomObjectDetectorOptions;
-import com.google.mlkit.vision.objects.defaults.ObjectDetectorOptions;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-/**
- * Live preview demo for ML Kit APIs.
- */
-@KeepName
-public final class LivePreviewActivity extends AppCompatActivity
-        implements OnRequestPermissionsResultCallback,
-        OnItemSelectedListener,
-        CompoundButton.OnCheckedChangeListener {
-    private static final String OBJECT_DETECTION = "Object Detection";
-    private static final String OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Birds)";
-    private static final String FACE_DETECTION = "Face Detection";
-    private static final String TEXT_RECOGNITION = "Text Recognition";
-    private static final String BARCODE_SCANNING = "Barcode Scanning";
-    private static final String IMAGE_LABELING = "Image Labeling";
-    private static final String IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Birds)";
-    private static final String AUTOML_LABELING = "AutoML Image Labeling";
-    private static final String TAG = "LivePreviewActivity";
-    private static final int PERMISSION_REQUESTS = 1;
-
-    private CameraSource cameraSource = null;
-    private CameraSourcePreview preview;
-    private GraphicOverlay graphicOverlay;
-    private String selectedModel = OBJECT_DETECTION;
-
-    @Override
-    protected void onCreate(Bundle savedInstanceState) {
-        super.onCreate(savedInstanceState);
-        Log.d(TAG, "onCreate");
-
-        setContentView(R.layout.activity_live_preview);
-
-        preview = findViewById(R.id.preview);
-        if (preview == null) {
-            Log.d(TAG, "Preview is null");
-        }
-        graphicOverlay = findViewById(R.id.graphic_overlay);
-        if (graphicOverlay == null) {
-            Log.d(TAG, "graphicOverlay is null");
-        }
-
-        Spinner spinner = findViewById(R.id.spinner);
-        List<String> options = new ArrayList<>();
-        options.add(OBJECT_DETECTION);
-        options.add(OBJECT_DETECTION_CUSTOM);
-        options.add(FACE_DETECTION);
-        options.add(TEXT_RECOGNITION);
-        options.add(BARCODE_SCANNING);
-        options.add(IMAGE_LABELING);
-        options.add(IMAGE_LABELING_CUSTOM);
-        options.add(AUTOML_LABELING);
-        // Creating adapter for spinner
-        ArrayAdapter<String> dataAdapter = new ArrayAdapter<>(this, R.layout.spinner_style, options);
-        // Drop down layout style - list view with radio button
-        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
-        // attaching data adapter to spinner
-        spinner.setAdapter(dataAdapter);
-        spinner.setOnItemSelectedListener(this);
-
-        ToggleButton facingSwitch = findViewById(R.id.facing_switch);
-        facingSwitch.setOnCheckedChangeListener(this);
-
-        ImageView settingsButton = findViewById(R.id.settings_button);
-        settingsButton.setOnClickListener(
-                v -> {
-                    Intent intent = new Intent(getApplicationContext(), SettingsActivity.class);
-                    intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE,
-                            SettingsActivity.LaunchSource.LIVE_PREVIEW);
-                    startActivity(intent);
-                });
-
-        if (allPermissionsGranted()) {
-            createCameraSource(selectedModel);
-        } else {
-            getRuntimePermissions();
-        }
-    }
-
-    @Override
-    public boolean onCreateOptionsMenu(Menu menu) {
-        getMenuInflater().inflate(R.menu.live_preview_menu, menu);
-        return true;
-    }
-
-    @Override
-    public boolean onOptionsItemSelected(MenuItem item) {
-        if (item.getItemId() == R.id.settings) {
-            Intent intent = new Intent(this, SettingsActivity.class);
-            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE, LaunchSource.LIVE_PREVIEW);
-            startActivity(intent);
-            return true;
-        }
-
-        return super.onOptionsItemSelected(item);
-    }
-
-    @Override
-    public synchronized void onItemSelected(AdapterView<?> parent, View view, int pos, long id) {
-        // An item was selected. You can retrieve the selected item using
-        // parent.getItemAtPosition(pos)
-        selectedModel = parent.getItemAtPosition(pos).toString();
-        Log.d(TAG, "Selected model: " + selectedModel);
-        preview.stop();
-        if (allPermissionsGranted()) {
-            createCameraSource(selectedModel);
-            startCameraSource();
-        } else {
-            getRuntimePermissions();
-        }
-    }
-
-    @Override
-    public void onNothingSelected(AdapterView<?> parent) {
-        // Do nothing.
-    }
-
-    @Override
-    public void onCheckedChanged(CompoundButton buttonView, boolean isChecked) {
-        Log.d(TAG, "Set facing");
-        if (cameraSource != null) {
-            if (isChecked) {
-                cameraSource.setFacing(CameraSource.CAMERA_FACING_FRONT);
-            } else {
-                cameraSource.setFacing(CameraSource.CAMERA_FACING_BACK);
-            }
-        }
-        preview.stop();
-        startCameraSource();
-    }
-
-    private void createCameraSource(String model) {
-        // If there's no existing cameraSource, create one.
-        if (cameraSource == null) {
-            cameraSource = new CameraSource(this, graphicOverlay);
-        }
-
-        try {
-            switch (model) {
-                case OBJECT_DETECTION:
-                    Log.i(TAG, "Using Object Detector Processor");
-                    ObjectDetectorOptions objectDetectorOptions =
-                            PreferenceUtils.getObjectDetectorOptionsForLivePreview(this);
-                    cameraSource.setMachineLearningFrameProcessor(
-                            new ObjectDetectorProcessor(this, objectDetectorOptions));
-                    break;
-                case OBJECT_DETECTION_CUSTOM:
-                    Log.i(TAG, "Using Custom Object Detector Processor");
-                    LocalModel localModel =
-                            new LocalModel.Builder()
-                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
-                                    .build();
-                    CustomObjectDetectorOptions customObjectDetectorOptions =
-                            PreferenceUtils.getCustomObjectDetectorOptionsForLivePreview(this, localModel);
-                    cameraSource.setMachineLearningFrameProcessor(
-                            new ObjectDetectorProcessor(this, customObjectDetectorOptions));
-                    break;
-                case TEXT_RECOGNITION:
-                    Log.i(TAG, "Using on-device Text recognition Processor");
-                    cameraSource.setMachineLearningFrameProcessor(new TextRecognitionProcessor(this));
-                    break;
-                case FACE_DETECTION:
-                    Log.i(TAG, "Using Face Detector Processor");
-                    FaceDetectorOptions faceDetectorOptions =
-                            PreferenceUtils.getFaceDetectorOptionsForLivePreview(this);
-                    cameraSource.setMachineLearningFrameProcessor(
-                            new FaceDetectorProcessor(this, faceDetectorOptions));
-                    break;
-                case BARCODE_SCANNING:
-                    Log.i(TAG, "Using Barcode Detector Processor");
-                    cameraSource.setMachineLearningFrameProcessor(new BarcodeScannerProcessor(this));
-                    break;
-                case IMAGE_LABELING:
-                    Log.i(TAG, "Using Image Label Detector Processor");
-                    cameraSource.setMachineLearningFrameProcessor(
-                            new LabelDetectorProcessor(this, ImageLabelerOptions.DEFAULT_OPTIONS));
-                    break;
-                case IMAGE_LABELING_CUSTOM:
-                    Log.i(TAG, "Using Custom Image Label Detector Processor");
-                    LocalModel localClassifier =
-                            new LocalModel.Builder()
-                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
-                                    .build();
-                    CustomImageLabelerOptions customImageLabelerOptions =
-                            new CustomImageLabelerOptions.Builder(localClassifier).build();
-                    cameraSource.setMachineLearningFrameProcessor(
-                            new LabelDetectorProcessor(this, customImageLabelerOptions));
-                    break;
-                case AUTOML_LABELING:
-                    cameraSource.setMachineLearningFrameProcessor(
-                            new AutoMLImageLabelerProcessor(this));
-                    break;
-                default:
-                    Log.e(TAG, "Unknown model: " + model);
-            }
-        } catch (Exception e) {
-            Log.e(TAG, "Can not create image processor: " + model, e);
-            Toast.makeText(
-                    getApplicationContext(),
-                    "Can not create image processor: " + e.getMessage(),
-                    Toast.LENGTH_LONG)
-                    .show();
-        }
-    }
-
-    /**
-     * Starts or restarts the camera source, if it exists. If the camera source doesn't exist yet
-     * (e.g., because onResume was called before the camera source was created), this will be called
-     * again when the camera source is created.
-     */
-    private void startCameraSource() {
-        if (cameraSource != null) {
-            try {
-                if (preview == null) {
-                    Log.d(TAG, "resume: Preview is null");
-                }
-                if (graphicOverlay == null) {
-                    Log.d(TAG, "resume: graphOverlay is null");
-                }
-                preview.start(cameraSource, graphicOverlay);
-            } catch (IOException e) {
-                Log.e(TAG, "Unable to start camera source.", e);
-                cameraSource.release();
-                cameraSource = null;
-            }
-        }
-    }
-
-    @Override
-    public void onResume() {
-        super.onResume();
-        Log.d(TAG, "onResume");
-        createCameraSource(selectedModel);
-        startCameraSource();
-    }
-
-    /**
-     * Stops the camera.
-     */
-    @Override
-    protected void onPause() {
-        super.onPause();
-        preview.stop();
-    }
-
-    @Override
-    public void onDestroy() {
-        super.onDestroy();
-        if (cameraSource != null) {
-            cameraSource.release();
-        }
-    }
-
-    private String[] getRequiredPermissions() {
-        try {
-            PackageInfo info =
-                    this.getPackageManager()
-                            .getPackageInfo(this.getPackageName(), PackageManager.GET_PERMISSIONS);
-            String[] ps = info.requestedPermissions;
-            if (ps != null && ps.length > 0) {
-                return ps;
-            } else {
-                return new String[0];
-            }
-        } catch (Exception e) {
-            return new String[0];
-        }
-    }
-
-    private boolean allPermissionsGranted() {
-        for (String permission : getRequiredPermissions()) {
-            if (!isPermissionGranted(this, permission)) {
-                return false;
-            }
-        }
-        return true;
-    }
-
-    private void getRuntimePermissions() {
-        List<String> allNeededPermissions = new ArrayList<>();
-        for (String permission : getRequiredPermissions()) {
-            if (!isPermissionGranted(this, permission)) {
-                allNeededPermissions.add(permission);
-            }
-        }
-
-        if (!allNeededPermissions.isEmpty()) {
-            ActivityCompat.requestPermissions(
-                    this, allNeededPermissions.toArray(new String[0]), PERMISSION_REQUESTS);
-        }
-    }
-
-    @Override
-    public void onRequestPermissionsResult(
-            int requestCode, String[] permissions, int[] grantResults) {
-        Log.i(TAG, "Permission granted!");
-        if (allPermissionsGranted()) {
-            createCameraSource(selectedModel);
-        }
-        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
-    }
-
-    private static boolean isPermissionGranted(Context context, String permission) {
-        if (ContextCompat.checkSelfPermission(context, permission)
-                == PackageManager.PERMISSION_GRANTED) {
-            Log.i(TAG, "Permission granted: " + permission);
-            return true;
-        }
-        Log.i(TAG, "Permission NOT granted: " + permission);
-        return false;
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.content.Context;
+import android.content.Intent;
+import android.content.pm.PackageInfo;
+import android.content.pm.PackageManager;
+import android.os.Bundle;
+
+import androidx.core.app.ActivityCompat;
+import androidx.core.app.ActivityCompat.OnRequestPermissionsResultCallback;
+import androidx.core.content.ContextCompat;
+import androidx.appcompat.app.AppCompatActivity;
+
+import android.util.Log;
+import android.view.Menu;
+import android.view.MenuItem;
+import android.view.View;
+import android.widget.AdapterView;
+import android.widget.AdapterView.OnItemSelectedListener;
+import android.widget.ArrayAdapter;
+import android.widget.CompoundButton;
+import android.widget.ImageView;
+import android.widget.Spinner;
+import android.widget.Toast;
+import android.widget.ToggleButton;
+
+import com.google.android.gms.common.annotation.KeepName;
+import com.google.mlkit.common.model.LocalModel;
+import com.google.mlkit.vision.demo.automl.AutoMLImageLabelerProcessor;
+import com.google.mlkit.vision.demo.barcodescanner.BarcodeScannerProcessor;
+import com.google.mlkit.vision.demo.facedetector.FaceDetectorProcessor;
+import com.google.mlkit.vision.demo.labeldetector.LabelDetectorProcessor;
+import com.google.mlkit.vision.demo.objectdetector.ObjectDetectorProcessor;
+import com.google.mlkit.vision.demo.preference.PreferenceUtils;
+import com.google.mlkit.vision.demo.preference.SettingsActivity;
+import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource;
+import com.google.mlkit.vision.demo.textdetector.TextRecognitionProcessor;
+import com.google.mlkit.vision.face.FaceDetectorOptions;
+import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions;
+import com.google.mlkit.vision.label.defaults.ImageLabelerOptions;
+import com.google.mlkit.vision.objects.custom.CustomObjectDetectorOptions;
+import com.google.mlkit.vision.objects.defaults.ObjectDetectorOptions;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * Live preview demo for ML Kit APIs.
+ */
+@KeepName
+public final class LivePreviewActivity extends AppCompatActivity
+        implements OnRequestPermissionsResultCallback,
+        OnItemSelectedListener,
+        CompoundButton.OnCheckedChangeListener {
+    private static final String OBJECT_DETECTION = "Object Detection";
+    private static final String OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Birds)";
+    private static final String FACE_DETECTION = "Face Detection";
+    private static final String TEXT_RECOGNITION = "Text Recognition";
+    private static final String BARCODE_SCANNING = "Barcode Scanning";
+    private static final String IMAGE_LABELING = "Image Labeling";
+    private static final String IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Birds)";
+    private static final String AUTOML_LABELING = "AutoML Image Labeling";
+    private static final String TAG = "LivePreviewActivity";
+    private static final int PERMISSION_REQUESTS = 1;
+
+    private CameraSource cameraSource = null;
+    private CameraSourcePreview preview;
+    private GraphicOverlay graphicOverlay;
+    private String selectedModel = TEXT_RECOGNITION;
+
+    @Override
+    protected void onCreate(Bundle savedInstanceState) {
+        super.onCreate(savedInstanceState);
+        Log.d(TAG, "onCreate");
+
+        setContentView(R.layout.activity_live_preview);
+
+        preview = findViewById(R.id.preview);
+        if (preview == null) {
+            Log.d(TAG, "Preview is null");
+        }
+        graphicOverlay = findViewById(R.id.graphic_overlay);
+        if (graphicOverlay == null) {
+            Log.d(TAG, "graphicOverlay is null");
+        }
+
+        Spinner spinner = findViewById(R.id.spinner);
+        List<String> options = new ArrayList<>();
+        options.add(TEXT_RECOGNITION);
+        options.add(OBJECT_DETECTION);
+        options.add(OBJECT_DETECTION_CUSTOM);
+        options.add(FACE_DETECTION);
+
+        options.add(BARCODE_SCANNING);
+        options.add(IMAGE_LABELING);
+        options.add(IMAGE_LABELING_CUSTOM);
+        options.add(AUTOML_LABELING);
+        // Creating adapter for spinner
+        ArrayAdapter<String> dataAdapter = new ArrayAdapter<>(this, R.layout.spinner_style, options);
+        // Drop down layout style - list view with radio button
+        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
+        // attaching data adapter to spinner
+        spinner.setAdapter(dataAdapter);
+        spinner.setOnItemSelectedListener(this);
+
+        ToggleButton facingSwitch = findViewById(R.id.facing_switch);
+        facingSwitch.setOnCheckedChangeListener(this);
+
+        ImageView settingsButton = findViewById(R.id.settings_button);
+        settingsButton.setOnClickListener(
+                v -> {
+                    Intent intent = new Intent(getApplicationContext(), SettingsActivity.class);
+                    intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE,
+                            SettingsActivity.LaunchSource.LIVE_PREVIEW);
+                    startActivity(intent);
+                });
+
+        if (allPermissionsGranted()) {
+            createCameraSource(selectedModel);
+        } else {
+            getRuntimePermissions();
+        }
+    }
+
+    @Override
+    public boolean onCreateOptionsMenu(Menu menu) {
+        getMenuInflater().inflate(R.menu.live_preview_menu, menu);
+        return true;
+    }
+
+    @Override
+    public boolean onOptionsItemSelected(MenuItem item) {
+        if (item.getItemId() == R.id.settings) {
+            Intent intent = new Intent(this, SettingsActivity.class);
+            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE, LaunchSource.LIVE_PREVIEW);
+            startActivity(intent);
+            return true;
+        }
+
+        return super.onOptionsItemSelected(item);
+    }
+
+    @Override
+    public synchronized void onItemSelected(AdapterView<?> parent, View view, int pos, long id) {
+        // An item was selected. You can retrieve the selected item using
+        // parent.getItemAtPosition(pos)
+        selectedModel = parent.getItemAtPosition(pos).toString();
+        Log.d(TAG, "Selected model: " + selectedModel);
+        preview.stop();
+        if (allPermissionsGranted()) {
+            createCameraSource(selectedModel);
+            startCameraSource();
+        } else {
+            getRuntimePermissions();
+        }
+    }
+
+    @Override
+    public void onNothingSelected(AdapterView<?> parent) {
+        // Do nothing.
+    }
+
+    @Override
+    public void onCheckedChanged(CompoundButton buttonView, boolean isChecked) {
+        Log.d(TAG, "Set facing");
+        if (cameraSource != null) {
+            if (isChecked) {
+                cameraSource.setFacing(CameraSource.CAMERA_FACING_FRONT);
+            } else {
+                cameraSource.setFacing(CameraSource.CAMERA_FACING_BACK);
+            }
+        }
+        preview.stop();
+        startCameraSource();
+    }
+
+    private void createCameraSource(String model) {
+        // If there's no existing cameraSource, create one.
+        if (cameraSource == null) {
+            cameraSource = new CameraSource(this, graphicOverlay);
+        }
+
+        try {
+            switch (model) {
+                case OBJECT_DETECTION:
+                    Log.i(TAG, "Using Object Detector Processor");
+                    ObjectDetectorOptions objectDetectorOptions =
+                            PreferenceUtils.getObjectDetectorOptionsForLivePreview(this);
+                    cameraSource.setMachineLearningFrameProcessor(
+                            new ObjectDetectorProcessor(this, objectDetectorOptions));
+                    break;
+                case OBJECT_DETECTION_CUSTOM:
+                    Log.i(TAG, "Using Custom Object Detector Processor");
+                    LocalModel localModel =
+                            new LocalModel.Builder()
+                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
+                                    .build();
+                    CustomObjectDetectorOptions customObjectDetectorOptions =
+                            PreferenceUtils.getCustomObjectDetectorOptionsForLivePreview(this, localModel);
+                    cameraSource.setMachineLearningFrameProcessor(
+                            new ObjectDetectorProcessor(this, customObjectDetectorOptions));
+                    break;
+                case TEXT_RECOGNITION:
+                    Log.i(TAG, "Using on-device Text recognition Processor");
+                    cameraSource.setMachineLearningFrameProcessor(new TextRecognitionProcessor(this));
+                    break;
+                case FACE_DETECTION:
+                    Log.i(TAG, "Using Face Detector Processor");
+                    FaceDetectorOptions faceDetectorOptions =
+                            PreferenceUtils.getFaceDetectorOptionsForLivePreview(this);
+                    cameraSource.setMachineLearningFrameProcessor(
+                            new FaceDetectorProcessor(this, faceDetectorOptions));
+                    break;
+                case BARCODE_SCANNING:
+                    Log.i(TAG, "Using Barcode Detector Processor");
+                    cameraSource.setMachineLearningFrameProcessor(new BarcodeScannerProcessor(this));
+                    break;
+                case IMAGE_LABELING:
+                    Log.i(TAG, "Using Image Label Detector Processor");
+                    cameraSource.setMachineLearningFrameProcessor(
+                            new LabelDetectorProcessor(this, ImageLabelerOptions.DEFAULT_OPTIONS));
+                    break;
+                case IMAGE_LABELING_CUSTOM:
+                    Log.i(TAG, "Using Custom Image Label Detector Processor");
+                    LocalModel localClassifier =
+                            new LocalModel.Builder()
+                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
+                                    .build();
+                    CustomImageLabelerOptions customImageLabelerOptions =
+                            new CustomImageLabelerOptions.Builder(localClassifier).build();
+                    cameraSource.setMachineLearningFrameProcessor(
+                            new LabelDetectorProcessor(this, customImageLabelerOptions));
+                    break;
+                case AUTOML_LABELING:
+                    cameraSource.setMachineLearningFrameProcessor(
+                            new AutoMLImageLabelerProcessor(this));
+                    break;
+                default:
+                    Log.e(TAG, "Unknown model: " + model);
+            }
+        } catch (Exception e) {
+            Log.e(TAG, "Can not create image processor: " + model, e);
+            Toast.makeText(
+                    getApplicationContext(),
+                    "Can not create image processor: " + e.getMessage(),
+                    Toast.LENGTH_LONG)
+                    .show();
+        }
+    }
+
+    /**
+     * Starts or restarts the camera source, if it exists. If the camera source doesn't exist yet
+     * (e.g., because onResume was called before the camera source was created), this will be called
+     * again when the camera source is created.
+     */
+    private void startCameraSource() {
+        if (cameraSource != null) {
+            try {
+                if (preview == null) {
+                    Log.d(TAG, "resume: Preview is null");
+                }
+                if (graphicOverlay == null) {
+                    Log.d(TAG, "resume: graphOverlay is null");
+                }
+                preview.start(cameraSource, graphicOverlay);
+            } catch (IOException e) {
+                Log.e(TAG, "Unable to start camera source.", e);
+                cameraSource.release();
+                cameraSource = null;
+            }
+        }
+    }
+
+    @Override
+    public void onResume() {
+        super.onResume();
+        Log.d(TAG, "onResume");
+        createCameraSource(selectedModel);
+        startCameraSource();
+    }
+
+    /**
+     * Stops the camera.
+     */
+    @Override
+    protected void onPause() {
+        super.onPause();
+        preview.stop();
+    }
+
+    @Override
+    public void onDestroy() {
+        super.onDestroy();
+        if (cameraSource != null) {
+            cameraSource.release();
+        }
+    }
+
+    private String[] getRequiredPermissions() {
+        try {
+            PackageInfo info =
+                    this.getPackageManager()
+                            .getPackageInfo(this.getPackageName(), PackageManager.GET_PERMISSIONS);
+            String[] ps = info.requestedPermissions;
+            if (ps != null && ps.length > 0) {
+                return ps;
+            } else {
+                return new String[0];
+            }
+        } catch (Exception e) {
+            return new String[0];
+        }
+    }
+
+    private boolean allPermissionsGranted() {
+        for (String permission : getRequiredPermissions()) {
+            if (!isPermissionGranted(this, permission)) {
+                return false;
+            }
+        }
+        return true;
+    }
+
+    private void getRuntimePermissions() {
+        List<String> allNeededPermissions = new ArrayList<>();
+        for (String permission : getRequiredPermissions()) {
+            if (!isPermissionGranted(this, permission)) {
+                allNeededPermissions.add(permission);
+            }
+        }
+
+        if (!allNeededPermissions.isEmpty()) {
+            ActivityCompat.requestPermissions(
+                    this, allNeededPermissions.toArray(new String[0]), PERMISSION_REQUESTS);
+        }
+    }
+
+    @Override
+    public void onRequestPermissionsResult(
+            int requestCode, String[] permissions, int[] grantResults) {
+        Log.i(TAG, "Permission granted!");
+        if (allPermissionsGranted()) {
+            createCameraSource(selectedModel);
+        }
+        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
+    }
+
+    private static boolean isPermissionGranted(Context context, String permission) {
+        if (ContextCompat.checkSelfPermission(context, permission)
+                == PackageManager.PERMISSION_GRANTED) {
+            Log.i(TAG, "Permission granted: " + permission);
+            return true;
+        }
+        Log.i(TAG, "Permission NOT granted: " + permission);
+        return false;
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/ScopedExecutor.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/ScopedExecutor.java
index 7a19c2f..265dd33 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/ScopedExecutor.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/ScopedExecutor.java
@@ -1,62 +1,62 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import androidx.annotation.NonNull;
-
-import java.util.concurrent.Executor;
-import java.util.concurrent.atomic.AtomicBoolean;
-
-/**
- * Wraps an existing executor to provide a {@link #shutdown} method that allows subsequent
- * cancellation of submitted runnables.
- */
-public class ScopedExecutor implements Executor {
-
-    private final Executor executor;
-    private final AtomicBoolean shutdown = new AtomicBoolean();
-
-    public ScopedExecutor(@NonNull Executor executor) {
-        this.executor = executor;
-    }
-
-    @Override
-    public void execute(@NonNull Runnable command) {
-        // Return early if this object has been shut down.
-        if (shutdown.get()) {
-            return;
-        }
-        executor.execute(
-                () -> {
-                    // Check again in case it has been shut down in the mean time.
-                    if (shutdown.get()) {
-                        return;
-                    }
-                    command.run();
-                });
-    }
-
-    /**
-     * After this method is called, no runnables that have been submitted or are subsequently
-     * submitted will start to execute, turning this executor into a no-op.
-     *
-     * <p>Runnables that have already started to execute will continue.
-     */
-    public void shutdown() {
-        shutdown.set(true);
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import androidx.annotation.NonNull;
+
+import java.util.concurrent.Executor;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+/**
+ * Wraps an existing executor to provide a {@link #shutdown} method that allows subsequent
+ * cancellation of submitted runnables.
+ */
+public class ScopedExecutor implements Executor {
+
+    private final Executor executor;
+    private final AtomicBoolean shutdown = new AtomicBoolean();
+
+    public ScopedExecutor(@NonNull Executor executor) {
+        this.executor = executor;
+    }
+
+    @Override
+    public void execute(@NonNull Runnable command) {
+        // Return early if this object has been shut down.
+        if (shutdown.get()) {
+            return;
+        }
+        executor.execute(
+                () -> {
+                    // Check again in case it has been shut down in the mean time.
+                    if (shutdown.get()) {
+                        return;
+                    }
+                    command.run();
+                });
+    }
+
+    /**
+     * After this method is called, no runnables that have been submitted or are subsequently
+     * submitted will start to execute, turning this executor into a no-op.
+     *
+     * <p>Runnables that have already started to execute will continue.
+     */
+    public void shutdown() {
+        shutdown.set(true);
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/StillImageActivity.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/StillImageActivity.java
index 4e49e4e..6cc9a10 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/StillImageActivity.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/StillImageActivity.java
@@ -1,431 +1,431 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.content.ContentValues;
-import android.content.Intent;
-import android.content.res.Configuration;
-import android.graphics.Bitmap;
-import android.net.Uri;
-import android.os.Bundle;
-import android.provider.MediaStore;
-
-import android.view.ViewTreeObserver.OnGlobalLayoutListener;
-import androidx.appcompat.app.AppCompatActivity;
-
-import android.util.Log;
-import android.util.Pair;
-import android.view.Menu;
-import android.view.MenuInflater;
-import android.view.MenuItem;
-import android.view.View;
-import android.widget.AdapterView;
-import android.widget.AdapterView.OnItemSelectedListener;
-import android.widget.ArrayAdapter;
-import android.widget.ImageView;
-import android.widget.PopupMenu;
-import android.widget.Spinner;
-import android.widget.Toast;
-
-import com.google.android.gms.common.annotation.KeepName;
-import com.google.mlkit.common.model.LocalModel;
-import com.google.mlkit.vision.demo.automl.AutoMLImageLabelerProcessor;
-import com.google.mlkit.vision.demo.barcodescanner.BarcodeScannerProcessor;
-import com.google.mlkit.vision.demo.facedetector.FaceDetectorProcessor;
-import com.google.mlkit.vision.demo.labeldetector.LabelDetectorProcessor;
-import com.google.mlkit.vision.demo.objectdetector.ObjectDetectorProcessor;
-import com.google.mlkit.vision.demo.preference.PreferenceUtils;
-import com.google.mlkit.vision.demo.preference.SettingsActivity;
-import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource;
-import com.google.mlkit.vision.demo.textdetector.TextRecognitionProcessor;
-import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions;
-import com.google.mlkit.vision.label.defaults.ImageLabelerOptions;
-import com.google.mlkit.vision.objects.custom.CustomObjectDetectorOptions;
-import com.google.mlkit.vision.objects.defaults.ObjectDetectorOptions;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-/**
- * Activity demonstrating different image detector features with a still image from camera.
- */
-@KeepName
-public final class StillImageActivity extends AppCompatActivity {
-
-    private static final String TAG = "StillImageActivity";
-
-    private static final String OBJECT_DETECTION = "Object Detection";
-    private static final String OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Birds)";
-    private static final String FACE_DETECTION = "Face Detection";
-    private static final String BARCODE_SCANNING = "Barcode Scanning";
-    private static final String TEXT_RECOGNITION = "Text Recognition";
-    private static final String IMAGE_LABELING = "Image Labeling";
-    private static final String IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Birds)";
-    private static final String AUTOML_LABELING = "AutoML Labeling";
-
-    private static final String SIZE_SCREEN = "w:screen"; // Match screen width
-    private static final String SIZE_1024_768 = "w:1024"; // ~1024*768 in a normal ratio
-    private static final String SIZE_640_480 = "w:640"; // ~640*480 in a normal ratio
-
-    private static final String KEY_IMAGE_URI = "com.google.mlkit.vision.demo.KEY_IMAGE_URI";
-    private static final String KEY_SELECTED_SIZE = "com.google.mlkit.vision.demo.KEY_SELECTED_SIZE";
-
-    private static final int REQUEST_IMAGE_CAPTURE = 1001;
-    private static final int REQUEST_CHOOSE_IMAGE = 1002;
-
-    private ImageView preview;
-    private GraphicOverlay graphicOverlay;
-    private String selectedMode = OBJECT_DETECTION;
-    private String selectedSize = SIZE_SCREEN;
-
-    boolean isLandScape;
-
-    private Uri imageUri;
-    private int imageMaxWidth;
-    private int imageMaxHeight;
-    private VisionImageProcessor imageProcessor;
-
-    @Override
-    protected void onCreate(Bundle savedInstanceState) {
-        super.onCreate(savedInstanceState);
-
-        setContentView(R.layout.activity_still_image);
-
-        findViewById(R.id.select_image_button)
-                .setOnClickListener(
-                        view -> {
-                            // Menu for selecting either: a) take new photo b) select from existing
-                            PopupMenu popup = new PopupMenu(StillImageActivity.this, view);
-                            popup.setOnMenuItemClickListener(
-                                    menuItem -> {
-                                        int itemId = menuItem.getItemId();
-                                        if (itemId == R.id.select_images_from_local) {
-                                            startChooseImageIntentForResult();
-                                            return true;
-                                        } else if (itemId == R.id.take_photo_using_camera) {
-                                            startCameraIntentForResult();
-                                            return true;
-                                        }
-                                        return false;
-                                    });
-                            MenuInflater inflater = popup.getMenuInflater();
-                            inflater.inflate(R.menu.camera_button_menu, popup.getMenu());
-                            popup.show();
-                        });
-        preview = findViewById(R.id.preview);
-        graphicOverlay = findViewById(R.id.graphic_overlay);
-
-        populateFeatureSelector();
-        populateSizeSelector();
-
-        isLandScape =
-                (getResources().getConfiguration().orientation == Configuration.ORIENTATION_LANDSCAPE);
-
-        if (savedInstanceState != null) {
-            imageUri = savedInstanceState.getParcelable(KEY_IMAGE_URI);
-            selectedSize = savedInstanceState.getString(KEY_SELECTED_SIZE);
-        }
-
-        View rootView = findViewById(R.id.root);
-        rootView.getViewTreeObserver().addOnGlobalLayoutListener(new OnGlobalLayoutListener() {
-            @Override
-            public void onGlobalLayout() {
-                rootView.getViewTreeObserver().removeOnGlobalLayoutListener(this);
-                imageMaxWidth = rootView.getWidth();
-                imageMaxHeight = rootView.getHeight() - findViewById(R.id.control).getHeight();
-                if (SIZE_SCREEN.equals(selectedSize)) {
-                    tryReloadAndDetectInImage();
-                }
-            }
-        });
-
-        ImageView settingsButton = findViewById(R.id.settings_button);
-        settingsButton.setOnClickListener(v -> {
-            Intent intent = new Intent(getApplicationContext(), SettingsActivity.class);
-            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE,
-                    SettingsActivity.LaunchSource.STILL_IMAGE);
-            startActivity(intent);
-        });
-    }
-
-    @Override
-    public void onResume() {
-        super.onResume();
-        Log.d(TAG, "onResume");
-        createImageProcessor();
-        tryReloadAndDetectInImage();
-    }
-
-    @Override
-    public boolean onCreateOptionsMenu(Menu menu) {
-        getMenuInflater().inflate(R.menu.still_image_menu, menu);
-        return true;
-    }
-
-    @Override
-    public boolean onOptionsItemSelected(MenuItem item) {
-        if (item.getItemId() == R.id.settings) {
-            Intent intent = new Intent(this, SettingsActivity.class);
-            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE, LaunchSource.STILL_IMAGE);
-            startActivity(intent);
-            return true;
-        }
-
-        return super.onOptionsItemSelected(item);
-    }
-
-    private void populateFeatureSelector() {
-        Spinner featureSpinner = findViewById(R.id.feature_selector);
-        List<String> options = new ArrayList<>();
-        options.add(OBJECT_DETECTION);
-        options.add(OBJECT_DETECTION_CUSTOM);
-        options.add(FACE_DETECTION);
-        options.add(BARCODE_SCANNING);
-        options.add(TEXT_RECOGNITION);
-        options.add(IMAGE_LABELING);
-        options.add(IMAGE_LABELING_CUSTOM);
-        options.add(AUTOML_LABELING);
-
-        // Creating adapter for featureSpinner
-        ArrayAdapter<String> dataAdapter = new ArrayAdapter<>(this, R.layout.spinner_style, options);
-        // Drop down layout style - list view with radio button
-        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
-        // attaching data adapter to spinner
-        featureSpinner.setAdapter(dataAdapter);
-        featureSpinner.setOnItemSelectedListener(
-                new OnItemSelectedListener() {
-
-                    @Override
-                    public void onItemSelected(
-                            AdapterView<?> parentView, View selectedItemView, int pos, long id) {
-                        selectedMode = parentView.getItemAtPosition(pos).toString();
-                        createImageProcessor();
-                        tryReloadAndDetectInImage();
-                    }
-
-                    @Override
-                    public void onNothingSelected(AdapterView<?> arg0) {
-                    }
-                });
-    }
-
-    private void populateSizeSelector() {
-        Spinner sizeSpinner = findViewById(R.id.size_selector);
-        List<String> options = new ArrayList<>();
-        options.add(SIZE_SCREEN);
-        options.add(SIZE_1024_768);
-        options.add(SIZE_640_480);
-
-        // Creating adapter for featureSpinner
-        ArrayAdapter<String> dataAdapter = new ArrayAdapter<>(this, R.layout.spinner_style, options);
-        // Drop down layout style - list view with radio button
-        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
-        // attaching data adapter to spinner
-        sizeSpinner.setAdapter(dataAdapter);
-        sizeSpinner.setOnItemSelectedListener(
-                new OnItemSelectedListener() {
-
-                    @Override
-                    public void onItemSelected(
-                            AdapterView<?> parentView, View selectedItemView, int pos, long id) {
-                        selectedSize = parentView.getItemAtPosition(pos).toString();
-                        createImageProcessor();
-                        tryReloadAndDetectInImage();
-                    }
-
-                    @Override
-                    public void onNothingSelected(AdapterView<?> arg0) {
-                    }
-                });
-    }
-
-    @Override
-    public void onSaveInstanceState(Bundle outState) {
-        super.onSaveInstanceState(outState);
-        outState.putParcelable(KEY_IMAGE_URI, imageUri);
-        outState.putString(KEY_SELECTED_SIZE, selectedSize);
-    }
-
-    private void startCameraIntentForResult() {
-        // Clean up last time's image
-        imageUri = null;
-        preview.setImageBitmap(null);
-
-        Intent takePictureIntent = new Intent(MediaStore.ACTION_IMAGE_CAPTURE);
-        if (takePictureIntent.resolveActivity(getPackageManager()) != null) {
-            ContentValues values = new ContentValues();
-            values.put(MediaStore.Images.Media.TITLE, "New Picture");
-            values.put(MediaStore.Images.Media.DESCRIPTION, "From Camera");
-            imageUri = getContentResolver().insert(MediaStore.Images.Media.EXTERNAL_CONTENT_URI, values);
-            takePictureIntent.putExtra(MediaStore.EXTRA_OUTPUT, imageUri);
-            startActivityForResult(takePictureIntent, REQUEST_IMAGE_CAPTURE);
-        }
-    }
-
-    private void startChooseImageIntentForResult() {
-        Intent intent = new Intent();
-        intent.setType("image/*");
-        intent.setAction(Intent.ACTION_GET_CONTENT);
-        startActivityForResult(Intent.createChooser(intent, "Select Picture"), REQUEST_CHOOSE_IMAGE);
-    }
-
-    @Override
-    protected void onActivityResult(int requestCode, int resultCode, Intent data) {
-        if (requestCode == REQUEST_IMAGE_CAPTURE && resultCode == RESULT_OK) {
-            tryReloadAndDetectInImage();
-        } else if (requestCode == REQUEST_CHOOSE_IMAGE && resultCode == RESULT_OK) {
-            // In this case, imageUri is returned by the chooser, save it.
-            imageUri = data.getData();
-            tryReloadAndDetectInImage();
-        } else {
-            super.onActivityResult(requestCode, resultCode, data);
-        }
-    }
-
-    private void tryReloadAndDetectInImage() {
-        Log.d(TAG, "Try reload and detect image");
-        try {
-            if (imageUri == null) {
-                return;
-            }
-
-            if (SIZE_SCREEN.equals(selectedSize) && imageMaxWidth == 0) {
-                // UI layout has not finished yet, will reload once it's ready.
-                return;
-            }
-
-            Bitmap imageBitmap = BitmapUtils.getBitmapFromContentUri(getContentResolver(), imageUri);
-            if (imageBitmap == null) {
-                return;
-            }
-
-            // Clear the overlay first
-            graphicOverlay.clear();
-
-            // Get the dimensions of the image view
-            Pair<Integer, Integer> targetedSize = getTargetedWidthHeight();
-
-            // Determine how much to scale down the image
-            float scaleFactor =
-                    Math.max(
-                            (float) imageBitmap.getWidth() / (float) targetedSize.first,
-                            (float) imageBitmap.getHeight() / (float) targetedSize.second);
-
-            Bitmap resizedBitmap =
-                    Bitmap.createScaledBitmap(
-                            imageBitmap,
-                            (int) (imageBitmap.getWidth() / scaleFactor),
-                            (int) (imageBitmap.getHeight() / scaleFactor),
-                            true);
-
-            preview.setImageBitmap(resizedBitmap);
-
-            if (imageProcessor != null) {
-                graphicOverlay.setImageSourceInfo(
-                        resizedBitmap.getWidth(), resizedBitmap.getHeight(), /* isFlipped= */ false);
-                imageProcessor.processBitmap(resizedBitmap, graphicOverlay);
-            } else {
-                Log.e(TAG, "Null imageProcessor, please check adb logs for imageProcessor creation error");
-            }
-        } catch (IOException e) {
-            Log.e(TAG, "Error retrieving saved image");
-            imageUri = null;
-        }
-    }
-
-    private Pair<Integer, Integer> getTargetedWidthHeight() {
-        int targetWidth;
-        int targetHeight;
-
-        switch (selectedSize) {
-            case SIZE_SCREEN:
-                targetWidth = imageMaxWidth;
-                targetHeight = imageMaxHeight;
-                break;
-            case SIZE_640_480:
-                targetWidth = isLandScape ? 640 : 480;
-                targetHeight = isLandScape ? 480 : 640;
-                break;
-            case SIZE_1024_768:
-                targetWidth = isLandScape ? 1024 : 768;
-                targetHeight = isLandScape ? 768 : 1024;
-                break;
-            default:
-                throw new IllegalStateException("Unknown size");
-        }
-
-        return new Pair<>(targetWidth, targetHeight);
-    }
-
-    private void createImageProcessor() {
-        try {
-            switch (selectedMode) {
-                case OBJECT_DETECTION:
-                    Log.i(TAG, "Using Object Detector Processor");
-                    ObjectDetectorOptions objectDetectorOptions =
-                            PreferenceUtils.getObjectDetectorOptionsForStillImage(this);
-                    imageProcessor = new ObjectDetectorProcessor(this, objectDetectorOptions);
-                    break;
-                case OBJECT_DETECTION_CUSTOM:
-                    Log.i(TAG, "Using Custom Object Detector Processor");
-                    LocalModel localModel =
-                            new LocalModel.Builder()
-                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
-                                    .build();
-                    CustomObjectDetectorOptions customObjectDetectorOptions =
-                            PreferenceUtils.getCustomObjectDetectorOptionsForStillImage(this, localModel);
-                    imageProcessor = new ObjectDetectorProcessor(this, customObjectDetectorOptions);
-                    break;
-                case FACE_DETECTION:
-                    imageProcessor = new FaceDetectorProcessor(this);
-                    break;
-                case BARCODE_SCANNING:
-                    imageProcessor = new BarcodeScannerProcessor(this);
-                    break;
-                case TEXT_RECOGNITION:
-                    imageProcessor = new TextRecognitionProcessor(this);
-                    break;
-                case IMAGE_LABELING:
-                    imageProcessor = new LabelDetectorProcessor(this, ImageLabelerOptions.DEFAULT_OPTIONS);
-                    break;
-                case IMAGE_LABELING_CUSTOM:
-                    Log.i(TAG, "Using Custom Image Label Detector Processor");
-                    LocalModel localClassifier =
-                            new LocalModel.Builder()
-                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
-                                    .build();
-                    CustomImageLabelerOptions customImageLabelerOptions =
-                            new CustomImageLabelerOptions.Builder(localClassifier).build();
-                    imageProcessor = new LabelDetectorProcessor(this, customImageLabelerOptions);
-                    break;
-                case AUTOML_LABELING:
-                    imageProcessor = new AutoMLImageLabelerProcessor(this);
-                    break;
-                default:
-                    Log.e(TAG, "Unknown selectedMode: " + selectedMode);
-            }
-        } catch (Exception e) {
-            Log.e(TAG, "Can not create image processor: " + selectedMode, e);
-            Toast.makeText(
-                    getApplicationContext(),
-                    "Can not create image processor: " + e.getMessage(),
-                    Toast.LENGTH_LONG)
-                    .show();
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.content.ContentValues;
+import android.content.Intent;
+import android.content.res.Configuration;
+import android.graphics.Bitmap;
+import android.net.Uri;
+import android.os.Bundle;
+import android.provider.MediaStore;
+
+import android.view.ViewTreeObserver.OnGlobalLayoutListener;
+import androidx.appcompat.app.AppCompatActivity;
+
+import android.util.Log;
+import android.util.Pair;
+import android.view.Menu;
+import android.view.MenuInflater;
+import android.view.MenuItem;
+import android.view.View;
+import android.widget.AdapterView;
+import android.widget.AdapterView.OnItemSelectedListener;
+import android.widget.ArrayAdapter;
+import android.widget.ImageView;
+import android.widget.PopupMenu;
+import android.widget.Spinner;
+import android.widget.Toast;
+
+import com.google.android.gms.common.annotation.KeepName;
+import com.google.mlkit.common.model.LocalModel;
+import com.google.mlkit.vision.demo.automl.AutoMLImageLabelerProcessor;
+import com.google.mlkit.vision.demo.barcodescanner.BarcodeScannerProcessor;
+import com.google.mlkit.vision.demo.facedetector.FaceDetectorProcessor;
+import com.google.mlkit.vision.demo.labeldetector.LabelDetectorProcessor;
+import com.google.mlkit.vision.demo.objectdetector.ObjectDetectorProcessor;
+import com.google.mlkit.vision.demo.preference.PreferenceUtils;
+import com.google.mlkit.vision.demo.preference.SettingsActivity;
+import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource;
+import com.google.mlkit.vision.demo.textdetector.TextRecognitionProcessor;
+import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions;
+import com.google.mlkit.vision.label.defaults.ImageLabelerOptions;
+import com.google.mlkit.vision.objects.custom.CustomObjectDetectorOptions;
+import com.google.mlkit.vision.objects.defaults.ObjectDetectorOptions;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * Activity demonstrating different image detector features with a still image from camera.
+ */
+@KeepName
+public final class StillImageActivity extends AppCompatActivity {
+
+    private static final String TAG = "StillImageActivity";
+
+    private static final String OBJECT_DETECTION = "Object Detection";
+    private static final String OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Birds)";
+    private static final String FACE_DETECTION = "Face Detection";
+    private static final String BARCODE_SCANNING = "Barcode Scanning";
+    private static final String TEXT_RECOGNITION = "Text Recognition";
+    private static final String IMAGE_LABELING = "Image Labeling";
+    private static final String IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Birds)";
+    private static final String AUTOML_LABELING = "AutoML Labeling";
+
+    private static final String SIZE_SCREEN = "w:screen"; // Match screen width
+    private static final String SIZE_1024_768 = "w:1024"; // ~1024*768 in a normal ratio
+    private static final String SIZE_640_480 = "w:640"; // ~640*480 in a normal ratio
+
+    private static final String KEY_IMAGE_URI = "com.google.mlkit.vision.demo.KEY_IMAGE_URI";
+    private static final String KEY_SELECTED_SIZE = "com.google.mlkit.vision.demo.KEY_SELECTED_SIZE";
+
+    private static final int REQUEST_IMAGE_CAPTURE = 1001;
+    private static final int REQUEST_CHOOSE_IMAGE = 1002;
+
+    private ImageView preview;
+    private GraphicOverlay graphicOverlay;
+    private String selectedMode = OBJECT_DETECTION;
+    private String selectedSize = SIZE_SCREEN;
+
+    boolean isLandScape;
+
+    private Uri imageUri;
+    private int imageMaxWidth;
+    private int imageMaxHeight;
+    private VisionImageProcessor imageProcessor;
+
+    @Override
+    protected void onCreate(Bundle savedInstanceState) {
+        super.onCreate(savedInstanceState);
+
+        setContentView(R.layout.activity_still_image);
+
+        findViewById(R.id.select_image_button)
+                .setOnClickListener(
+                        view -> {
+                            // Menu for selecting either: a) take new photo b) select from existing
+                            PopupMenu popup = new PopupMenu(StillImageActivity.this, view);
+                            popup.setOnMenuItemClickListener(
+                                    menuItem -> {
+                                        int itemId = menuItem.getItemId();
+                                        if (itemId == R.id.select_images_from_local) {
+                                            startChooseImageIntentForResult();
+                                            return true;
+                                        } else if (itemId == R.id.take_photo_using_camera) {
+                                            startCameraIntentForResult();
+                                            return true;
+                                        }
+                                        return false;
+                                    });
+                            MenuInflater inflater = popup.getMenuInflater();
+                            inflater.inflate(R.menu.camera_button_menu, popup.getMenu());
+                            popup.show();
+                        });
+        preview = findViewById(R.id.preview);
+        graphicOverlay = findViewById(R.id.graphic_overlay);
+
+        populateFeatureSelector();
+        populateSizeSelector();
+
+        isLandScape =
+                (getResources().getConfiguration().orientation == Configuration.ORIENTATION_LANDSCAPE);
+
+        if (savedInstanceState != null) {
+            imageUri = savedInstanceState.getParcelable(KEY_IMAGE_URI);
+            selectedSize = savedInstanceState.getString(KEY_SELECTED_SIZE);
+        }
+
+        View rootView = findViewById(R.id.root);
+        rootView.getViewTreeObserver().addOnGlobalLayoutListener(new OnGlobalLayoutListener() {
+            @Override
+            public void onGlobalLayout() {
+                rootView.getViewTreeObserver().removeOnGlobalLayoutListener(this);
+                imageMaxWidth = rootView.getWidth();
+                imageMaxHeight = rootView.getHeight() - findViewById(R.id.control).getHeight();
+                if (SIZE_SCREEN.equals(selectedSize)) {
+                    tryReloadAndDetectInImage();
+                }
+            }
+        });
+
+        ImageView settingsButton = findViewById(R.id.settings_button);
+        settingsButton.setOnClickListener(v -> {
+            Intent intent = new Intent(getApplicationContext(), SettingsActivity.class);
+            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE,
+                    SettingsActivity.LaunchSource.STILL_IMAGE);
+            startActivity(intent);
+        });
+    }
+
+    @Override
+    public void onResume() {
+        super.onResume();
+        Log.d(TAG, "onResume");
+        createImageProcessor();
+        tryReloadAndDetectInImage();
+    }
+
+    @Override
+    public boolean onCreateOptionsMenu(Menu menu) {
+        getMenuInflater().inflate(R.menu.still_image_menu, menu);
+        return true;
+    }
+
+    @Override
+    public boolean onOptionsItemSelected(MenuItem item) {
+        if (item.getItemId() == R.id.settings) {
+            Intent intent = new Intent(this, SettingsActivity.class);
+            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE, LaunchSource.STILL_IMAGE);
+            startActivity(intent);
+            return true;
+        }
+
+        return super.onOptionsItemSelected(item);
+    }
+
+    private void populateFeatureSelector() {
+        Spinner featureSpinner = findViewById(R.id.feature_selector);
+        List<String> options = new ArrayList<>();
+        options.add(OBJECT_DETECTION);
+        options.add(OBJECT_DETECTION_CUSTOM);
+        options.add(FACE_DETECTION);
+        options.add(BARCODE_SCANNING);
+        options.add(TEXT_RECOGNITION);
+        options.add(IMAGE_LABELING);
+        options.add(IMAGE_LABELING_CUSTOM);
+        options.add(AUTOML_LABELING);
+
+        // Creating adapter for featureSpinner
+        ArrayAdapter<String> dataAdapter = new ArrayAdapter<>(this, R.layout.spinner_style, options);
+        // Drop down layout style - list view with radio button
+        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
+        // attaching data adapter to spinner
+        featureSpinner.setAdapter(dataAdapter);
+        featureSpinner.setOnItemSelectedListener(
+                new OnItemSelectedListener() {
+
+                    @Override
+                    public void onItemSelected(
+                            AdapterView<?> parentView, View selectedItemView, int pos, long id) {
+                        selectedMode = parentView.getItemAtPosition(pos).toString();
+                        createImageProcessor();
+                        tryReloadAndDetectInImage();
+                    }
+
+                    @Override
+                    public void onNothingSelected(AdapterView<?> arg0) {
+                    }
+                });
+    }
+
+    private void populateSizeSelector() {
+        Spinner sizeSpinner = findViewById(R.id.size_selector);
+        List<String> options = new ArrayList<>();
+        options.add(SIZE_SCREEN);
+        options.add(SIZE_1024_768);
+        options.add(SIZE_640_480);
+
+        // Creating adapter for featureSpinner
+        ArrayAdapter<String> dataAdapter = new ArrayAdapter<>(this, R.layout.spinner_style, options);
+        // Drop down layout style - list view with radio button
+        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
+        // attaching data adapter to spinner
+        sizeSpinner.setAdapter(dataAdapter);
+        sizeSpinner.setOnItemSelectedListener(
+                new OnItemSelectedListener() {
+
+                    @Override
+                    public void onItemSelected(
+                            AdapterView<?> parentView, View selectedItemView, int pos, long id) {
+                        selectedSize = parentView.getItemAtPosition(pos).toString();
+                        createImageProcessor();
+                        tryReloadAndDetectInImage();
+                    }
+
+                    @Override
+                    public void onNothingSelected(AdapterView<?> arg0) {
+                    }
+                });
+    }
+
+    @Override
+    public void onSaveInstanceState(Bundle outState) {
+        super.onSaveInstanceState(outState);
+        outState.putParcelable(KEY_IMAGE_URI, imageUri);
+        outState.putString(KEY_SELECTED_SIZE, selectedSize);
+    }
+
+    private void startCameraIntentForResult() {
+        // Clean up last time's image
+        imageUri = null;
+        preview.setImageBitmap(null);
+
+        Intent takePictureIntent = new Intent(MediaStore.ACTION_IMAGE_CAPTURE);
+        if (takePictureIntent.resolveActivity(getPackageManager()) != null) {
+            ContentValues values = new ContentValues();
+            values.put(MediaStore.Images.Media.TITLE, "New Picture");
+            values.put(MediaStore.Images.Media.DESCRIPTION, "From Camera");
+            imageUri = getContentResolver().insert(MediaStore.Images.Media.EXTERNAL_CONTENT_URI, values);
+            takePictureIntent.putExtra(MediaStore.EXTRA_OUTPUT, imageUri);
+            startActivityForResult(takePictureIntent, REQUEST_IMAGE_CAPTURE);
+        }
+    }
+
+    private void startChooseImageIntentForResult() {
+        Intent intent = new Intent();
+        intent.setType("image/*");
+        intent.setAction(Intent.ACTION_GET_CONTENT);
+        startActivityForResult(Intent.createChooser(intent, "Select Picture"), REQUEST_CHOOSE_IMAGE);
+    }
+
+    @Override
+    protected void onActivityResult(int requestCode, int resultCode, Intent data) {
+        if (requestCode == REQUEST_IMAGE_CAPTURE && resultCode == RESULT_OK) {
+            tryReloadAndDetectInImage();
+        } else if (requestCode == REQUEST_CHOOSE_IMAGE && resultCode == RESULT_OK) {
+            // In this case, imageUri is returned by the chooser, save it.
+            imageUri = data.getData();
+            tryReloadAndDetectInImage();
+        } else {
+            super.onActivityResult(requestCode, resultCode, data);
+        }
+    }
+
+    private void tryReloadAndDetectInImage() {
+        Log.d(TAG, "Try reload and detect image");
+        try {
+            if (imageUri == null) {
+                return;
+            }
+
+            if (SIZE_SCREEN.equals(selectedSize) && imageMaxWidth == 0) {
+                // UI layout has not finished yet, will reload once it's ready.
+                return;
+            }
+
+            Bitmap imageBitmap = BitmapUtils.getBitmapFromContentUri(getContentResolver(), imageUri);
+            if (imageBitmap == null) {
+                return;
+            }
+
+            // Clear the overlay first
+            graphicOverlay.clear();
+
+            // Get the dimensions of the image view
+            Pair<Integer, Integer> targetedSize = getTargetedWidthHeight();
+
+            // Determine how much to scale down the image
+            float scaleFactor =
+                    Math.max(
+                            (float) imageBitmap.getWidth() / (float) targetedSize.first,
+                            (float) imageBitmap.getHeight() / (float) targetedSize.second);
+
+            Bitmap resizedBitmap =
+                    Bitmap.createScaledBitmap(
+                            imageBitmap,
+                            (int) (imageBitmap.getWidth() / scaleFactor),
+                            (int) (imageBitmap.getHeight() / scaleFactor),
+                            true);
+
+            preview.setImageBitmap(resizedBitmap);
+
+            if (imageProcessor != null) {
+                graphicOverlay.setImageSourceInfo(
+                        resizedBitmap.getWidth(), resizedBitmap.getHeight(), /* isFlipped= */ false);
+                imageProcessor.processBitmap(resizedBitmap, graphicOverlay);
+            } else {
+                Log.e(TAG, "Null imageProcessor, please check adb logs for imageProcessor creation error");
+            }
+        } catch (IOException e) {
+            Log.e(TAG, "Error retrieving saved image");
+            imageUri = null;
+        }
+    }
+
+    private Pair<Integer, Integer> getTargetedWidthHeight() {
+        int targetWidth;
+        int targetHeight;
+
+        switch (selectedSize) {
+            case SIZE_SCREEN:
+                targetWidth = imageMaxWidth;
+                targetHeight = imageMaxHeight;
+                break;
+            case SIZE_640_480:
+                targetWidth = isLandScape ? 640 : 480;
+                targetHeight = isLandScape ? 480 : 640;
+                break;
+            case SIZE_1024_768:
+                targetWidth = isLandScape ? 1024 : 768;
+                targetHeight = isLandScape ? 768 : 1024;
+                break;
+            default:
+                throw new IllegalStateException("Unknown size");
+        }
+
+        return new Pair<>(targetWidth, targetHeight);
+    }
+
+    private void createImageProcessor() {
+        try {
+            switch (selectedMode) {
+                case OBJECT_DETECTION:
+                    Log.i(TAG, "Using Object Detector Processor");
+                    ObjectDetectorOptions objectDetectorOptions =
+                            PreferenceUtils.getObjectDetectorOptionsForStillImage(this);
+                    imageProcessor = new ObjectDetectorProcessor(this, objectDetectorOptions);
+                    break;
+                case OBJECT_DETECTION_CUSTOM:
+                    Log.i(TAG, "Using Custom Object Detector Processor");
+                    LocalModel localModel =
+                            new LocalModel.Builder()
+                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
+                                    .build();
+                    CustomObjectDetectorOptions customObjectDetectorOptions =
+                            PreferenceUtils.getCustomObjectDetectorOptionsForStillImage(this, localModel);
+                    imageProcessor = new ObjectDetectorProcessor(this, customObjectDetectorOptions);
+                    break;
+                case FACE_DETECTION:
+                    imageProcessor = new FaceDetectorProcessor(this);
+                    break;
+                case BARCODE_SCANNING:
+                    imageProcessor = new BarcodeScannerProcessor(this);
+                    break;
+                case TEXT_RECOGNITION:
+                    imageProcessor = new TextRecognitionProcessor(this);
+                    break;
+                case IMAGE_LABELING:
+                    imageProcessor = new LabelDetectorProcessor(this, ImageLabelerOptions.DEFAULT_OPTIONS);
+                    break;
+                case IMAGE_LABELING_CUSTOM:
+                    Log.i(TAG, "Using Custom Image Label Detector Processor");
+                    LocalModel localClassifier =
+                            new LocalModel.Builder()
+                                    .setAssetFilePath("custom_models/bird_classifier.tflite")
+                                    .build();
+                    CustomImageLabelerOptions customImageLabelerOptions =
+                            new CustomImageLabelerOptions.Builder(localClassifier).build();
+                    imageProcessor = new LabelDetectorProcessor(this, customImageLabelerOptions);
+                    break;
+                case AUTOML_LABELING:
+                    imageProcessor = new AutoMLImageLabelerProcessor(this);
+                    break;
+                default:
+                    Log.e(TAG, "Unknown selectedMode: " + selectedMode);
+            }
+        } catch (Exception e) {
+            Log.e(TAG, "Can not create image processor: " + selectedMode, e);
+            Toast.makeText(
+                    getApplicationContext(),
+                    "Can not create image processor: " + e.getMessage(),
+                    Toast.LENGTH_LONG)
+                    .show();
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/VisionImageProcessor.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/VisionImageProcessor.java
index bbb9d2d..ea51725 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/VisionImageProcessor.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/VisionImageProcessor.java
@@ -1,57 +1,57 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.graphics.Bitmap;
-import android.os.Build.VERSION_CODES;
-
-import androidx.annotation.RequiresApi;
-import androidx.camera.core.ImageProxy;
-
-import com.google.mlkit.common.MlKitException;
-
-import java.nio.ByteBuffer;
-
-/**
- * An interface to process the images with different vision detectors and custom image models.
- */
-public interface VisionImageProcessor {
-
-    /**
-     * Processes a bitmap image.
-     */
-    void processBitmap(Bitmap bitmap, GraphicOverlay graphicOverlay);
-
-    /**
-     * Processes ByteBuffer image data, e.g. used for Camera1 live preview case.
-     */
-    void processByteBuffer(
-            ByteBuffer data, FrameMetadata frameMetadata, GraphicOverlay graphicOverlay)
-            throws MlKitException;
-
-    /**
-     * Processes ImageProxy image data, e.g. used for CameraX live preview case.
-     */
-    @RequiresApi(VERSION_CODES.KITKAT)
-    void processImageProxy(ImageProxy image, GraphicOverlay graphicOverlay)
-            throws MlKitException;
-
-    /**
-     * Stops the underlying machine learning model and release resources.
-     */
-    void stop();
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.graphics.Bitmap;
+import android.os.Build.VERSION_CODES;
+
+import androidx.annotation.RequiresApi;
+import androidx.camera.core.ImageProxy;
+
+import com.google.mlkit.common.MlKitException;
+
+import java.nio.ByteBuffer;
+
+/**
+ * An interface to process the images with different vision detectors and custom image models.
+ */
+public interface VisionImageProcessor {
+
+    /**
+     * Processes a bitmap image.
+     */
+    void processBitmap(Bitmap bitmap, GraphicOverlay graphicOverlay);
+
+    /**
+     * Processes ByteBuffer image data, e.g. used for Camera1 live preview case.
+     */
+    void processByteBuffer(
+            ByteBuffer data, FrameMetadata frameMetadata, GraphicOverlay graphicOverlay)
+            throws MlKitException;
+
+    /**
+     * Processes ImageProxy image data, e.g. used for CameraX live preview case.
+     */
+    @RequiresApi(VERSION_CODES.KITKAT)
+    void processImageProxy(ImageProxy image, GraphicOverlay graphicOverlay)
+            throws MlKitException;
+
+    /**
+     * Stops the underlying machine learning model and release resources.
+     */
+    void stop();
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/VisionProcessorBase.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/VisionProcessorBase.java
index ae50702..700e556 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/VisionProcessorBase.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/VisionProcessorBase.java
@@ -1,249 +1,249 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo;
-
-import android.app.ActivityManager;
-import android.app.ActivityManager.MemoryInfo;
-import android.content.Context;
-import android.graphics.Bitmap;
-import android.os.Build.VERSION_CODES;
-import android.os.SystemClock;
-import android.util.Log;
-import android.widget.Toast;
-
-import androidx.annotation.GuardedBy;
-import androidx.annotation.NonNull;
-import androidx.annotation.Nullable;
-import androidx.annotation.RequiresApi;
-import androidx.camera.core.ExperimentalGetImage;
-import androidx.camera.core.ImageProxy;
-
-import com.google.android.gms.tasks.Task;
-import com.google.android.gms.tasks.TaskExecutors;
-import com.google.mlkit.vision.common.InputImage;
-import com.google.mlkit.vision.demo.preference.PreferenceUtils;
-
-import java.nio.ByteBuffer;
-import java.util.Timer;
-import java.util.TimerTask;
-
-/**
- * Abstract base class for vision frame processors. Subclasses need to implement {@link
- * #onSuccess(Object, GraphicOverlay)} to define what they want to with the detection results and
- * {@link #detectInImage(InputImage)} to specify the detector object.
- *
- * @param <T> The type of the detected feature.
- */
-public abstract class VisionProcessorBase<T> implements VisionImageProcessor {
-
-    protected static final String MANUAL_TESTING_LOG = "LogTagForTest";
-    private static final String TAG = "VisionProcessorBase";
-
-    private final ActivityManager activityManager;
-    private final Timer fpsTimer = new Timer();
-    private final ScopedExecutor executor;
-
-    // Whether this processor is already shut down
-    private boolean isShutdown;
-
-    // Used to calculate latency, running in the same thread, no sync needed.
-    private int numRuns = 0;
-    private long totalRunMs = 0;
-    private long maxRunMs = 0;
-    private long minRunMs = Long.MAX_VALUE;
-
-    // Frame count that have been processed so far in an one second interval to calculate FPS.
-    private int frameProcessedInOneSecondInterval = 0;
-    private int framesPerSecond = 0;
-
-    // To keep the latest images and its metadata.
-    @GuardedBy("this")
-    private ByteBuffer latestImage;
-    @GuardedBy("this")
-    private FrameMetadata latestImageMetaData;
-    // To keep the images and metadata in process.
-    @GuardedBy("this")
-    private ByteBuffer processingImage;
-    @GuardedBy("this")
-    private FrameMetadata processingMetaData;
-
-    protected VisionProcessorBase(Context context) {
-        activityManager = (ActivityManager) context.getSystemService(Context.ACTIVITY_SERVICE);
-        executor = new ScopedExecutor(TaskExecutors.MAIN_THREAD);
-        fpsTimer.scheduleAtFixedRate(
-                new TimerTask() {
-                    @Override
-                    public void run() {
-                        framesPerSecond = frameProcessedInOneSecondInterval;
-                        frameProcessedInOneSecondInterval = 0;
-                    }
-                },
-                /* delay= */ 0,
-                /* period= */ 1000);
-    }
-
-    // -----------------Code for processing single still image----------------------------------------
-    @Override
-    public void processBitmap(Bitmap bitmap, final GraphicOverlay graphicOverlay) {
-        requestDetectInImage(
-                InputImage.fromBitmap(bitmap, 0),
-                graphicOverlay,
-                /* originalCameraImage= */ null,
-                /* shouldShowFps= */ false);
-    }
-
-    // -----------------Code for processing live preview frame from Camera1 API-----------------------
-    @Override
-    public synchronized void processByteBuffer(
-            ByteBuffer data, final FrameMetadata frameMetadata, final GraphicOverlay graphicOverlay) {
-        latestImage = data;
-        latestImageMetaData = frameMetadata;
-        if (processingImage == null && processingMetaData == null) {
-            processLatestImage(graphicOverlay);
-        }
-    }
-
-    private synchronized void processLatestImage(final GraphicOverlay graphicOverlay) {
-        processingImage = latestImage;
-        processingMetaData = latestImageMetaData;
-        latestImage = null;
-        latestImageMetaData = null;
-        if (processingImage != null && processingMetaData != null && !isShutdown) {
-            processImage(processingImage, processingMetaData, graphicOverlay);
-        }
-    }
-
-    private void processImage(
-            ByteBuffer data, final FrameMetadata frameMetadata, final GraphicOverlay graphicOverlay) {
-        // If live viewport is on (that is the underneath surface view takes care of the camera preview
-        // drawing), skip the unnecessary bitmap creation that used for the manual preview drawing.
-        Bitmap bitmap =
-                PreferenceUtils.isCameraLiveViewportEnabled(graphicOverlay.getContext())
-                        ? null
-                        : BitmapUtils.getBitmap(data, frameMetadata);
-
-        requestDetectInImage(
-                InputImage.fromByteBuffer(
-                        data,
-                        frameMetadata.getWidth(),
-                        frameMetadata.getHeight(),
-                        frameMetadata.getRotation(),
-                        InputImage.IMAGE_FORMAT_NV21),
-                graphicOverlay,
-                bitmap,
-                /* shouldShowFps= */ true)
-                .addOnSuccessListener(executor, results -> processLatestImage(graphicOverlay));
-    }
-
-    // -----------------Code for processing live preview frame from CameraX API-----------------------
-    @Override
-    @RequiresApi(VERSION_CODES.KITKAT)
-    @ExperimentalGetImage
-    public void processImageProxy(ImageProxy image, GraphicOverlay graphicOverlay) {
-        if (isShutdown) {
-            image.close();
-            return;
-        }
-
-        Bitmap bitmap = null;
-        if (!PreferenceUtils.isCameraLiveViewportEnabled(graphicOverlay.getContext())) {
-            bitmap = BitmapUtils.getBitmap(image);
-        }
-
-        requestDetectInImage(
-                InputImage.fromMediaImage(image.getImage(), image.getImageInfo().getRotationDegrees()),
-                graphicOverlay,
-                /* originalCameraImage= */ bitmap,
-                /* shouldShowFps= */ true)
-                // When the image is from CameraX analysis use case, must call image.close() on received
-                // images when finished using them. Otherwise, new images may not be received or the camera
-                // may stall.
-                .addOnCompleteListener(results -> image.close());
-    }
-
-    // -----------------Common processing logic-------------------------------------------------------
-    private Task<T> requestDetectInImage(
-            final InputImage image,
-            final GraphicOverlay graphicOverlay,
-            @Nullable final Bitmap originalCameraImage,
-            boolean shouldShowFps) {
-        final long startMs = SystemClock.elapsedRealtime();
-        return detectInImage(image)
-                .addOnSuccessListener(
-                        executor,
-                        results -> {
-                            long currentLatencyMs = SystemClock.elapsedRealtime() - startMs;
-                            numRuns++;
-                            frameProcessedInOneSecondInterval++;
-                            totalRunMs += currentLatencyMs;
-                            maxRunMs = Math.max(currentLatencyMs, maxRunMs);
-                            minRunMs = Math.min(currentLatencyMs, minRunMs);
-
-                            // Only log inference info once per second. When frameProcessedInOneSecondInterval is
-                            // equal to 1, it means this is the first frame processed during the current second.
-                            if (frameProcessedInOneSecondInterval == 1) {
-                                Log.d(TAG, "Max latency is: " + maxRunMs);
-                                Log.d(TAG, "Min latency is: " + minRunMs);
-                                Log.d(TAG, "Num of Runs: " + numRuns + ", Avg latency is: " + totalRunMs / numRuns);
-                                MemoryInfo mi = new MemoryInfo();
-                                activityManager.getMemoryInfo(mi);
-                                long availableMegs = mi.availMem / 0x100000L;
-                                Log.d(TAG, "Memory available in system: " + availableMegs + " MB");
-                            }
-
-                            graphicOverlay.clear();
-                            if (originalCameraImage != null) {
-                                graphicOverlay.add(new CameraImageGraphic(graphicOverlay, originalCameraImage));
-                            }
-                            VisionProcessorBase.this.onSuccess(results, graphicOverlay);
-                            graphicOverlay.add(
-                                    new InferenceInfoGraphic(
-                                            graphicOverlay, currentLatencyMs, shouldShowFps ? framesPerSecond : null));
-                            graphicOverlay.postInvalidate();
-                        })
-                .addOnFailureListener(
-                        executor,
-                        e -> {
-                            graphicOverlay.clear();
-                            graphicOverlay.postInvalidate();
-                            String error = "Failed to process. Error: " + e.getLocalizedMessage();
-                            Toast.makeText(
-                                    graphicOverlay.getContext(),
-                                    error + "\nCause: " + e.getCause(),
-                                    Toast.LENGTH_SHORT)
-                                    .show();
-                            Log.d(TAG, error);
-                            e.printStackTrace();
-                            VisionProcessorBase.this.onFailure(e);
-                        });
-    }
-
-    @Override
-    public void stop() {
-        executor.shutdown();
-        isShutdown = true;
-        numRuns = 0;
-        totalRunMs = 0;
-        fpsTimer.cancel();
-    }
-
-    protected abstract Task<T> detectInImage(InputImage image);
-
-    protected abstract void onSuccess(@NonNull T results, @NonNull GraphicOverlay graphicOverlay);
-
-    protected abstract void onFailure(@NonNull Exception e);
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo;
+
+import android.app.ActivityManager;
+import android.app.ActivityManager.MemoryInfo;
+import android.content.Context;
+import android.graphics.Bitmap;
+import android.os.Build.VERSION_CODES;
+import android.os.SystemClock;
+import android.util.Log;
+import android.widget.Toast;
+
+import androidx.annotation.GuardedBy;
+import androidx.annotation.NonNull;
+import androidx.annotation.Nullable;
+import androidx.annotation.RequiresApi;
+import androidx.camera.core.ExperimentalGetImage;
+import androidx.camera.core.ImageProxy;
+
+import com.google.android.gms.tasks.Task;
+import com.google.android.gms.tasks.TaskExecutors;
+import com.google.mlkit.vision.common.InputImage;
+import com.google.mlkit.vision.demo.preference.PreferenceUtils;
+
+import java.nio.ByteBuffer;
+import java.util.Timer;
+import java.util.TimerTask;
+
+/**
+ * Abstract base class for vision frame processors. Subclasses need to implement {@link
+ * #onSuccess(Object, GraphicOverlay)} to define what they want to with the detection results and
+ * {@link #detectInImage(InputImage)} to specify the detector object.
+ *
+ * @param <T> The type of the detected feature.
+ */
+public abstract class VisionProcessorBase<T> implements VisionImageProcessor {
+
+    protected static final String MANUAL_TESTING_LOG = "LogTagForTest";
+    private static final String TAG = "VisionProcessorBase";
+
+    private final ActivityManager activityManager;
+    private final Timer fpsTimer = new Timer();
+    private final ScopedExecutor executor;
+
+    // Whether this processor is already shut down
+    private boolean isShutdown;
+
+    // Used to calculate latency, running in the same thread, no sync needed.
+    private int numRuns = 0;
+    private long totalRunMs = 0;
+    private long maxRunMs = 0;
+    private long minRunMs = Long.MAX_VALUE;
+
+    // Frame count that have been processed so far in an one second interval to calculate FPS.
+    private int frameProcessedInOneSecondInterval = 0;
+    private int framesPerSecond = 0;
+
+    // To keep the latest images and its metadata.
+    @GuardedBy("this")
+    private ByteBuffer latestImage;
+    @GuardedBy("this")
+    private FrameMetadata latestImageMetaData;
+    // To keep the images and metadata in process.
+    @GuardedBy("this")
+    private ByteBuffer processingImage;
+    @GuardedBy("this")
+    private FrameMetadata processingMetaData;
+
+    protected VisionProcessorBase(Context context) {
+        activityManager = (ActivityManager) context.getSystemService(Context.ACTIVITY_SERVICE);
+        executor = new ScopedExecutor(TaskExecutors.MAIN_THREAD);
+        fpsTimer.scheduleAtFixedRate(
+                new TimerTask() {
+                    @Override
+                    public void run() {
+                        framesPerSecond = frameProcessedInOneSecondInterval;
+                        frameProcessedInOneSecondInterval = 0;
+                    }
+                },
+                /* delay= */ 0,
+                /* period= */ 1000);
+    }
+
+    // -----------------Code for processing single still image----------------------------------------
+    @Override
+    public void processBitmap(Bitmap bitmap, final GraphicOverlay graphicOverlay) {
+        requestDetectInImage(
+                InputImage.fromBitmap(bitmap, 0),
+                graphicOverlay,
+                /* originalCameraImage= */ null,
+                /* shouldShowFps= */ false);
+    }
+
+    // -----------------Code for processing live preview frame from Camera1 API-----------------------
+    @Override
+    public synchronized void processByteBuffer(
+            ByteBuffer data, final FrameMetadata frameMetadata, final GraphicOverlay graphicOverlay) {
+        latestImage = data;
+        latestImageMetaData = frameMetadata;
+        if (processingImage == null && processingMetaData == null) {
+            processLatestImage(graphicOverlay);
+        }
+    }
+
+    private synchronized void processLatestImage(final GraphicOverlay graphicOverlay) {
+        processingImage = latestImage;
+        processingMetaData = latestImageMetaData;
+        latestImage = null;
+        latestImageMetaData = null;
+        if (processingImage != null && processingMetaData != null && !isShutdown) {
+            processImage(processingImage, processingMetaData, graphicOverlay);
+        }
+    }
+
+    private void processImage(
+            ByteBuffer data, final FrameMetadata frameMetadata, final GraphicOverlay graphicOverlay) {
+        // If live viewport is on (that is the underneath surface view takes care of the camera preview
+        // drawing), skip the unnecessary bitmap creation that used for the manual preview drawing.
+        Bitmap bitmap =
+                PreferenceUtils.isCameraLiveViewportEnabled(graphicOverlay.getContext())
+                        ? null
+                        : BitmapUtils.getBitmap(data, frameMetadata);
+
+        requestDetectInImage(
+                InputImage.fromByteBuffer(
+                        data,
+                        frameMetadata.getWidth(),
+                        frameMetadata.getHeight(),
+                        frameMetadata.getRotation(),
+                        InputImage.IMAGE_FORMAT_NV21),
+                graphicOverlay,
+                bitmap,
+                /* shouldShowFps= */ true)
+                .addOnSuccessListener(executor, results -> processLatestImage(graphicOverlay));
+    }
+
+    // -----------------Code for processing live preview frame from CameraX API-----------------------
+    @Override
+    @RequiresApi(VERSION_CODES.KITKAT)
+    @ExperimentalGetImage
+    public void processImageProxy(ImageProxy image, GraphicOverlay graphicOverlay) {
+        if (isShutdown) {
+            image.close();
+            return;
+        }
+
+        Bitmap bitmap = null;
+        if (!PreferenceUtils.isCameraLiveViewportEnabled(graphicOverlay.getContext())) {
+            bitmap = BitmapUtils.getBitmap(image);
+        }
+
+        requestDetectInImage(
+                InputImage.fromMediaImage(image.getImage(), image.getImageInfo().getRotationDegrees()),
+                graphicOverlay,
+                /* originalCameraImage= */ bitmap,
+                /* shouldShowFps= */ true)
+                // When the image is from CameraX analysis use case, must call image.close() on received
+                // images when finished using them. Otherwise, new images may not be received or the camera
+                // may stall.
+                .addOnCompleteListener(results -> image.close());
+    }
+
+    // -----------------Common processing logic-------------------------------------------------------
+    private Task<T> requestDetectInImage(
+            final InputImage image,
+            final GraphicOverlay graphicOverlay,
+            @Nullable final Bitmap originalCameraImage,
+            boolean shouldShowFps) {
+        final long startMs = SystemClock.elapsedRealtime();
+        return detectInImage(image)
+                .addOnSuccessListener(
+                        executor,
+                        results -> {
+                            long currentLatencyMs = SystemClock.elapsedRealtime() - startMs;
+                            numRuns++;
+                            frameProcessedInOneSecondInterval++;
+                            totalRunMs += currentLatencyMs;
+                            maxRunMs = Math.max(currentLatencyMs, maxRunMs);
+                            minRunMs = Math.min(currentLatencyMs, minRunMs);
+
+                            // Only log inference info once per second. When frameProcessedInOneSecondInterval is
+                            // equal to 1, it means this is the first frame processed during the current second.
+                            if (frameProcessedInOneSecondInterval == 1) {
+                                Log.d(TAG, "Max latency is: " + maxRunMs);
+                                Log.d(TAG, "Min latency is: " + minRunMs);
+                                Log.d(TAG, "Num of Runs: " + numRuns + ", Avg latency is: " + totalRunMs / numRuns);
+                                MemoryInfo mi = new MemoryInfo();
+                                activityManager.getMemoryInfo(mi);
+                                long availableMegs = mi.availMem / 0x100000L;
+                                Log.d(TAG, "Memory available in system: " + availableMegs + " MB");
+                            }
+
+                            graphicOverlay.clear();
+                            if (originalCameraImage != null) {
+                                graphicOverlay.add(new CameraImageGraphic(graphicOverlay, originalCameraImage));
+                            }
+                            VisionProcessorBase.this.onSuccess(results, graphicOverlay);
+                            graphicOverlay.add(
+                                    new InferenceInfoGraphic(
+                                            graphicOverlay, currentLatencyMs, shouldShowFps ? framesPerSecond : null));
+                            graphicOverlay.postInvalidate();
+                        })
+                .addOnFailureListener(
+                        executor,
+                        e -> {
+                            graphicOverlay.clear();
+                            graphicOverlay.postInvalidate();
+                            String error = "Failed to process. Error: " + e.getLocalizedMessage();
+                            Toast.makeText(
+                                    graphicOverlay.getContext(),
+                                    error + "\nCause: " + e.getCause(),
+                                    Toast.LENGTH_SHORT)
+                                    .show();
+                            Log.d(TAG, error);
+                            e.printStackTrace();
+                            VisionProcessorBase.this.onFailure(e);
+                        });
+    }
+
+    @Override
+    public void stop() {
+        executor.shutdown();
+        isShutdown = true;
+        numRuns = 0;
+        totalRunMs = 0;
+        fpsTimer.cancel();
+    }
+
+    protected abstract Task<T> detectInImage(InputImage image);
+
+    protected abstract void onSuccess(@NonNull T results, @NonNull GraphicOverlay graphicOverlay);
+
+    protected abstract void onFailure(@NonNull Exception e);
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/automl/AutoMLImageLabelerProcessor.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/automl/AutoMLImageLabelerProcessor.java
index d271ed0..195c873 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/automl/AutoMLImageLabelerProcessor.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/automl/AutoMLImageLabelerProcessor.java
@@ -1,84 +1,84 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.automl;
-
-import android.content.Context;
-import android.util.Log;
-
-import androidx.annotation.NonNull;
-
-import com.google.android.gms.tasks.Task;
-import com.google.mlkit.vision.common.InputImage;
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.demo.VisionProcessorBase;
-import com.google.mlkit.vision.label.ImageLabel;
-import com.google.mlkit.vision.label.ImageLabeler;
-import com.google.mlkit.vision.label.ImageLabeling;
-import com.google.mlkit.vision.label.automl.AutoMLImageLabelerLocalModel;
-import com.google.mlkit.vision.label.automl.AutoMLImageLabelerOptions;
-
-import java.io.IOException;
-import java.util.List;
-
-/**
- * AutoML image labeler demo.
- */
-public class AutoMLImageLabelerProcessor extends VisionProcessorBase<List<ImageLabel>> {
-
-    private static final String TAG = "AutoMLProcessor";
-
-    private final ImageLabeler imageLabeler;
-
-    public AutoMLImageLabelerProcessor(Context context) {
-        super(context);
-        Log.d(TAG, "Local model used.");
-        AutoMLImageLabelerLocalModel localModel =
-                new AutoMLImageLabelerLocalModel.Builder()
-                        .setAssetFilePath("automl/manifest.json")
-                        .build();
-        imageLabeler =
-                ImageLabeling.getClient(
-                        new AutoMLImageLabelerOptions.Builder(localModel).setConfidenceThreshold(0).build());
-    }
-
-    @Override
-    public void stop() {
-        super.stop();
-        try {
-            imageLabeler.close();
-        } catch (IOException e) {
-            Log.e(TAG, "Exception thrown while trying to close the image labeler", e);
-        }
-    }
-
-    @Override
-    protected Task<List<ImageLabel>> detectInImage(InputImage image) {
-        return imageLabeler.process(image);
-    }
-
-    @Override
-    protected void onSuccess(
-            @NonNull List<ImageLabel> labels, @NonNull GraphicOverlay graphicOverlay) {
-        graphicOverlay.add(new LabelGraphic(graphicOverlay, labels));
-    }
-
-    @Override
-    protected void onFailure(@NonNull Exception e) {
-        Log.w(TAG, "Label detection failed.", e);
-    }
-}
-
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.automl;
+
+import android.content.Context;
+import android.util.Log;
+
+import androidx.annotation.NonNull;
+
+import com.google.android.gms.tasks.Task;
+import com.google.mlkit.vision.common.InputImage;
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.demo.VisionProcessorBase;
+import com.google.mlkit.vision.label.ImageLabel;
+import com.google.mlkit.vision.label.ImageLabeler;
+import com.google.mlkit.vision.label.ImageLabeling;
+import com.google.mlkit.vision.label.automl.AutoMLImageLabelerLocalModel;
+import com.google.mlkit.vision.label.automl.AutoMLImageLabelerOptions;
+
+import java.io.IOException;
+import java.util.List;
+
+/**
+ * AutoML image labeler demo.
+ */
+public class AutoMLImageLabelerProcessor extends VisionProcessorBase<List<ImageLabel>> {
+
+    private static final String TAG = "AutoMLProcessor";
+
+    private final ImageLabeler imageLabeler;
+
+    public AutoMLImageLabelerProcessor(Context context) {
+        super(context);
+        Log.d(TAG, "Local model used.");
+        AutoMLImageLabelerLocalModel localModel =
+                new AutoMLImageLabelerLocalModel.Builder()
+                        .setAssetFilePath("automl/manifest.json")
+                        .build();
+        imageLabeler =
+                ImageLabeling.getClient(
+                        new AutoMLImageLabelerOptions.Builder(localModel).setConfidenceThreshold(0).build());
+    }
+
+    @Override
+    public void stop() {
+        super.stop();
+        try {
+            imageLabeler.close();
+        } catch (IOException e) {
+            Log.e(TAG, "Exception thrown while trying to close the image labeler", e);
+        }
+    }
+
+    @Override
+    protected Task<List<ImageLabel>> detectInImage(InputImage image) {
+        return imageLabeler.process(image);
+    }
+
+    @Override
+    protected void onSuccess(
+            @NonNull List<ImageLabel> labels, @NonNull GraphicOverlay graphicOverlay) {
+        graphicOverlay.add(new LabelGraphic(graphicOverlay, labels));
+    }
+
+    @Override
+    protected void onFailure(@NonNull Exception e) {
+        Log.w(TAG, "Label detection failed.", e);
+    }
+}
+
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/automl/LabelGraphic.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/automl/LabelGraphic.java
index 427b606..3682c2c 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/automl/LabelGraphic.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/automl/LabelGraphic.java
@@ -1,93 +1,93 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.automl;
-
-import android.graphics.Canvas;
-import android.graphics.Color;
-import android.graphics.Paint;
-
-import com.google.common.primitives.Floats;
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.label.ImageLabel;
-
-import java.util.List;
-import java.util.Locale;
-
-/**
- * Graphic instance for rendering a label within an associated graphic overlay view.
- */
-public class LabelGraphic extends GraphicOverlay.Graphic {
-
-    private static final float TEXT_SIZE = 70.0f;
-    private static final String LABEL_FORMAT = "%.2f%% confidence (index: %d)";
-
-    private final Paint textPaint;
-    private final Paint labelPaint;
-    private final GraphicOverlay overlay;
-
-    private final List<ImageLabel> labels;
-
-    public LabelGraphic(GraphicOverlay overlay, List<ImageLabel> labels) {
-        super(overlay);
-        this.overlay = overlay;
-        this.labels = labels;
-        textPaint = new Paint();
-        textPaint.setColor(Color.WHITE);
-        textPaint.setTextSize(TEXT_SIZE);
-
-        labelPaint = new Paint();
-        labelPaint.setColor(Color.BLACK);
-        labelPaint.setStyle(Paint.Style.FILL);
-        labelPaint.setAlpha(200);
-    }
-
-    @Override
-    public synchronized void draw(Canvas canvas) {
-        // First try to find maxWidth and totalHeight in order to draw to the center of the screen.
-        float maxWidth = 0;
-        float totalHeight = labels.size() * 2 * TEXT_SIZE;
-        for (ImageLabel label : labels) {
-            float line1Width = textPaint.measureText(label.getText());
-            float line2Width = textPaint.measureText(
-                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex()));
-            maxWidth = Floats.max(maxWidth, line1Width, line2Width);
-        }
-        float x = Math.max(0, overlay.getWidth() / 2.0f - maxWidth / 2.0f);
-        float y = Math.max(200, overlay.getHeight() / 2.0f - totalHeight / 2.0f);
-
-        if (!labels.isEmpty()) {
-            float padding = 20;
-            canvas.drawRect(x - padding,
-                    y - padding,
-                    x + maxWidth + padding,
-                    y + totalHeight + padding,
-                    labelPaint);
-        }
-
-        for (ImageLabel label : labels) {
-            if (y + TEXT_SIZE * 2 > overlay.getHeight()) {
-                break;
-            }
-            canvas.drawText(label.getText(), x, y + TEXT_SIZE, textPaint);
-            y += TEXT_SIZE;
-            canvas.drawText(
-                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex()),
-                    x, y + TEXT_SIZE, textPaint);
-            y += TEXT_SIZE;
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.automl;
+
+import android.graphics.Canvas;
+import android.graphics.Color;
+import android.graphics.Paint;
+
+import com.google.common.primitives.Floats;
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.label.ImageLabel;
+
+import java.util.List;
+import java.util.Locale;
+
+/**
+ * Graphic instance for rendering a label within an associated graphic overlay view.
+ */
+public class LabelGraphic extends GraphicOverlay.Graphic {
+
+    private static final float TEXT_SIZE = 70.0f;
+    private static final String LABEL_FORMAT = "%.2f%% confidence (index: %d)";
+
+    private final Paint textPaint;
+    private final Paint labelPaint;
+    private final GraphicOverlay overlay;
+
+    private final List<ImageLabel> labels;
+
+    public LabelGraphic(GraphicOverlay overlay, List<ImageLabel> labels) {
+        super(overlay);
+        this.overlay = overlay;
+        this.labels = labels;
+        textPaint = new Paint();
+        textPaint.setColor(Color.WHITE);
+        textPaint.setTextSize(TEXT_SIZE);
+
+        labelPaint = new Paint();
+        labelPaint.setColor(Color.BLACK);
+        labelPaint.setStyle(Paint.Style.FILL);
+        labelPaint.setAlpha(200);
+    }
+
+    @Override
+    public synchronized void draw(Canvas canvas) {
+        // First try to find maxWidth and totalHeight in order to draw to the center of the screen.
+        float maxWidth = 0;
+        float totalHeight = labels.size() * 2 * TEXT_SIZE;
+        for (ImageLabel label : labels) {
+            float line1Width = textPaint.measureText(label.getText());
+            float line2Width = textPaint.measureText(
+                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex()));
+            maxWidth = Floats.max(maxWidth, line1Width, line2Width);
+        }
+        float x = Math.max(0, overlay.getWidth() / 2.0f - maxWidth / 2.0f);
+        float y = Math.max(200, overlay.getHeight() / 2.0f - totalHeight / 2.0f);
+
+        if (!labels.isEmpty()) {
+            float padding = 20;
+            canvas.drawRect(x - padding,
+                    y - padding,
+                    x + maxWidth + padding,
+                    y + totalHeight + padding,
+                    labelPaint);
+        }
+
+        for (ImageLabel label : labels) {
+            if (y + TEXT_SIZE * 2 > overlay.getHeight()) {
+                break;
+            }
+            canvas.drawText(label.getText(), x, y + TEXT_SIZE, textPaint);
+            y += TEXT_SIZE;
+            canvas.drawText(
+                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex()),
+                    x, y + TEXT_SIZE, textPaint);
+            y += TEXT_SIZE;
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/barcodescanner/BarcodeGraphic.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/barcodescanner/BarcodeGraphic.java
index 8c9b746..c02ce0c 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/barcodescanner/BarcodeGraphic.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/barcodescanner/BarcodeGraphic.java
@@ -1,92 +1,92 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.barcodescanner;
-
-import android.graphics.Canvas;
-import android.graphics.Color;
-import android.graphics.Paint;
-import android.graphics.RectF;
-
-import com.google.mlkit.vision.barcode.Barcode;
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic;
-
-/**
- * Graphic instance for rendering Barcode position and content information in an overlay view.
- */
-public class BarcodeGraphic extends Graphic {
-
-    private static final int TEXT_COLOR = Color.BLACK;
-    private static final int MARKER_COLOR = Color.WHITE;
-    private static final float TEXT_SIZE = 54.0f;
-    private static final float STROKE_WIDTH = 4.0f;
-
-    private final Paint rectPaint;
-    private final Paint barcodePaint;
-    private final Barcode barcode;
-    private final Paint labelPaint;
-
-    BarcodeGraphic(GraphicOverlay overlay, Barcode barcode) {
-        super(overlay);
-
-        this.barcode = barcode;
-
-        rectPaint = new Paint();
-        rectPaint.setColor(MARKER_COLOR);
-        rectPaint.setStyle(Paint.Style.STROKE);
-        rectPaint.setStrokeWidth(STROKE_WIDTH);
-
-        barcodePaint = new Paint();
-        barcodePaint.setColor(TEXT_COLOR);
-        barcodePaint.setTextSize(TEXT_SIZE);
-
-        labelPaint = new Paint();
-        labelPaint.setColor(MARKER_COLOR);
-        labelPaint.setStyle(Paint.Style.FILL);
-    }
-
-    /**
-     * Draws the barcode block annotations for position, size, and raw value on the supplied canvas.
-     */
-    @Override
-    public void draw(Canvas canvas) {
-        if (barcode == null) {
-            throw new IllegalStateException("Attempting to draw a null barcode.");
-        }
-
-        // Draws the bounding box around the BarcodeBlock.
-        RectF rect = new RectF(barcode.getBoundingBox());
-        rect.left = translateX(rect.left);
-        rect.top = translateY(rect.top);
-        rect.right = translateX(rect.right);
-        rect.bottom = translateY(rect.bottom);
-        canvas.drawRect(rect, rectPaint);
-
-        // Draws other object info.
-        float lineHeight = TEXT_SIZE + (2 * STROKE_WIDTH);
-        float textWidth = barcodePaint.measureText(barcode.getRawValue());
-        float left = isImageFlipped() ? rect.right : rect.left;
-        canvas.drawRect(
-                left - STROKE_WIDTH,
-                rect.top - lineHeight,
-                left + textWidth + (2 * STROKE_WIDTH),
-                rect.top,
-                labelPaint);
-        //Renders the barcode at the bottom of the box.
-        canvas.drawText(barcode.getRawValue(), left, rect.top - STROKE_WIDTH, barcodePaint);
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.barcodescanner;
+
+import android.graphics.Canvas;
+import android.graphics.Color;
+import android.graphics.Paint;
+import android.graphics.RectF;
+
+import com.google.mlkit.vision.barcode.Barcode;
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic;
+
+/**
+ * Graphic instance for rendering Barcode position and content information in an overlay view.
+ */
+public class BarcodeGraphic extends Graphic {
+
+    private static final int TEXT_COLOR = Color.BLACK;
+    private static final int MARKER_COLOR = Color.WHITE;
+    private static final float TEXT_SIZE = 54.0f;
+    private static final float STROKE_WIDTH = 4.0f;
+
+    private final Paint rectPaint;
+    private final Paint barcodePaint;
+    private final Barcode barcode;
+    private final Paint labelPaint;
+
+    BarcodeGraphic(GraphicOverlay overlay, Barcode barcode) {
+        super(overlay);
+
+        this.barcode = barcode;
+
+        rectPaint = new Paint();
+        rectPaint.setColor(MARKER_COLOR);
+        rectPaint.setStyle(Paint.Style.STROKE);
+        rectPaint.setStrokeWidth(STROKE_WIDTH);
+
+        barcodePaint = new Paint();
+        barcodePaint.setColor(TEXT_COLOR);
+        barcodePaint.setTextSize(TEXT_SIZE);
+
+        labelPaint = new Paint();
+        labelPaint.setColor(MARKER_COLOR);
+        labelPaint.setStyle(Paint.Style.FILL);
+    }
+
+    /**
+     * Draws the barcode block annotations for position, size, and raw value on the supplied canvas.
+     */
+    @Override
+    public void draw(Canvas canvas) {
+        if (barcode == null) {
+            throw new IllegalStateException("Attempting to draw a null barcode.");
+        }
+
+        // Draws the bounding box around the BarcodeBlock.
+        RectF rect = new RectF(barcode.getBoundingBox());
+        rect.left = translateX(rect.left);
+        rect.top = translateY(rect.top);
+        rect.right = translateX(rect.right);
+        rect.bottom = translateY(rect.bottom);
+        canvas.drawRect(rect, rectPaint);
+
+        // Draws other object info.
+        float lineHeight = TEXT_SIZE + (2 * STROKE_WIDTH);
+        float textWidth = barcodePaint.measureText(barcode.getRawValue());
+        float left = isImageFlipped() ? rect.right : rect.left;
+        canvas.drawRect(
+                left - STROKE_WIDTH,
+                rect.top - lineHeight,
+                left + textWidth + (2 * STROKE_WIDTH),
+                rect.top,
+                labelPaint);
+        //Renders the barcode at the bottom of the box.
+        canvas.drawText(barcode.getRawValue(), left, rect.top - STROKE_WIDTH, barcodePaint);
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/barcodescanner/BarcodeScannerProcessor.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/barcodescanner/BarcodeScannerProcessor.java
index 6ed6e51..1b97500 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/barcodescanner/BarcodeScannerProcessor.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/barcodescanner/BarcodeScannerProcessor.java
@@ -1,119 +1,119 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.barcodescanner;
-
-import android.content.Context;
-import android.graphics.Point;
-import android.util.Log;
-
-import androidx.annotation.NonNull;
-
-import com.google.android.gms.tasks.Task;
-import com.google.mlkit.vision.barcode.Barcode;
-import com.google.mlkit.vision.barcode.BarcodeScanner;
-import com.google.mlkit.vision.barcode.BarcodeScanning;
-import com.google.mlkit.vision.common.InputImage;
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.demo.VisionProcessorBase;
-
-import java.util.List;
-
-/**
- * Barcode Detector Demo.
- */
-public class BarcodeScannerProcessor extends VisionProcessorBase<List<Barcode>> {
-
-    private static final String TAG = "BarcodeProcessor";
-
-    private final BarcodeScanner barcodeScanner;
-
-    public BarcodeScannerProcessor(Context context) {
-        super(context);
-        // Note that if you know which format of barcode your app is dealing with, detection will be
-        // faster to specify the supported barcode formats one by one, e.g.
-        // new BarcodeScannerOptions.Builder()
-        //     .setBarcodeFormats(Barcode.FORMAT_QR_CODE)
-        //     .build();
-        barcodeScanner = BarcodeScanning.getClient();
-    }
-
-    @Override
-    public void stop() {
-        super.stop();
-        barcodeScanner.close();
-    }
-
-    @Override
-    protected Task<List<Barcode>> detectInImage(InputImage image) {
-        return barcodeScanner.process(image);
-    }
-
-    @Override
-    protected void onSuccess(
-            @NonNull List<Barcode> barcodes, @NonNull GraphicOverlay graphicOverlay) {
-        if (barcodes.isEmpty()) {
-            Log.v(MANUAL_TESTING_LOG, "No barcode has been detected");
-        }
-        for (int i = 0; i < barcodes.size(); ++i) {
-            Barcode barcode = barcodes.get(i);
-            graphicOverlay.add(new BarcodeGraphic(graphicOverlay, barcode));
-            logExtrasForTesting(barcode);
-        }
-    }
-
-    private static void logExtrasForTesting(Barcode barcode) {
-        if (barcode != null) {
-            Log.v(
-                    MANUAL_TESTING_LOG,
-                    String.format(
-                            "Detected barcode's bounding box: %s", barcode.getBoundingBox().flattenToString()));
-            Log.v(
-                    MANUAL_TESTING_LOG,
-                    String.format(
-                            "Expected corner point size is 4, get %d", barcode.getCornerPoints().length));
-            for (Point point : barcode.getCornerPoints()) {
-                Log.v(
-                        MANUAL_TESTING_LOG,
-                        String.format("Corner point is located at: x = %d, y = %d", point.x, point.y));
-            }
-            Log.v(MANUAL_TESTING_LOG, "barcode display value: " + barcode.getDisplayValue());
-            Log.v(MANUAL_TESTING_LOG, "barcode raw value: " + barcode.getRawValue());
-            Barcode.DriverLicense dl = barcode.getDriverLicense();
-            if (dl != null) {
-                Log.v(MANUAL_TESTING_LOG, "driver license city: " + dl.getAddressCity());
-                Log.v(MANUAL_TESTING_LOG, "driver license state: " + dl.getAddressState());
-                Log.v(MANUAL_TESTING_LOG, "driver license street: " + dl.getAddressStreet());
-                Log.v(MANUAL_TESTING_LOG, "driver license zip code: " + dl.getAddressZip());
-                Log.v(MANUAL_TESTING_LOG, "driver license birthday: " + dl.getBirthDate());
-                Log.v(MANUAL_TESTING_LOG, "driver license document type: " + dl.getDocumentType());
-                Log.v(MANUAL_TESTING_LOG, "driver license expiry date: " + dl.getExpiryDate());
-                Log.v(MANUAL_TESTING_LOG, "driver license first name: " + dl.getFirstName());
-                Log.v(MANUAL_TESTING_LOG, "driver license middle name: " + dl.getMiddleName());
-                Log.v(MANUAL_TESTING_LOG, "driver license last name: " + dl.getLastName());
-                Log.v(MANUAL_TESTING_LOG, "driver license gender: " + dl.getGender());
-                Log.v(MANUAL_TESTING_LOG, "driver license issue date: " + dl.getIssueDate());
-                Log.v(MANUAL_TESTING_LOG, "driver license issue country: " + dl.getIssuingCountry());
-                Log.v(MANUAL_TESTING_LOG, "driver license number: " + dl.getLicenseNumber());
-            }
-        }
-    }
-
-    @Override
-    protected void onFailure(@NonNull Exception e) {
-        Log.e(TAG, "Barcode detection failed " + e);
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.barcodescanner;
+
+import android.content.Context;
+import android.graphics.Point;
+import android.util.Log;
+
+import androidx.annotation.NonNull;
+
+import com.google.android.gms.tasks.Task;
+import com.google.mlkit.vision.barcode.Barcode;
+import com.google.mlkit.vision.barcode.BarcodeScanner;
+import com.google.mlkit.vision.barcode.BarcodeScanning;
+import com.google.mlkit.vision.common.InputImage;
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.demo.VisionProcessorBase;
+
+import java.util.List;
+
+/**
+ * Barcode Detector Demo.
+ */
+public class BarcodeScannerProcessor extends VisionProcessorBase<List<Barcode>> {
+
+    private static final String TAG = "BarcodeProcessor";
+
+    private final BarcodeScanner barcodeScanner;
+
+    public BarcodeScannerProcessor(Context context) {
+        super(context);
+        // Note that if you know which format of barcode your app is dealing with, detection will be
+        // faster to specify the supported barcode formats one by one, e.g.
+        // new BarcodeScannerOptions.Builder()
+        //     .setBarcodeFormats(Barcode.FORMAT_QR_CODE)
+        //     .build();
+        barcodeScanner = BarcodeScanning.getClient();
+    }
+
+    @Override
+    public void stop() {
+        super.stop();
+        barcodeScanner.close();
+    }
+
+    @Override
+    protected Task<List<Barcode>> detectInImage(InputImage image) {
+        return barcodeScanner.process(image);
+    }
+
+    @Override
+    protected void onSuccess(
+            @NonNull List<Barcode> barcodes, @NonNull GraphicOverlay graphicOverlay) {
+        if (barcodes.isEmpty()) {
+            Log.v(MANUAL_TESTING_LOG, "No barcode has been detected");
+        }
+        for (int i = 0; i < barcodes.size(); ++i) {
+            Barcode barcode = barcodes.get(i);
+            graphicOverlay.add(new BarcodeGraphic(graphicOverlay, barcode));
+            logExtrasForTesting(barcode);
+        }
+    }
+
+    private static void logExtrasForTesting(Barcode barcode) {
+        if (barcode != null) {
+            Log.v(
+                    MANUAL_TESTING_LOG,
+                    String.format(
+                            "Detected barcode's bounding box: %s", barcode.getBoundingBox().flattenToString()));
+            Log.v(
+                    MANUAL_TESTING_LOG,
+                    String.format(
+                            "Expected corner point size is 4, get %d", barcode.getCornerPoints().length));
+            for (Point point : barcode.getCornerPoints()) {
+                Log.v(
+                        MANUAL_TESTING_LOG,
+                        String.format("Corner point is located at: x = %d, y = %d", point.x, point.y));
+            }
+            Log.v(MANUAL_TESTING_LOG, "barcode display value: " + barcode.getDisplayValue());
+            Log.v(MANUAL_TESTING_LOG, "barcode raw value: " + barcode.getRawValue());
+            Barcode.DriverLicense dl = barcode.getDriverLicense();
+            if (dl != null) {
+                Log.v(MANUAL_TESTING_LOG, "driver license city: " + dl.getAddressCity());
+                Log.v(MANUAL_TESTING_LOG, "driver license state: " + dl.getAddressState());
+                Log.v(MANUAL_TESTING_LOG, "driver license street: " + dl.getAddressStreet());
+                Log.v(MANUAL_TESTING_LOG, "driver license zip code: " + dl.getAddressZip());
+                Log.v(MANUAL_TESTING_LOG, "driver license birthday: " + dl.getBirthDate());
+                Log.v(MANUAL_TESTING_LOG, "driver license document type: " + dl.getDocumentType());
+                Log.v(MANUAL_TESTING_LOG, "driver license expiry date: " + dl.getExpiryDate());
+                Log.v(MANUAL_TESTING_LOG, "driver license first name: " + dl.getFirstName());
+                Log.v(MANUAL_TESTING_LOG, "driver license middle name: " + dl.getMiddleName());
+                Log.v(MANUAL_TESTING_LOG, "driver license last name: " + dl.getLastName());
+                Log.v(MANUAL_TESTING_LOG, "driver license gender: " + dl.getGender());
+                Log.v(MANUAL_TESTING_LOG, "driver license issue date: " + dl.getIssueDate());
+                Log.v(MANUAL_TESTING_LOG, "driver license issue country: " + dl.getIssuingCountry());
+                Log.v(MANUAL_TESTING_LOG, "driver license number: " + dl.getLicenseNumber());
+            }
+        }
+    }
+
+    @Override
+    protected void onFailure(@NonNull Exception e) {
+        Log.e(TAG, "Barcode detection failed " + e);
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/facedetector/FaceDetectorProcessor.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/facedetector/FaceDetectorProcessor.java
index 0be532b..9e9091a 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/facedetector/FaceDetectorProcessor.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/facedetector/FaceDetectorProcessor.java
@@ -1,148 +1,148 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.facedetector;
-
-import android.content.Context;
-import android.graphics.PointF;
-import android.util.Log;
-
-import androidx.annotation.NonNull;
-
-import com.google.android.gms.tasks.Task;
-import com.google.mlkit.vision.common.InputImage;
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.demo.VisionProcessorBase;
-import com.google.mlkit.vision.face.Face;
-import com.google.mlkit.vision.face.FaceDetection;
-import com.google.mlkit.vision.face.FaceDetector;
-import com.google.mlkit.vision.face.FaceDetectorOptions;
-import com.google.mlkit.vision.face.FaceLandmark;
-
-import java.util.List;
-import java.util.Locale;
-
-/**
- * Face Detector Demo.
- */
-public class FaceDetectorProcessor extends VisionProcessorBase<List<Face>> {
-
-    private static final String TAG = "FaceDetectorProcessor";
-
-    private final FaceDetector detector;
-
-    public FaceDetectorProcessor(Context context) {
-        this(
-                context,
-                new FaceDetectorOptions.Builder()
-                        .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)
-                        .enableTracking()
-                        .build());
-    }
-
-    public FaceDetectorProcessor(Context context, FaceDetectorOptions options) {
-        super(context);
-        Log.v(MANUAL_TESTING_LOG, "Face detector options: " + options);
-        detector = FaceDetection.getClient(options);
-    }
-
-    @Override
-    public void stop() {
-        super.stop();
-        detector.close();
-    }
-
-    @Override
-    protected Task<List<Face>> detectInImage(InputImage image) {
-        return detector.process(image);
-    }
-
-    @Override
-    protected void onSuccess(@NonNull List<Face> faces, @NonNull GraphicOverlay graphicOverlay) {
-        for (Face face : faces) {
-            graphicOverlay.add(new FaceGraphic(graphicOverlay, face));
-            logExtrasForTesting(face);
-        }
-    }
-
-    private static void logExtrasForTesting(Face face) {
-        if (face != null) {
-            Log.v(MANUAL_TESTING_LOG, "face bounding box: " + face.getBoundingBox().flattenToString());
-            Log.v(MANUAL_TESTING_LOG, "face Euler Angle X: " + face.getHeadEulerAngleX());
-            Log.v(MANUAL_TESTING_LOG, "face Euler Angle Y: " + face.getHeadEulerAngleY());
-            Log.v(MANUAL_TESTING_LOG, "face Euler Angle Z: " + face.getHeadEulerAngleZ());
-
-            // All landmarks
-            int[] landMarkTypes =
-                    new int[]{
-                            FaceLandmark.MOUTH_BOTTOM,
-                            FaceLandmark.MOUTH_RIGHT,
-                            FaceLandmark.MOUTH_LEFT,
-                            FaceLandmark.RIGHT_EYE,
-                            FaceLandmark.LEFT_EYE,
-                            FaceLandmark.RIGHT_EAR,
-                            FaceLandmark.LEFT_EAR,
-                            FaceLandmark.RIGHT_CHEEK,
-                            FaceLandmark.LEFT_CHEEK,
-                            FaceLandmark.NOSE_BASE
-                    };
-            String[] landMarkTypesStrings =
-                    new String[]{
-                            "MOUTH_BOTTOM",
-                            "MOUTH_RIGHT",
-                            "MOUTH_LEFT",
-                            "RIGHT_EYE",
-                            "LEFT_EYE",
-                            "RIGHT_EAR",
-                            "LEFT_EAR",
-                            "RIGHT_CHEEK",
-                            "LEFT_CHEEK",
-                            "NOSE_BASE"
-                    };
-            for (int i = 0; i < landMarkTypes.length; i++) {
-                FaceLandmark landmark = face.getLandmark(landMarkTypes[i]);
-                if (landmark == null) {
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "No landmark of type: " + landMarkTypesStrings[i] + " has been detected");
-                } else {
-                    PointF landmarkPosition = landmark.getPosition();
-                    String landmarkPositionStr =
-                            String.format(Locale.US, "x: %f , y: %f", landmarkPosition.x, landmarkPosition.y);
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "Position for face landmark: "
-                                    + landMarkTypesStrings[i]
-                                    + " is :"
-                                    + landmarkPositionStr);
-                }
-            }
-            Log.v(
-                    MANUAL_TESTING_LOG,
-                    "face left eye open probability: " + face.getLeftEyeOpenProbability());
-            Log.v(
-                    MANUAL_TESTING_LOG,
-                    "face right eye open probability: " + face.getRightEyeOpenProbability());
-            Log.v(MANUAL_TESTING_LOG, "face smiling probability: " + face.getSmilingProbability());
-            Log.v(MANUAL_TESTING_LOG, "face tracking id: " + face.getTrackingId());
-        }
-    }
-
-    @Override
-    protected void onFailure(@NonNull Exception e) {
-        Log.e(TAG, "Face detection failed " + e);
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.facedetector;
+
+import android.content.Context;
+import android.graphics.PointF;
+import android.util.Log;
+
+import androidx.annotation.NonNull;
+
+import com.google.android.gms.tasks.Task;
+import com.google.mlkit.vision.common.InputImage;
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.demo.VisionProcessorBase;
+import com.google.mlkit.vision.face.Face;
+import com.google.mlkit.vision.face.FaceDetection;
+import com.google.mlkit.vision.face.FaceDetector;
+import com.google.mlkit.vision.face.FaceDetectorOptions;
+import com.google.mlkit.vision.face.FaceLandmark;
+
+import java.util.List;
+import java.util.Locale;
+
+/**
+ * Face Detector Demo.
+ */
+public class FaceDetectorProcessor extends VisionProcessorBase<List<Face>> {
+
+    private static final String TAG = "FaceDetectorProcessor";
+
+    private final FaceDetector detector;
+
+    public FaceDetectorProcessor(Context context) {
+        this(
+                context,
+                new FaceDetectorOptions.Builder()
+                        .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)
+                        .enableTracking()
+                        .build());
+    }
+
+    public FaceDetectorProcessor(Context context, FaceDetectorOptions options) {
+        super(context);
+        Log.v(MANUAL_TESTING_LOG, "Face detector options: " + options);
+        detector = FaceDetection.getClient(options);
+    }
+
+    @Override
+    public void stop() {
+        super.stop();
+        detector.close();
+    }
+
+    @Override
+    protected Task<List<Face>> detectInImage(InputImage image) {
+        return detector.process(image);
+    }
+
+    @Override
+    protected void onSuccess(@NonNull List<Face> faces, @NonNull GraphicOverlay graphicOverlay) {
+        for (Face face : faces) {
+            graphicOverlay.add(new FaceGraphic(graphicOverlay, face));
+            logExtrasForTesting(face);
+        }
+    }
+
+    private static void logExtrasForTesting(Face face) {
+        if (face != null) {
+            Log.v(MANUAL_TESTING_LOG, "face bounding box: " + face.getBoundingBox().flattenToString());
+            Log.v(MANUAL_TESTING_LOG, "face Euler Angle X: " + face.getHeadEulerAngleX());
+            Log.v(MANUAL_TESTING_LOG, "face Euler Angle Y: " + face.getHeadEulerAngleY());
+            Log.v(MANUAL_TESTING_LOG, "face Euler Angle Z: " + face.getHeadEulerAngleZ());
+
+            // All landmarks
+            int[] landMarkTypes =
+                    new int[]{
+                            FaceLandmark.MOUTH_BOTTOM,
+                            FaceLandmark.MOUTH_RIGHT,
+                            FaceLandmark.MOUTH_LEFT,
+                            FaceLandmark.RIGHT_EYE,
+                            FaceLandmark.LEFT_EYE,
+                            FaceLandmark.RIGHT_EAR,
+                            FaceLandmark.LEFT_EAR,
+                            FaceLandmark.RIGHT_CHEEK,
+                            FaceLandmark.LEFT_CHEEK,
+                            FaceLandmark.NOSE_BASE
+                    };
+            String[] landMarkTypesStrings =
+                    new String[]{
+                            "MOUTH_BOTTOM",
+                            "MOUTH_RIGHT",
+                            "MOUTH_LEFT",
+                            "RIGHT_EYE",
+                            "LEFT_EYE",
+                            "RIGHT_EAR",
+                            "LEFT_EAR",
+                            "RIGHT_CHEEK",
+                            "LEFT_CHEEK",
+                            "NOSE_BASE"
+                    };
+            for (int i = 0; i < landMarkTypes.length; i++) {
+                FaceLandmark landmark = face.getLandmark(landMarkTypes[i]);
+                if (landmark == null) {
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "No landmark of type: " + landMarkTypesStrings[i] + " has been detected");
+                } else {
+                    PointF landmarkPosition = landmark.getPosition();
+                    String landmarkPositionStr =
+                            String.format(Locale.US, "x: %f , y: %f", landmarkPosition.x, landmarkPosition.y);
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "Position for face landmark: "
+                                    + landMarkTypesStrings[i]
+                                    + " is :"
+                                    + landmarkPositionStr);
+                }
+            }
+            Log.v(
+                    MANUAL_TESTING_LOG,
+                    "face left eye open probability: " + face.getLeftEyeOpenProbability());
+            Log.v(
+                    MANUAL_TESTING_LOG,
+                    "face right eye open probability: " + face.getRightEyeOpenProbability());
+            Log.v(MANUAL_TESTING_LOG, "face smiling probability: " + face.getSmilingProbability());
+            Log.v(MANUAL_TESTING_LOG, "face tracking id: " + face.getTrackingId());
+        }
+    }
+
+    @Override
+    protected void onFailure(@NonNull Exception e) {
+        Log.e(TAG, "Face detection failed " + e);
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/facedetector/FaceGraphic.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/facedetector/FaceGraphic.java
index 0d442a4..51d6329 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/facedetector/FaceGraphic.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/facedetector/FaceGraphic.java
@@ -1,231 +1,231 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.facedetector;
-
-import android.graphics.Canvas;
-import android.graphics.Color;
-import android.graphics.Paint;
-import android.graphics.PointF;
-
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic;
-import com.google.mlkit.vision.face.Face;
-import com.google.mlkit.vision.face.FaceContour;
-import com.google.mlkit.vision.face.FaceLandmark;
-import com.google.mlkit.vision.face.FaceLandmark.LandmarkType;
-
-import java.util.Locale;
-
-/**
- * Graphic instance for rendering face position, contour, and landmarks within the associated
- * graphic overlay view.
- */
-public class FaceGraphic extends Graphic {
-    private static final float FACE_POSITION_RADIUS = 4.0f;
-    private static final float ID_TEXT_SIZE = 30.0f;
-    private static final float ID_Y_OFFSET = 40.0f;
-    private static final float ID_X_OFFSET = -40.0f;
-    private static final float BOX_STROKE_WIDTH = 5.0f;
-    private static final int NUM_COLORS = 10;
-    private static final int[][] COLORS = new int[][]{
-            // {Text color, background color}
-            {Color.BLACK, Color.WHITE},
-            {Color.WHITE, Color.MAGENTA},
-            {Color.BLACK, Color.LTGRAY},
-            {Color.WHITE, Color.RED},
-            {Color.WHITE, Color.BLUE},
-            {Color.WHITE, Color.DKGRAY},
-            {Color.BLACK, Color.CYAN},
-            {Color.BLACK, Color.YELLOW},
-            {Color.WHITE, Color.BLACK},
-            {Color.BLACK, Color.GREEN}
-    };
-
-    private final Paint facePositionPaint;
-    private final Paint[] idPaints;
-    private final Paint[] boxPaints;
-    private final Paint[] labelPaints;
-
-    private volatile Face face;
-
-    FaceGraphic(GraphicOverlay overlay, Face face) {
-        super(overlay);
-
-        this.face = face;
-        final int selectedColor = Color.WHITE;
-
-        facePositionPaint = new Paint();
-        facePositionPaint.setColor(selectedColor);
-
-        int numColors = COLORS.length;
-        idPaints = new Paint[numColors];
-        boxPaints = new Paint[numColors];
-        labelPaints = new Paint[numColors];
-        for (int i = 0; i < numColors; i++) {
-            idPaints[i] = new Paint();
-            idPaints[i].setColor(COLORS[i][0] /* text color */);
-            idPaints[i].setTextSize(ID_TEXT_SIZE);
-
-            boxPaints[i] = new Paint();
-            boxPaints[i].setColor(COLORS[i][1] /* background color */);
-            boxPaints[i].setStyle(Paint.Style.STROKE);
-            boxPaints[i].setStrokeWidth(BOX_STROKE_WIDTH);
-
-            labelPaints[i] = new Paint();
-            labelPaints[i].setColor(COLORS[i][1]  /* background color */);
-            labelPaints[i].setStyle(Paint.Style.FILL);
-        }
-    }
-
-    /**
-     * Draws the face annotations for position on the supplied canvas.
-     */
-    @Override
-    public void draw(Canvas canvas) {
-        Face face = this.face;
-        if (face == null) {
-            return;
-        }
-
-        // Draws a circle at the position of the detected face, with the face's track id below.
-        float x = translateX(face.getBoundingBox().centerX());
-        float y = translateY(face.getBoundingBox().centerY());
-        canvas.drawCircle(x, y, FACE_POSITION_RADIUS, facePositionPaint);
-
-        // Calculate positions.
-        float left = x - scale(face.getBoundingBox().width() / 2.0f);
-        float top = y - scale(face.getBoundingBox().height() / 2.0f);
-        float right = x + scale(face.getBoundingBox().width() / 2.0f);
-        float bottom = y + scale(face.getBoundingBox().height() / 2.0f);
-        float lineHeight = ID_TEXT_SIZE + BOX_STROKE_WIDTH;
-        float yLabelOffset = -lineHeight;
-
-        // Decide color based on face ID
-        int colorID = (face.getTrackingId() == null)
-                ? 0 : Math.abs(face.getTrackingId() % NUM_COLORS);
-
-        // Calculate width and height of label box
-        float textWidth = idPaints[colorID].measureText("ID: " + face.getTrackingId());
-        if (face.getSmilingProbability() != null) {
-            yLabelOffset -= lineHeight;
-            textWidth = Math.max(textWidth, idPaints[colorID].measureText(
-                    String.format(Locale.US, "Happiness: %.2f", face.getSmilingProbability())));
-        }
-        if (face.getLeftEyeOpenProbability() != null) {
-            yLabelOffset -= lineHeight;
-            textWidth = Math.max(textWidth, idPaints[colorID].measureText(
-                    String.format(Locale.US, "Left eye: %.2f", face.getLeftEyeOpenProbability())));
-        }
-        if (face.getRightEyeOpenProbability() != null) {
-            yLabelOffset -= lineHeight;
-            textWidth = Math.max(textWidth, idPaints[colorID].measureText(
-                    String.format(Locale.US, "Right eye: %.2f", face.getLeftEyeOpenProbability())));
-        }
-
-        // Draw labels
-        canvas.drawRect(left - BOX_STROKE_WIDTH,
-                top + yLabelOffset,
-                left + textWidth + (2 * BOX_STROKE_WIDTH),
-                top,
-                labelPaints[colorID]);
-        yLabelOffset += ID_TEXT_SIZE;
-        canvas.drawRect(left, top, right, bottom, boxPaints[colorID]);
-        canvas.drawText("ID: " + face.getTrackingId(), left, top + yLabelOffset,
-                idPaints[colorID]);
-        yLabelOffset += lineHeight;
-
-        // Draws all face contours.
-        for (FaceContour contour : face.getAllContours()) {
-            for (PointF point : contour.getPoints()) {
-                canvas.drawCircle(
-                        translateX(point.x), translateY(point.y), FACE_POSITION_RADIUS, facePositionPaint);
-            }
-        }
-
-        // Draws smiling and left/right eye open probabilities.
-        if (face.getSmilingProbability() != null) {
-            canvas.drawText(
-                    "Smiling: " + String.format(Locale.US, "%.2f", face.getSmilingProbability()),
-                    left,
-                    top + yLabelOffset,
-                    idPaints[colorID]);
-            yLabelOffset += lineHeight;
-        }
-
-        FaceLandmark leftEye = face.getLandmark(FaceLandmark.LEFT_EYE);
-        if (leftEye != null && face.getLeftEyeOpenProbability() != null) {
-            canvas.drawText(
-                    "Left eye open: " + String.format(Locale.US, "%.2f", face.getLeftEyeOpenProbability()),
-                    translateX(leftEye.getPosition().x) + ID_X_OFFSET,
-                    translateY(leftEye.getPosition().y) + ID_Y_OFFSET,
-                    idPaints[colorID]);
-        } else if (leftEye != null && face.getLeftEyeOpenProbability() == null) {
-            canvas.drawText(
-                    "Left eye",
-                    left,
-                    top + yLabelOffset,
-                    idPaints[colorID]);
-            yLabelOffset += lineHeight;
-        } else if (leftEye == null && face.getLeftEyeOpenProbability() != null) {
-            canvas.drawText(
-                    "Left eye open: " + String.format(Locale.US, "%.2f", face.getLeftEyeOpenProbability()),
-                    left,
-                    top + yLabelOffset,
-                    idPaints[colorID]);
-            yLabelOffset += lineHeight;
-        }
-
-        FaceLandmark rightEye = face.getLandmark(FaceLandmark.RIGHT_EYE);
-        if (rightEye != null && face.getRightEyeOpenProbability() != null) {
-            canvas.drawText(
-                    "Right eye open: " + String.format(Locale.US, "%.2f", face.getRightEyeOpenProbability()),
-                    translateX(rightEye.getPosition().x) + ID_X_OFFSET,
-                    translateY(rightEye.getPosition().y) + ID_Y_OFFSET,
-                    idPaints[colorID]);
-        } else if (rightEye != null && face.getRightEyeOpenProbability() == null) {
-            canvas.drawText(
-                    "Right eye",
-                    left,
-                    top + yLabelOffset,
-                    idPaints[colorID]);
-            yLabelOffset += lineHeight;
-        } else if (rightEye == null && face.getRightEyeOpenProbability() != null) {
-            canvas.drawText(
-                    "Right eye open: " + String.format(Locale.US, "%.2f", face.getRightEyeOpenProbability()),
-                    left,
-                    top + yLabelOffset,
-                    idPaints[colorID]);
-        }
-
-        // Draw facial landmarks
-        drawFaceLandmark(canvas, FaceLandmark.LEFT_EYE);
-        drawFaceLandmark(canvas, FaceLandmark.RIGHT_EYE);
-        drawFaceLandmark(canvas, FaceLandmark.LEFT_CHEEK);
-        drawFaceLandmark(canvas, FaceLandmark.RIGHT_CHEEK);
-    }
-
-    private void drawFaceLandmark(Canvas canvas, @LandmarkType int landmarkType) {
-        FaceLandmark faceLandmark = face.getLandmark(landmarkType);
-        if (faceLandmark != null) {
-            canvas.drawCircle(
-                    translateX(faceLandmark.getPosition().x),
-                    translateY(faceLandmark.getPosition().y),
-                    FACE_POSITION_RADIUS,
-                    facePositionPaint);
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.facedetector;
+
+import android.graphics.Canvas;
+import android.graphics.Color;
+import android.graphics.Paint;
+import android.graphics.PointF;
+
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic;
+import com.google.mlkit.vision.face.Face;
+import com.google.mlkit.vision.face.FaceContour;
+import com.google.mlkit.vision.face.FaceLandmark;
+import com.google.mlkit.vision.face.FaceLandmark.LandmarkType;
+
+import java.util.Locale;
+
+/**
+ * Graphic instance for rendering face position, contour, and landmarks within the associated
+ * graphic overlay view.
+ */
+public class FaceGraphic extends Graphic {
+    private static final float FACE_POSITION_RADIUS = 4.0f;
+    private static final float ID_TEXT_SIZE = 30.0f;
+    private static final float ID_Y_OFFSET = 40.0f;
+    private static final float ID_X_OFFSET = -40.0f;
+    private static final float BOX_STROKE_WIDTH = 5.0f;
+    private static final int NUM_COLORS = 10;
+    private static final int[][] COLORS = new int[][]{
+            // {Text color, background color}
+            {Color.BLACK, Color.WHITE},
+            {Color.WHITE, Color.MAGENTA},
+            {Color.BLACK, Color.LTGRAY},
+            {Color.WHITE, Color.RED},
+            {Color.WHITE, Color.BLUE},
+            {Color.WHITE, Color.DKGRAY},
+            {Color.BLACK, Color.CYAN},
+            {Color.BLACK, Color.YELLOW},
+            {Color.WHITE, Color.BLACK},
+            {Color.BLACK, Color.GREEN}
+    };
+
+    private final Paint facePositionPaint;
+    private final Paint[] idPaints;
+    private final Paint[] boxPaints;
+    private final Paint[] labelPaints;
+
+    private volatile Face face;
+
+    FaceGraphic(GraphicOverlay overlay, Face face) {
+        super(overlay);
+
+        this.face = face;
+        final int selectedColor = Color.WHITE;
+
+        facePositionPaint = new Paint();
+        facePositionPaint.setColor(selectedColor);
+
+        int numColors = COLORS.length;
+        idPaints = new Paint[numColors];
+        boxPaints = new Paint[numColors];
+        labelPaints = new Paint[numColors];
+        for (int i = 0; i < numColors; i++) {
+            idPaints[i] = new Paint();
+            idPaints[i].setColor(COLORS[i][0] /* text color */);
+            idPaints[i].setTextSize(ID_TEXT_SIZE);
+
+            boxPaints[i] = new Paint();
+            boxPaints[i].setColor(COLORS[i][1] /* background color */);
+            boxPaints[i].setStyle(Paint.Style.STROKE);
+            boxPaints[i].setStrokeWidth(BOX_STROKE_WIDTH);
+
+            labelPaints[i] = new Paint();
+            labelPaints[i].setColor(COLORS[i][1]  /* background color */);
+            labelPaints[i].setStyle(Paint.Style.FILL);
+        }
+    }
+
+    /**
+     * Draws the face annotations for position on the supplied canvas.
+     */
+    @Override
+    public void draw(Canvas canvas) {
+        Face face = this.face;
+        if (face == null) {
+            return;
+        }
+
+        // Draws a circle at the position of the detected face, with the face's track id below.
+        float x = translateX(face.getBoundingBox().centerX());
+        float y = translateY(face.getBoundingBox().centerY());
+        canvas.drawCircle(x, y, FACE_POSITION_RADIUS, facePositionPaint);
+
+        // Calculate positions.
+        float left = x - scale(face.getBoundingBox().width() / 2.0f);
+        float top = y - scale(face.getBoundingBox().height() / 2.0f);
+        float right = x + scale(face.getBoundingBox().width() / 2.0f);
+        float bottom = y + scale(face.getBoundingBox().height() / 2.0f);
+        float lineHeight = ID_TEXT_SIZE + BOX_STROKE_WIDTH;
+        float yLabelOffset = -lineHeight;
+
+        // Decide color based on face ID
+        int colorID = (face.getTrackingId() == null)
+                ? 0 : Math.abs(face.getTrackingId() % NUM_COLORS);
+
+        // Calculate width and height of label box
+        float textWidth = idPaints[colorID].measureText("ID: " + face.getTrackingId());
+        if (face.getSmilingProbability() != null) {
+            yLabelOffset -= lineHeight;
+            textWidth = Math.max(textWidth, idPaints[colorID].measureText(
+                    String.format(Locale.US, "Happiness: %.2f", face.getSmilingProbability())));
+        }
+        if (face.getLeftEyeOpenProbability() != null) {
+            yLabelOffset -= lineHeight;
+            textWidth = Math.max(textWidth, idPaints[colorID].measureText(
+                    String.format(Locale.US, "Left eye: %.2f", face.getLeftEyeOpenProbability())));
+        }
+        if (face.getRightEyeOpenProbability() != null) {
+            yLabelOffset -= lineHeight;
+            textWidth = Math.max(textWidth, idPaints[colorID].measureText(
+                    String.format(Locale.US, "Right eye: %.2f", face.getLeftEyeOpenProbability())));
+        }
+
+        // Draw labels
+        canvas.drawRect(left - BOX_STROKE_WIDTH,
+                top + yLabelOffset,
+                left + textWidth + (2 * BOX_STROKE_WIDTH),
+                top,
+                labelPaints[colorID]);
+        yLabelOffset += ID_TEXT_SIZE;
+        canvas.drawRect(left, top, right, bottom, boxPaints[colorID]);
+        canvas.drawText("ID: " + face.getTrackingId(), left, top + yLabelOffset,
+                idPaints[colorID]);
+        yLabelOffset += lineHeight;
+
+        // Draws all face contours.
+        for (FaceContour contour : face.getAllContours()) {
+            for (PointF point : contour.getPoints()) {
+                canvas.drawCircle(
+                        translateX(point.x), translateY(point.y), FACE_POSITION_RADIUS, facePositionPaint);
+            }
+        }
+
+        // Draws smiling and left/right eye open probabilities.
+        if (face.getSmilingProbability() != null) {
+            canvas.drawText(
+                    "Smiling: " + String.format(Locale.US, "%.2f", face.getSmilingProbability()),
+                    left,
+                    top + yLabelOffset,
+                    idPaints[colorID]);
+            yLabelOffset += lineHeight;
+        }
+
+        FaceLandmark leftEye = face.getLandmark(FaceLandmark.LEFT_EYE);
+        if (leftEye != null && face.getLeftEyeOpenProbability() != null) {
+            canvas.drawText(
+                    "Left eye open: " + String.format(Locale.US, "%.2f", face.getLeftEyeOpenProbability()),
+                    translateX(leftEye.getPosition().x) + ID_X_OFFSET,
+                    translateY(leftEye.getPosition().y) + ID_Y_OFFSET,
+                    idPaints[colorID]);
+        } else if (leftEye != null && face.getLeftEyeOpenProbability() == null) {
+            canvas.drawText(
+                    "Left eye",
+                    left,
+                    top + yLabelOffset,
+                    idPaints[colorID]);
+            yLabelOffset += lineHeight;
+        } else if (leftEye == null && face.getLeftEyeOpenProbability() != null) {
+            canvas.drawText(
+                    "Left eye open: " + String.format(Locale.US, "%.2f", face.getLeftEyeOpenProbability()),
+                    left,
+                    top + yLabelOffset,
+                    idPaints[colorID]);
+            yLabelOffset += lineHeight;
+        }
+
+        FaceLandmark rightEye = face.getLandmark(FaceLandmark.RIGHT_EYE);
+        if (rightEye != null && face.getRightEyeOpenProbability() != null) {
+            canvas.drawText(
+                    "Right eye open: " + String.format(Locale.US, "%.2f", face.getRightEyeOpenProbability()),
+                    translateX(rightEye.getPosition().x) + ID_X_OFFSET,
+                    translateY(rightEye.getPosition().y) + ID_Y_OFFSET,
+                    idPaints[colorID]);
+        } else if (rightEye != null && face.getRightEyeOpenProbability() == null) {
+            canvas.drawText(
+                    "Right eye",
+                    left,
+                    top + yLabelOffset,
+                    idPaints[colorID]);
+            yLabelOffset += lineHeight;
+        } else if (rightEye == null && face.getRightEyeOpenProbability() != null) {
+            canvas.drawText(
+                    "Right eye open: " + String.format(Locale.US, "%.2f", face.getRightEyeOpenProbability()),
+                    left,
+                    top + yLabelOffset,
+                    idPaints[colorID]);
+        }
+
+        // Draw facial landmarks
+        drawFaceLandmark(canvas, FaceLandmark.LEFT_EYE);
+        drawFaceLandmark(canvas, FaceLandmark.RIGHT_EYE);
+        drawFaceLandmark(canvas, FaceLandmark.LEFT_CHEEK);
+        drawFaceLandmark(canvas, FaceLandmark.RIGHT_CHEEK);
+    }
+
+    private void drawFaceLandmark(Canvas canvas, @LandmarkType int landmarkType) {
+        FaceLandmark faceLandmark = face.getLandmark(landmarkType);
+        if (faceLandmark != null) {
+            canvas.drawCircle(
+                    translateX(faceLandmark.getPosition().x),
+                    translateY(faceLandmark.getPosition().y),
+                    FACE_POSITION_RADIUS,
+                    facePositionPaint);
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/CameraXLivePreviewActivity.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/CameraXLivePreviewActivity.kt
index c13d927..f53bffd 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/CameraXLivePreviewActivity.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/CameraXLivePreviewActivity.kt
@@ -1,513 +1,513 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin
-
-import android.annotation.SuppressLint
-import android.content.Context
-import android.content.Intent
-import android.content.pm.PackageManager
-import android.os.Build.VERSION
-import android.os.Build.VERSION_CODES
-import android.os.Bundle
-import android.util.Log
-import android.view.Menu
-import android.view.MenuItem
-import android.view.View
-import android.widget.AdapterView
-import android.widget.AdapterView.OnItemSelectedListener
-import android.widget.ArrayAdapter
-import android.widget.CompoundButton
-import android.widget.ImageView
-import android.widget.Spinner
-import android.widget.Toast
-import android.widget.ToggleButton
-import androidx.appcompat.app.AppCompatActivity
-import androidx.camera.core.CameraInfoUnavailableException
-import androidx.camera.core.CameraSelector
-import androidx.camera.core.ImageAnalysis
-import androidx.camera.core.ImageProxy
-import androidx.camera.core.Preview
-import androidx.camera.lifecycle.ProcessCameraProvider
-import androidx.camera.view.PreviewView
-import androidx.core.app.ActivityCompat
-import androidx.core.content.ContextCompat
-import androidx.lifecycle.Observer
-import androidx.lifecycle.ViewModelProvider
-import com.google.android.gms.common.annotation.KeepName
-import com.google.mlkit.common.MlKitException
-import com.google.mlkit.common.model.LocalModel
-import com.google.mlkit.vision.demo.CameraXViewModel
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.R
-import com.google.mlkit.vision.demo.VisionImageProcessor
-import com.google.mlkit.vision.demo.kotlin.automl.AutoMLImageLabelerProcessor
-import com.google.mlkit.vision.demo.kotlin.barcodescanner.BarcodeScannerProcessor
-import com.google.mlkit.vision.demo.kotlin.facedetector.FaceDetectorProcessor
-import com.google.mlkit.vision.demo.kotlin.labeldetector.LabelDetectorProcessor
-import com.google.mlkit.vision.demo.kotlin.objectdetector.ObjectDetectorProcessor
-import com.google.mlkit.vision.demo.kotlin.textdetector.TextRecognitionProcessor
-import com.google.mlkit.vision.demo.preference.PreferenceUtils
-import com.google.mlkit.vision.demo.preference.SettingsActivity
-import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource
-import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions
-import com.google.mlkit.vision.label.defaults.ImageLabelerOptions
-import java.util.ArrayList
-
-/** Live preview demo app for ML Kit APIs using CameraX.  */
-@KeepName
-class CameraXLivePreviewActivity :
-        AppCompatActivity(),
-        ActivityCompat.OnRequestPermissionsResultCallback,
-        OnItemSelectedListener,
-        CompoundButton.OnCheckedChangeListener {
-
-    private var previewView: PreviewView? = null
-    private var graphicOverlay: GraphicOverlay? = null
-    private var cameraProvider: ProcessCameraProvider? = null
-    private var previewUseCase: Preview? = null
-    private var analysisUseCase: ImageAnalysis? = null
-    private var imageProcessor: VisionImageProcessor? = null
-    private var needUpdateGraphicOverlayImageSourceInfo = false
-    private var selectedModel = OBJECT_DETECTION
-    private var lensFacing = CameraSelector.LENS_FACING_BACK
-    private var cameraSelector: CameraSelector? = null
-
-    override fun onCreate(savedInstanceState: Bundle?) {
-        super.onCreate(savedInstanceState)
-        Log.d(TAG, "onCreate")
-        if (VERSION.SDK_INT < VERSION_CODES.LOLLIPOP) {
-            Toast.makeText(
-                    applicationContext,
-                    "CameraX is only supported on SDK version >=21. Current SDK version is " +
-                            VERSION.SDK_INT,
-                    Toast.LENGTH_LONG
-            )
-                    .show()
-            return
-        }
-        if (savedInstanceState != null) {
-            selectedModel =
-                    savedInstanceState.getString(
-                            STATE_SELECTED_MODEL,
-                            OBJECT_DETECTION
-                    )
-            lensFacing =
-                    savedInstanceState.getInt(
-                            STATE_LENS_FACING,
-                            CameraSelector.LENS_FACING_BACK
-                    )
-        }
-        cameraSelector = CameraSelector.Builder().requireLensFacing(lensFacing).build()
-        setContentView(R.layout.activity_camerax_live_preview)
-        previewView = findViewById(R.id.preview_view)
-        if (previewView == null) {
-            Log.d(TAG, "previewView is null")
-        }
-        graphicOverlay = findViewById(R.id.graphic_overlay)
-        if (graphicOverlay == null) {
-            Log.d(TAG, "graphicOverlay is null")
-        }
-        val spinner = findViewById<Spinner>(R.id.spinner)
-        val options: MutableList<String> = ArrayList()
-        options.add(OBJECT_DETECTION)
-        options.add(OBJECT_DETECTION_CUSTOM)
-        options.add(FACE_DETECTION)
-        options.add(TEXT_RECOGNITION)
-        options.add(BARCODE_SCANNING)
-        options.add(IMAGE_LABELING)
-        options.add(IMAGE_LABELING_CUSTOM)
-        options.add(AUTOML_LABELING)
-        // Creating adapter for spinner
-        val dataAdapter =
-                ArrayAdapter(this, R.layout.spinner_style, options)
-        // Drop down layout style - list view with radio button
-        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item)
-        // attaching data adapter to spinner
-        spinner.adapter = dataAdapter
-        spinner.onItemSelectedListener = this
-        val facingSwitch =
-                findViewById<ToggleButton>(R.id.facing_switch)
-        facingSwitch.setOnCheckedChangeListener(this)
-        ViewModelProvider(this,
-                ViewModelProvider.AndroidViewModelFactory.getInstance(application))
-                .get(CameraXViewModel::class.java)
-                .getProcessCameraProvider()
-                .observe(
-                        this,
-                        Observer { provider: ProcessCameraProvider? ->
-                            cameraProvider = provider
-                            if (allPermissionsGranted()) {
-                                bindAllCameraUseCases()
-                            }
-                        }
-                )
-
-        val settingsButton = findViewById<ImageView>(R.id.settings_button)
-        settingsButton.setOnClickListener { v: View? ->
-            val intent =
-                    Intent(applicationContext, SettingsActivity::class.java)
-            intent.putExtra(
-                    SettingsActivity.EXTRA_LAUNCH_SOURCE,
-                    LaunchSource.CAMERAX_LIVE_PREVIEW
-            )
-            startActivity(intent)
-        }
-
-        if (!allPermissionsGranted()) {
-            runtimePermissions
-        }
-    }
-
-    override fun onSaveInstanceState(bundle: Bundle) {
-        super.onSaveInstanceState(bundle)
-        bundle.putString(STATE_SELECTED_MODEL, selectedModel)
-        bundle.putInt(STATE_LENS_FACING, lensFacing)
-    }
-
-    @Synchronized
-    override fun onItemSelected(parent: AdapterView<*>?, view: View?, pos: Int, id: Long) {
-        // An item was selected. You can retrieve the selected item using
-        // parent.getItemAtPosition(pos)
-        selectedModel = parent?.getItemAtPosition(pos).toString()
-        Log.d(TAG, "Selected model: $selectedModel")
-        bindAnalysisUseCase()
-    }
-
-    override fun onNothingSelected(parent: AdapterView<*>?) {
-        // Do nothing.
-    }
-
-    override fun onCheckedChanged(buttonView: CompoundButton, isChecked: Boolean) {
-        Log.d(TAG, "Set facing")
-        if (cameraProvider == null) {
-            return
-        }
-        val newLensFacing = if (lensFacing == CameraSelector.LENS_FACING_FRONT) {
-            CameraSelector.LENS_FACING_BACK
-        } else {
-            CameraSelector.LENS_FACING_FRONT
-        }
-        val newCameraSelector =
-                CameraSelector.Builder().requireLensFacing(newLensFacing).build()
-        try {
-            if (cameraProvider!!.hasCamera(newCameraSelector)) {
-                lensFacing = newLensFacing
-                cameraSelector = newCameraSelector
-                bindAllCameraUseCases()
-                return
-            }
-        } catch (e: CameraInfoUnavailableException) {
-            // Falls through
-        }
-        Toast.makeText(
-                applicationContext, "This device does not have lens with facing: $newLensFacing",
-                Toast.LENGTH_SHORT
-        )
-                .show()
-    }
-
-    override fun onCreateOptionsMenu(menu: Menu): Boolean {
-        menuInflater.inflate(R.menu.live_preview_menu, menu)
-        return true
-    }
-
-    override fun onOptionsItemSelected(item: MenuItem): Boolean {
-        if (item.itemId == R.id.settings) {
-            val intent = Intent(this, SettingsActivity::class.java)
-            intent.putExtra(
-                    SettingsActivity.EXTRA_LAUNCH_SOURCE,
-                    LaunchSource.CAMERAX_LIVE_PREVIEW
-            )
-            startActivity(intent)
-            return true
-        }
-        return super.onOptionsItemSelected(item)
-    }
-
-    public override fun onResume() {
-        super.onResume()
-        bindAllCameraUseCases()
-    }
-
-    override fun onPause() {
-        super.onPause()
-
-        imageProcessor?.run {
-            this.stop()
-        }
-    }
-
-    public override fun onDestroy() {
-        super.onDestroy()
-        imageProcessor?.run {
-            this.stop()
-        }
-    }
-
-    private fun bindAllCameraUseCases() {
-        bindPreviewUseCase()
-        bindAnalysisUseCase()
-    }
-
-    private fun bindPreviewUseCase() {
-        if (!PreferenceUtils.isCameraLiveViewportEnabled(this)) {
-            return
-        }
-        if (cameraProvider == null) {
-            return
-        }
-        if (previewUseCase != null) {
-            cameraProvider!!.unbind(previewUseCase)
-        }
-
-        previewUseCase = Preview.Builder().build()
-        previewUseCase!!.setSurfaceProvider(previewView!!.createSurfaceProvider())
-        cameraProvider!!.bindToLifecycle(/* lifecycleOwner= */this, cameraSelector!!, previewUseCase)
-    }
-
-    @SuppressLint("NewApi")
-    private fun bindAnalysisUseCase() {
-        if (cameraProvider == null) {
-            return
-        }
-        if (analysisUseCase != null) {
-            cameraProvider!!.unbind(analysisUseCase)
-        }
-        if (imageProcessor != null) {
-            imageProcessor!!.stop()
-        }
-        imageProcessor = try {
-            when (selectedModel) {
-                OBJECT_DETECTION -> {
-                    Log.i(
-                            TAG,
-                            "Using Object Detector Processor"
-                    )
-                    val objectDetectorOptions =
-                            PreferenceUtils.getObjectDetectorOptionsForLivePreview(this)
-                    ObjectDetectorProcessor(
-                            this, objectDetectorOptions
-                    )
-                }
-                OBJECT_DETECTION_CUSTOM -> {
-                    Log.i(
-                            TAG,
-                            "Using Custom Object Detector (Bird) Processor"
-                    )
-                    val localModel = LocalModel.Builder()
-                            .setAssetFilePath("custom_models/bird_classifier.tflite")
-                            .build()
-                    val customObjectDetectorOptions =
-                            PreferenceUtils.getCustomObjectDetectorOptionsForLivePreview(this, localModel)
-                    ObjectDetectorProcessor(
-                            this, customObjectDetectorOptions
-                    )
-                }
-                TEXT_RECOGNITION -> {
-                    Log.i(
-                            TAG,
-                            "Using on-device Text recognition Processor"
-                    )
-                    TextRecognitionProcessor(this)
-                }
-                FACE_DETECTION -> {
-                    Log.i(
-                            TAG,
-                            "Using Face Detector Processor"
-                    )
-                    val faceDetectorOptions =
-                            PreferenceUtils.getFaceDetectorOptionsForLivePreview(this)
-                    FaceDetectorProcessor(this, faceDetectorOptions)
-                }
-                BARCODE_SCANNING -> {
-                    Log.i(
-                            TAG,
-                            "Using Barcode Detector Processor"
-                    )
-                    BarcodeScannerProcessor(this)
-                }
-                IMAGE_LABELING -> {
-                    Log.i(
-                            TAG,
-                            "Using Image Label Detector Processor"
-                    )
-                    LabelDetectorProcessor(
-                            this, ImageLabelerOptions.DEFAULT_OPTIONS
-                    )
-                }
-                IMAGE_LABELING_CUSTOM -> {
-                    Log.i(
-                            TAG,
-                            "Using Custom Image Label (Bird) Detector Processor"
-                    )
-                    val localClassifier = LocalModel.Builder()
-                            .setAssetFilePath("custom_models/bird_classifier.tflite")
-                            .build()
-                    val customImageLabelerOptions =
-                            CustomImageLabelerOptions.Builder(localClassifier).build()
-                    LabelDetectorProcessor(
-                            this, customImageLabelerOptions
-                    )
-                }
-                AUTOML_LABELING -> AutoMLImageLabelerProcessor(this)
-                else -> throw IllegalStateException("Invalid model name")
-            }
-        } catch (e: Exception) {
-            Log.e(
-                    TAG,
-                    "Can not create image processor: $selectedModel",
-                    e
-            )
-            Toast.makeText(
-                    applicationContext,
-                    "Can not create image processor: " + e.localizedMessage,
-                    Toast.LENGTH_LONG
-            )
-                    .show()
-            return
-        }
-
-        val builder = ImageAnalysis.Builder()
-        val targetAnalysisSize = PreferenceUtils.getCameraXTargetAnalysisSize(this)
-        if (targetAnalysisSize != null) {
-            builder.setTargetResolution(targetAnalysisSize)
-        }
-        analysisUseCase = builder.build()
-
-        needUpdateGraphicOverlayImageSourceInfo = true
-
-        analysisUseCase?.setAnalyzer(
-                // imageProcessor.processImageProxy will use another thread to run the detection underneath,
-                // thus we can just runs the analyzer itself on main thread.
-                ContextCompat.getMainExecutor(this),
-                ImageAnalysis.Analyzer { imageProxy: ImageProxy ->
-                    if (needUpdateGraphicOverlayImageSourceInfo) {
-                        val isImageFlipped =
-                                lensFacing == CameraSelector.LENS_FACING_FRONT
-                        val rotationDegrees =
-                                imageProxy.imageInfo.rotationDegrees
-                        if (rotationDegrees == 0 || rotationDegrees == 180) {
-                            graphicOverlay!!.setImageSourceInfo(
-                                    imageProxy.width, imageProxy.height, isImageFlipped
-                            )
-                        } else {
-                            graphicOverlay!!.setImageSourceInfo(
-                                    imageProxy.height, imageProxy.width, isImageFlipped
-                            )
-                        }
-                        needUpdateGraphicOverlayImageSourceInfo = false
-                    }
-                    try {
-                        imageProcessor!!.processImageProxy(imageProxy, graphicOverlay)
-                    } catch (e: MlKitException) {
-                        Log.e(
-                                TAG,
-                                "Failed to process image. Error: " + e.localizedMessage
-                        )
-                        Toast.makeText(
-                                applicationContext,
-                                e.localizedMessage,
-                                Toast.LENGTH_SHORT
-                        )
-                                .show()
-                    }
-                }
-        )
-        cameraProvider!!.bindToLifecycle( /* lifecycleOwner= */this, cameraSelector!!, analysisUseCase)
-    }
-
-    private val requiredPermissions: Array<String?>
-        get() = try {
-            val info = this.packageManager
-                    .getPackageInfo(this.packageName, PackageManager.GET_PERMISSIONS)
-            val ps = info.requestedPermissions
-            if (ps != null && ps.size > 0) {
-                ps
-            } else {
-                arrayOfNulls(0)
-            }
-        } catch (e: Exception) {
-            arrayOfNulls(0)
-        }
-
-    private fun allPermissionsGranted(): Boolean {
-        for (permission in requiredPermissions) {
-            if (!isPermissionGranted(this, permission)) {
-                return false
-            }
-        }
-        return true
-    }
-
-    private val runtimePermissions: Unit
-        get() {
-            val allNeededPermissions: MutableList<String?> = ArrayList()
-            for (permission in requiredPermissions) {
-                if (!isPermissionGranted(this, permission)) {
-                    allNeededPermissions.add(permission)
-                }
-            }
-            if (!allNeededPermissions.isEmpty()) {
-                ActivityCompat.requestPermissions(
-                        this,
-                        allNeededPermissions.toTypedArray(),
-                        PERMISSION_REQUESTS
-                )
-            }
-        }
-
-    override fun onRequestPermissionsResult(
-            requestCode: Int,
-            permissions: Array<String>,
-            grantResults: IntArray
-    ) {
-        Log.i(TAG, "Permission granted!")
-        if (allPermissionsGranted()) {
-            bindAllCameraUseCases()
-        }
-        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
-    }
-
-    companion object {
-        private const val TAG = "CameraXLivePreview"
-        private const val PERMISSION_REQUESTS = 1
-        private const val OBJECT_DETECTION = "Object Detection"
-        private const val OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Bird)"
-        private const val FACE_DETECTION = "Face Detection"
-        private const val TEXT_RECOGNITION = "Text Recognition"
-        private const val BARCODE_SCANNING = "Barcode Scanning"
-        private const val IMAGE_LABELING = "Image Labeling"
-        private const val IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Bird)"
-        private const val AUTOML_LABELING = "AutoML Image Labeling"
-        private const val STATE_SELECTED_MODEL = "selected_model"
-        private const val STATE_LENS_FACING = "lens_facing"
-
-        private fun isPermissionGranted(
-                context: Context,
-                permission: String?
-        ): Boolean {
-            if (ContextCompat.checkSelfPermission(context, permission!!)
-                    == PackageManager.PERMISSION_GRANTED
-            ) {
-                Log.i(TAG, "Permission granted: $permission")
-                return true
-            }
-            Log.i(TAG, "Permission NOT granted: $permission")
-            return false
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin
+
+import android.annotation.SuppressLint
+import android.content.Context
+import android.content.Intent
+import android.content.pm.PackageManager
+import android.os.Build.VERSION
+import android.os.Build.VERSION_CODES
+import android.os.Bundle
+import android.util.Log
+import android.view.Menu
+import android.view.MenuItem
+import android.view.View
+import android.widget.AdapterView
+import android.widget.AdapterView.OnItemSelectedListener
+import android.widget.ArrayAdapter
+import android.widget.CompoundButton
+import android.widget.ImageView
+import android.widget.Spinner
+import android.widget.Toast
+import android.widget.ToggleButton
+import androidx.appcompat.app.AppCompatActivity
+import androidx.camera.core.CameraInfoUnavailableException
+import androidx.camera.core.CameraSelector
+import androidx.camera.core.ImageAnalysis
+import androidx.camera.core.ImageProxy
+import androidx.camera.core.Preview
+import androidx.camera.lifecycle.ProcessCameraProvider
+import androidx.camera.view.PreviewView
+import androidx.core.app.ActivityCompat
+import androidx.core.content.ContextCompat
+import androidx.lifecycle.Observer
+import androidx.lifecycle.ViewModelProvider
+import com.google.android.gms.common.annotation.KeepName
+import com.google.mlkit.common.MlKitException
+import com.google.mlkit.common.model.LocalModel
+import com.google.mlkit.vision.demo.CameraXViewModel
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.R
+import com.google.mlkit.vision.demo.VisionImageProcessor
+import com.google.mlkit.vision.demo.kotlin.automl.AutoMLImageLabelerProcessor
+import com.google.mlkit.vision.demo.kotlin.barcodescanner.BarcodeScannerProcessor
+import com.google.mlkit.vision.demo.kotlin.facedetector.FaceDetectorProcessor
+import com.google.mlkit.vision.demo.kotlin.labeldetector.LabelDetectorProcessor
+import com.google.mlkit.vision.demo.kotlin.objectdetector.ObjectDetectorProcessor
+import com.google.mlkit.vision.demo.kotlin.textdetector.TextRecognitionProcessor
+import com.google.mlkit.vision.demo.preference.PreferenceUtils
+import com.google.mlkit.vision.demo.preference.SettingsActivity
+import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource
+import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions
+import com.google.mlkit.vision.label.defaults.ImageLabelerOptions
+import java.util.ArrayList
+
+/** Live preview demo app for ML Kit APIs using CameraX.  */
+@KeepName
+class CameraXLivePreviewActivity :
+        AppCompatActivity(),
+        ActivityCompat.OnRequestPermissionsResultCallback,
+        OnItemSelectedListener,
+        CompoundButton.OnCheckedChangeListener {
+
+    private var previewView: PreviewView? = null
+    private var graphicOverlay: GraphicOverlay? = null
+    private var cameraProvider: ProcessCameraProvider? = null
+    private var previewUseCase: Preview? = null
+    private var analysisUseCase: ImageAnalysis? = null
+    private var imageProcessor: VisionImageProcessor? = null
+    private var needUpdateGraphicOverlayImageSourceInfo = false
+    private var selectedModel = OBJECT_DETECTION
+    private var lensFacing = CameraSelector.LENS_FACING_BACK
+    private var cameraSelector: CameraSelector? = null
+
+    override fun onCreate(savedInstanceState: Bundle?) {
+        super.onCreate(savedInstanceState)
+        Log.d(TAG, "onCreate")
+        if (VERSION.SDK_INT < VERSION_CODES.LOLLIPOP) {
+            Toast.makeText(
+                    applicationContext,
+                    "CameraX is only supported on SDK version >=21. Current SDK version is " +
+                            VERSION.SDK_INT,
+                    Toast.LENGTH_LONG
+            )
+                    .show()
+            return
+        }
+        if (savedInstanceState != null) {
+            selectedModel =
+                    savedInstanceState.getString(
+                            STATE_SELECTED_MODEL,
+                            OBJECT_DETECTION
+                    )
+            lensFacing =
+                    savedInstanceState.getInt(
+                            STATE_LENS_FACING,
+                            CameraSelector.LENS_FACING_BACK
+                    )
+        }
+        cameraSelector = CameraSelector.Builder().requireLensFacing(lensFacing).build()
+        setContentView(R.layout.activity_camerax_live_preview)
+        previewView = findViewById(R.id.preview_view)
+        if (previewView == null) {
+            Log.d(TAG, "previewView is null")
+        }
+        graphicOverlay = findViewById(R.id.graphic_overlay)
+        if (graphicOverlay == null) {
+            Log.d(TAG, "graphicOverlay is null")
+        }
+        val spinner = findViewById<Spinner>(R.id.spinner)
+        val options: MutableList<String> = ArrayList()
+        options.add(OBJECT_DETECTION)
+        options.add(OBJECT_DETECTION_CUSTOM)
+        options.add(FACE_DETECTION)
+        options.add(TEXT_RECOGNITION)
+        options.add(BARCODE_SCANNING)
+        options.add(IMAGE_LABELING)
+        options.add(IMAGE_LABELING_CUSTOM)
+        options.add(AUTOML_LABELING)
+        // Creating adapter for spinner
+        val dataAdapter =
+                ArrayAdapter(this, R.layout.spinner_style, options)
+        // Drop down layout style - list view with radio button
+        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item)
+        // attaching data adapter to spinner
+        spinner.adapter = dataAdapter
+        spinner.onItemSelectedListener = this
+        val facingSwitch =
+                findViewById<ToggleButton>(R.id.facing_switch)
+        facingSwitch.setOnCheckedChangeListener(this)
+        ViewModelProvider(this,
+                ViewModelProvider.AndroidViewModelFactory.getInstance(application))
+                .get(CameraXViewModel::class.java)
+                .getProcessCameraProvider()
+                .observe(
+                        this,
+                        Observer { provider: ProcessCameraProvider? ->
+                            cameraProvider = provider
+                            if (allPermissionsGranted()) {
+                                bindAllCameraUseCases()
+                            }
+                        }
+                )
+
+        val settingsButton = findViewById<ImageView>(R.id.settings_button)
+        settingsButton.setOnClickListener { v: View? ->
+            val intent =
+                    Intent(applicationContext, SettingsActivity::class.java)
+            intent.putExtra(
+                    SettingsActivity.EXTRA_LAUNCH_SOURCE,
+                    LaunchSource.CAMERAX_LIVE_PREVIEW
+            )
+            startActivity(intent)
+        }
+
+        if (!allPermissionsGranted()) {
+            runtimePermissions
+        }
+    }
+
+    override fun onSaveInstanceState(bundle: Bundle) {
+        super.onSaveInstanceState(bundle)
+        bundle.putString(STATE_SELECTED_MODEL, selectedModel)
+        bundle.putInt(STATE_LENS_FACING, lensFacing)
+    }
+
+    @Synchronized
+    override fun onItemSelected(parent: AdapterView<*>?, view: View?, pos: Int, id: Long) {
+        // An item was selected. You can retrieve the selected item using
+        // parent.getItemAtPosition(pos)
+        selectedModel = parent?.getItemAtPosition(pos).toString()
+        Log.d(TAG, "Selected model: $selectedModel")
+        bindAnalysisUseCase()
+    }
+
+    override fun onNothingSelected(parent: AdapterView<*>?) {
+        // Do nothing.
+    }
+
+    override fun onCheckedChanged(buttonView: CompoundButton, isChecked: Boolean) {
+        Log.d(TAG, "Set facing")
+        if (cameraProvider == null) {
+            return
+        }
+        val newLensFacing = if (lensFacing == CameraSelector.LENS_FACING_FRONT) {
+            CameraSelector.LENS_FACING_BACK
+        } else {
+            CameraSelector.LENS_FACING_FRONT
+        }
+        val newCameraSelector =
+                CameraSelector.Builder().requireLensFacing(newLensFacing).build()
+        try {
+            if (cameraProvider!!.hasCamera(newCameraSelector)) {
+                lensFacing = newLensFacing
+                cameraSelector = newCameraSelector
+                bindAllCameraUseCases()
+                return
+            }
+        } catch (e: CameraInfoUnavailableException) {
+            // Falls through
+        }
+        Toast.makeText(
+                applicationContext, "This device does not have lens with facing: $newLensFacing",
+                Toast.LENGTH_SHORT
+        )
+                .show()
+    }
+
+    override fun onCreateOptionsMenu(menu: Menu): Boolean {
+        menuInflater.inflate(R.menu.live_preview_menu, menu)
+        return true
+    }
+
+    override fun onOptionsItemSelected(item: MenuItem): Boolean {
+        if (item.itemId == R.id.settings) {
+            val intent = Intent(this, SettingsActivity::class.java)
+            intent.putExtra(
+                    SettingsActivity.EXTRA_LAUNCH_SOURCE,
+                    LaunchSource.CAMERAX_LIVE_PREVIEW
+            )
+            startActivity(intent)
+            return true
+        }
+        return super.onOptionsItemSelected(item)
+    }
+
+    public override fun onResume() {
+        super.onResume()
+        bindAllCameraUseCases()
+    }
+
+    override fun onPause() {
+        super.onPause()
+
+        imageProcessor?.run {
+            this.stop()
+        }
+    }
+
+    public override fun onDestroy() {
+        super.onDestroy()
+        imageProcessor?.run {
+            this.stop()
+        }
+    }
+
+    private fun bindAllCameraUseCases() {
+        bindPreviewUseCase()
+        bindAnalysisUseCase()
+    }
+
+    private fun bindPreviewUseCase() {
+        if (!PreferenceUtils.isCameraLiveViewportEnabled(this)) {
+            return
+        }
+        if (cameraProvider == null) {
+            return
+        }
+        if (previewUseCase != null) {
+            cameraProvider!!.unbind(previewUseCase)
+        }
+
+        previewUseCase = Preview.Builder().build()
+        previewUseCase!!.setSurfaceProvider(previewView!!.createSurfaceProvider())
+        cameraProvider!!.bindToLifecycle(/* lifecycleOwner= */this, cameraSelector!!, previewUseCase)
+    }
+
+    @SuppressLint("NewApi")
+    private fun bindAnalysisUseCase() {
+        if (cameraProvider == null) {
+            return
+        }
+        if (analysisUseCase != null) {
+            cameraProvider!!.unbind(analysisUseCase)
+        }
+        if (imageProcessor != null) {
+            imageProcessor!!.stop()
+        }
+        imageProcessor = try {
+            when (selectedModel) {
+                OBJECT_DETECTION -> {
+                    Log.i(
+                            TAG,
+                            "Using Object Detector Processor"
+                    )
+                    val objectDetectorOptions =
+                            PreferenceUtils.getObjectDetectorOptionsForLivePreview(this)
+                    ObjectDetectorProcessor(
+                            this, objectDetectorOptions
+                    )
+                }
+                OBJECT_DETECTION_CUSTOM -> {
+                    Log.i(
+                            TAG,
+                            "Using Custom Object Detector (Bird) Processor"
+                    )
+                    val localModel = LocalModel.Builder()
+                            .setAssetFilePath("custom_models/bird_classifier.tflite")
+                            .build()
+                    val customObjectDetectorOptions =
+                            PreferenceUtils.getCustomObjectDetectorOptionsForLivePreview(this, localModel)
+                    ObjectDetectorProcessor(
+                            this, customObjectDetectorOptions
+                    )
+                }
+                TEXT_RECOGNITION -> {
+                    Log.i(
+                            TAG,
+                            "Using on-device Text recognition Processor"
+                    )
+                    TextRecognitionProcessor(this)
+                }
+                FACE_DETECTION -> {
+                    Log.i(
+                            TAG,
+                            "Using Face Detector Processor"
+                    )
+                    val faceDetectorOptions =
+                            PreferenceUtils.getFaceDetectorOptionsForLivePreview(this)
+                    FaceDetectorProcessor(this, faceDetectorOptions)
+                }
+                BARCODE_SCANNING -> {
+                    Log.i(
+                            TAG,
+                            "Using Barcode Detector Processor"
+                    )
+                    BarcodeScannerProcessor(this)
+                }
+                IMAGE_LABELING -> {
+                    Log.i(
+                            TAG,
+                            "Using Image Label Detector Processor"
+                    )
+                    LabelDetectorProcessor(
+                            this, ImageLabelerOptions.DEFAULT_OPTIONS
+                    )
+                }
+                IMAGE_LABELING_CUSTOM -> {
+                    Log.i(
+                            TAG,
+                            "Using Custom Image Label (Bird) Detector Processor"
+                    )
+                    val localClassifier = LocalModel.Builder()
+                            .setAssetFilePath("custom_models/bird_classifier.tflite")
+                            .build()
+                    val customImageLabelerOptions =
+                            CustomImageLabelerOptions.Builder(localClassifier).build()
+                    LabelDetectorProcessor(
+                            this, customImageLabelerOptions
+                    )
+                }
+                AUTOML_LABELING -> AutoMLImageLabelerProcessor(this)
+                else -> throw IllegalStateException("Invalid model name")
+            }
+        } catch (e: Exception) {
+            Log.e(
+                    TAG,
+                    "Can not create image processor: $selectedModel",
+                    e
+            )
+            Toast.makeText(
+                    applicationContext,
+                    "Can not create image processor: " + e.localizedMessage,
+                    Toast.LENGTH_LONG
+            )
+                    .show()
+            return
+        }
+
+        val builder = ImageAnalysis.Builder()
+        val targetAnalysisSize = PreferenceUtils.getCameraXTargetAnalysisSize(this)
+        if (targetAnalysisSize != null) {
+            builder.setTargetResolution(targetAnalysisSize)
+        }
+        analysisUseCase = builder.build()
+
+        needUpdateGraphicOverlayImageSourceInfo = true
+
+        analysisUseCase?.setAnalyzer(
+                // imageProcessor.processImageProxy will use another thread to run the detection underneath,
+                // thus we can just runs the analyzer itself on main thread.
+                ContextCompat.getMainExecutor(this),
+                ImageAnalysis.Analyzer { imageProxy: ImageProxy ->
+                    if (needUpdateGraphicOverlayImageSourceInfo) {
+                        val isImageFlipped =
+                                lensFacing == CameraSelector.LENS_FACING_FRONT
+                        val rotationDegrees =
+                                imageProxy.imageInfo.rotationDegrees
+                        if (rotationDegrees == 0 || rotationDegrees == 180) {
+                            graphicOverlay!!.setImageSourceInfo(
+                                    imageProxy.width, imageProxy.height, isImageFlipped
+                            )
+                        } else {
+                            graphicOverlay!!.setImageSourceInfo(
+                                    imageProxy.height, imageProxy.width, isImageFlipped
+                            )
+                        }
+                        needUpdateGraphicOverlayImageSourceInfo = false
+                    }
+                    try {
+                        imageProcessor!!.processImageProxy(imageProxy, graphicOverlay)
+                    } catch (e: MlKitException) {
+                        Log.e(
+                                TAG,
+                                "Failed to process image. Error: " + e.localizedMessage
+                        )
+                        Toast.makeText(
+                                applicationContext,
+                                e.localizedMessage,
+                                Toast.LENGTH_SHORT
+                        )
+                                .show()
+                    }
+                }
+        )
+        cameraProvider!!.bindToLifecycle( /* lifecycleOwner= */this, cameraSelector!!, analysisUseCase)
+    }
+
+    private val requiredPermissions: Array<String?>
+        get() = try {
+            val info = this.packageManager
+                    .getPackageInfo(this.packageName, PackageManager.GET_PERMISSIONS)
+            val ps = info.requestedPermissions
+            if (ps != null && ps.size > 0) {
+                ps
+            } else {
+                arrayOfNulls(0)
+            }
+        } catch (e: Exception) {
+            arrayOfNulls(0)
+        }
+
+    private fun allPermissionsGranted(): Boolean {
+        for (permission in requiredPermissions) {
+            if (!isPermissionGranted(this, permission)) {
+                return false
+            }
+        }
+        return true
+    }
+
+    private val runtimePermissions: Unit
+        get() {
+            val allNeededPermissions: MutableList<String?> = ArrayList()
+            for (permission in requiredPermissions) {
+                if (!isPermissionGranted(this, permission)) {
+                    allNeededPermissions.add(permission)
+                }
+            }
+            if (!allNeededPermissions.isEmpty()) {
+                ActivityCompat.requestPermissions(
+                        this,
+                        allNeededPermissions.toTypedArray(),
+                        PERMISSION_REQUESTS
+                )
+            }
+        }
+
+    override fun onRequestPermissionsResult(
+            requestCode: Int,
+            permissions: Array<String>,
+            grantResults: IntArray
+    ) {
+        Log.i(TAG, "Permission granted!")
+        if (allPermissionsGranted()) {
+            bindAllCameraUseCases()
+        }
+        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
+    }
+
+    companion object {
+        private const val TAG = "CameraXLivePreview"
+        private const val PERMISSION_REQUESTS = 1
+        private const val OBJECT_DETECTION = "Object Detection"
+        private const val OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Bird)"
+        private const val FACE_DETECTION = "Face Detection"
+        private const val TEXT_RECOGNITION = "Text Recognition"
+        private const val BARCODE_SCANNING = "Barcode Scanning"
+        private const val IMAGE_LABELING = "Image Labeling"
+        private const val IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Bird)"
+        private const val AUTOML_LABELING = "AutoML Image Labeling"
+        private const val STATE_SELECTED_MODEL = "selected_model"
+        private const val STATE_LENS_FACING = "lens_facing"
+
+        private fun isPermissionGranted(
+                context: Context,
+                permission: String?
+        ): Boolean {
+            if (ContextCompat.checkSelfPermission(context, permission!!)
+                    == PackageManager.PERMISSION_GRANTED
+            ) {
+                Log.i(TAG, "Permission granted: $permission")
+                return true
+            }
+            Log.i(TAG, "Permission NOT granted: $permission")
+            return false
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/ChooserActivity.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/ChooserActivity.kt
index 391f5cd..119d711 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/ChooserActivity.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/ChooserActivity.kt
@@ -1,178 +1,178 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin
-
-import android.content.Context
-import android.content.Intent
-import android.content.pm.PackageManager
-import android.os.Bundle
-import android.util.Log
-import android.view.LayoutInflater
-import android.view.View
-import android.view.ViewGroup
-import android.widget.AdapterView
-import android.widget.AdapterView.OnItemClickListener
-import android.widget.ArrayAdapter
-import android.widget.ListView
-import android.widget.TextView
-import androidx.appcompat.app.AppCompatActivity
-import androidx.core.app.ActivityCompat
-import androidx.core.content.ContextCompat
-import com.google.mlkit.vision.demo.R
-import java.util.ArrayList
-
-/**
- * Demo app chooser which takes care of runtime permission requesting and allow you pick from all
- * available testing Activities.
- */
-class ChooserActivity :
-        AppCompatActivity(),
-        ActivityCompat.OnRequestPermissionsResultCallback,
-        OnItemClickListener {
-    override fun onCreate(savedInstanceState: Bundle?) {
-        super.onCreate(savedInstanceState)
-        Log.d(TAG, "onCreate")
-        setContentView(R.layout.activity_chooser)
-
-        // Set up ListView and Adapter
-        val listView =
-                findViewById<ListView>(R.id.test_activity_list_view)
-        val adapter =
-                MyArrayAdapter(this, android.R.layout.simple_list_item_2, CLASSES)
-        adapter.setDescriptionIds(DESCRIPTION_IDS)
-        listView.adapter = adapter
-        listView.onItemClickListener = this
-
-        if (!allPermissionsGranted()) {
-            getRuntimePermissions()
-        }
-    }
-
-    override fun onItemClick(parent: AdapterView<*>?, view: View, position: Int, id: Long) {
-        val clicked = CLASSES[position]
-        startActivity(Intent(this, clicked))
-    }
-
-    private fun getRequiredPermissions(): Array<String?> {
-        return try {
-            val info = this.packageManager
-                    .getPackageInfo(this.packageName, PackageManager.GET_PERMISSIONS)
-            val ps = info.requestedPermissions
-            if (ps != null && ps.isNotEmpty()) {
-                ps
-            } else {
-                arrayOfNulls(0)
-            }
-        } catch (e: Exception) {
-            arrayOfNulls(0)
-        }
-    }
-
-    private fun allPermissionsGranted(): Boolean {
-        for (permission in getRequiredPermissions()) {
-            permission?.let {
-                if (!isPermissionGranted(this, it)) {
-                    return false
-                }
-            }
-        }
-        return true
-    }
-
-    private fun getRuntimePermissions() {
-        val allNeededPermissions = ArrayList<String>()
-        for (permission in getRequiredPermissions()) {
-            permission?.let {
-                if (!isPermissionGranted(this, it)) {
-                    allNeededPermissions.add(permission)
-                }
-            }
-        }
-
-        if (allNeededPermissions.isNotEmpty()) {
-            ActivityCompat.requestPermissions(
-                    this, allNeededPermissions.toTypedArray(), PERMISSION_REQUESTS
-            )
-        }
-    }
-
-    private fun isPermissionGranted(context: Context, permission: String): Boolean {
-        if (ContextCompat.checkSelfPermission(context, permission)
-                == PackageManager.PERMISSION_GRANTED
-        ) {
-            Log.i(TAG, "Permission granted: $permission")
-            return true
-        }
-        Log.i(TAG, "Permission NOT granted: $permission")
-        return false
-    }
-
-    private class MyArrayAdapter(
-            private val ctx: Context,
-            resource: Int,
-            private val classes: Array<Class<*>>
-    ) : ArrayAdapter<Class<*>>(ctx, resource, classes) {
-        private var descriptionIds: IntArray? = null
-
-        override fun getView(position: Int, convertView: View?, parent: ViewGroup): View {
-            var view = convertView
-
-            if (convertView == null) {
-                val inflater = ctx.getSystemService(Context.LAYOUT_INFLATER_SERVICE) as LayoutInflater
-                view = inflater.inflate(android.R.layout.simple_list_item_2, null)
-            }
-
-            (view!!.findViewById<View>(android.R.id.text1) as TextView).text =
-                    classes[position].simpleName
-            descriptionIds?.let {
-                (view.findViewById<View>(android.R.id.text2) as TextView).setText(it[position])
-            }
-
-            return view
-        }
-
-        fun setDescriptionIds(descriptionIds: IntArray) {
-            this.descriptionIds = descriptionIds
-        }
-    }
-
-    companion object {
-        private const val TAG = "ChooserActivity"
-        private const val PERMISSION_REQUESTS = 1
-        private val CLASSES = arrayOf<Class<*>>(
-                LivePreviewActivity::class.java,
-                StillImageActivity::class.java,
-                CameraXLivePreviewActivity::class.java
-        )
-        private val DESCRIPTION_IDS = intArrayOf(
-                R.string.desc_camera_source_activity,
-                R.string.desc_still_image_activity,
-                R.string.desc_camerax_live_preview_activity
-        )
-
-        private fun isPermissionGranted(context: Context, permission: String?): Boolean {
-            if (ContextCompat.checkSelfPermission(context, permission!!)
-                    == PackageManager.PERMISSION_GRANTED
-            ) {
-                Log.i(TAG, "Permission granted: $permission")
-                return true
-            }
-            Log.i(TAG, "Permission NOT granted: $permission")
-            return false
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin
+
+import android.content.Context
+import android.content.Intent
+import android.content.pm.PackageManager
+import android.os.Bundle
+import android.util.Log
+import android.view.LayoutInflater
+import android.view.View
+import android.view.ViewGroup
+import android.widget.AdapterView
+import android.widget.AdapterView.OnItemClickListener
+import android.widget.ArrayAdapter
+import android.widget.ListView
+import android.widget.TextView
+import androidx.appcompat.app.AppCompatActivity
+import androidx.core.app.ActivityCompat
+import androidx.core.content.ContextCompat
+import com.google.mlkit.vision.demo.R
+import java.util.ArrayList
+
+/**
+ * Demo app chooser which takes care of runtime permission requesting and allow you pick from all
+ * available testing Activities.
+ */
+class ChooserActivity :
+        AppCompatActivity(),
+        ActivityCompat.OnRequestPermissionsResultCallback,
+        OnItemClickListener {
+    override fun onCreate(savedInstanceState: Bundle?) {
+        super.onCreate(savedInstanceState)
+        Log.d(TAG, "onCreate")
+        setContentView(R.layout.activity_chooser)
+
+        // Set up ListView and Adapter
+        val listView =
+                findViewById<ListView>(R.id.test_activity_list_view)
+        val adapter =
+                MyArrayAdapter(this, android.R.layout.simple_list_item_2, CLASSES)
+        adapter.setDescriptionIds(DESCRIPTION_IDS)
+        listView.adapter = adapter
+        listView.onItemClickListener = this
+
+        if (!allPermissionsGranted()) {
+            getRuntimePermissions()
+        }
+    }
+
+    override fun onItemClick(parent: AdapterView<*>?, view: View, position: Int, id: Long) {
+        val clicked = CLASSES[position]
+        startActivity(Intent(this, clicked))
+    }
+
+    private fun getRequiredPermissions(): Array<String?> {
+        return try {
+            val info = this.packageManager
+                    .getPackageInfo(this.packageName, PackageManager.GET_PERMISSIONS)
+            val ps = info.requestedPermissions
+            if (ps != null && ps.isNotEmpty()) {
+                ps
+            } else {
+                arrayOfNulls(0)
+            }
+        } catch (e: Exception) {
+            arrayOfNulls(0)
+        }
+    }
+
+    private fun allPermissionsGranted(): Boolean {
+        for (permission in getRequiredPermissions()) {
+            permission?.let {
+                if (!isPermissionGranted(this, it)) {
+                    return false
+                }
+            }
+        }
+        return true
+    }
+
+    private fun getRuntimePermissions() {
+        val allNeededPermissions = ArrayList<String>()
+        for (permission in getRequiredPermissions()) {
+            permission?.let {
+                if (!isPermissionGranted(this, it)) {
+                    allNeededPermissions.add(permission)
+                }
+            }
+        }
+
+        if (allNeededPermissions.isNotEmpty()) {
+            ActivityCompat.requestPermissions(
+                    this, allNeededPermissions.toTypedArray(), PERMISSION_REQUESTS
+            )
+        }
+    }
+
+    private fun isPermissionGranted(context: Context, permission: String): Boolean {
+        if (ContextCompat.checkSelfPermission(context, permission)
+                == PackageManager.PERMISSION_GRANTED
+        ) {
+            Log.i(TAG, "Permission granted: $permission")
+            return true
+        }
+        Log.i(TAG, "Permission NOT granted: $permission")
+        return false
+    }
+
+    private class MyArrayAdapter(
+            private val ctx: Context,
+            resource: Int,
+            private val classes: Array<Class<*>>
+    ) : ArrayAdapter<Class<*>>(ctx, resource, classes) {
+        private var descriptionIds: IntArray? = null
+
+        override fun getView(position: Int, convertView: View?, parent: ViewGroup): View {
+            var view = convertView
+
+            if (convertView == null) {
+                val inflater = ctx.getSystemService(Context.LAYOUT_INFLATER_SERVICE) as LayoutInflater
+                view = inflater.inflate(android.R.layout.simple_list_item_2, null)
+            }
+
+            (view!!.findViewById<View>(android.R.id.text1) as TextView).text =
+                    classes[position].simpleName
+            descriptionIds?.let {
+                (view.findViewById<View>(android.R.id.text2) as TextView).setText(it[position])
+            }
+
+            return view
+        }
+
+        fun setDescriptionIds(descriptionIds: IntArray) {
+            this.descriptionIds = descriptionIds
+        }
+    }
+
+    companion object {
+        private const val TAG = "ChooserActivity"
+        private const val PERMISSION_REQUESTS = 1
+        private val CLASSES = arrayOf<Class<*>>(
+                LivePreviewActivity::class.java,
+                StillImageActivity::class.java,
+                CameraXLivePreviewActivity::class.java
+        )
+        private val DESCRIPTION_IDS = intArrayOf(
+                R.string.desc_camera_source_activity,
+                R.string.desc_still_image_activity,
+                R.string.desc_camerax_live_preview_activity
+        )
+
+        private fun isPermissionGranted(context: Context, permission: String?): Boolean {
+            if (ContextCompat.checkSelfPermission(context, permission!!)
+                    == PackageManager.PERMISSION_GRANTED
+            ) {
+                Log.i(TAG, "Permission granted: $permission")
+                return true
+            }
+            Log.i(TAG, "Permission NOT granted: $permission")
+            return false
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/LivePreviewActivity.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/LivePreviewActivity.kt
index ee1021a..394d79d 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/LivePreviewActivity.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/LivePreviewActivity.kt
@@ -1,383 +1,383 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin
-
-import android.content.Context
-import android.content.Intent
-import android.content.pm.PackageManager
-import android.os.Bundle
-import android.util.Log
-import android.view.Menu
-import android.view.MenuItem
-import android.view.View
-import android.widget.AdapterView
-import android.widget.AdapterView.OnItemSelectedListener
-import android.widget.ArrayAdapter
-import android.widget.CompoundButton
-import android.widget.ImageView
-import android.widget.Spinner
-import android.widget.Toast
-import android.widget.ToggleButton
-import androidx.appcompat.app.AppCompatActivity
-import androidx.core.app.ActivityCompat
-import androidx.core.content.ContextCompat
-import com.google.android.gms.common.annotation.KeepName
-import com.google.mlkit.common.model.LocalModel
-import com.google.mlkit.vision.demo.CameraSource
-import com.google.mlkit.vision.demo.CameraSourcePreview
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.R
-import com.google.mlkit.vision.demo.kotlin.automl.AutoMLImageLabelerProcessor
-import com.google.mlkit.vision.demo.kotlin.barcodescanner.BarcodeScannerProcessor
-import com.google.mlkit.vision.demo.kotlin.facedetector.FaceDetectorProcessor
-import com.google.mlkit.vision.demo.kotlin.labeldetector.LabelDetectorProcessor
-import com.google.mlkit.vision.demo.kotlin.objectdetector.ObjectDetectorProcessor
-import com.google.mlkit.vision.demo.kotlin.textdetector.TextRecognitionProcessor
-import com.google.mlkit.vision.demo.preference.PreferenceUtils
-import com.google.mlkit.vision.demo.preference.SettingsActivity
-import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource
-import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions
-import com.google.mlkit.vision.label.defaults.ImageLabelerOptions
-import java.io.IOException
-import java.util.ArrayList
-
-/** Live preview demo for ML Kit APIs.  */
-@KeepName
-class LivePreviewActivity :
-        AppCompatActivity(),
-        ActivityCompat.OnRequestPermissionsResultCallback,
-        OnItemSelectedListener,
-        CompoundButton.OnCheckedChangeListener {
-
-    private var cameraSource: CameraSource? = null
-    private var preview: CameraSourcePreview? = null
-    private var graphicOverlay: GraphicOverlay? = null
-    private var selectedModel = OBJECT_DETECTION
-
-    override fun onCreate(savedInstanceState: Bundle?) {
-        super.onCreate(savedInstanceState)
-        Log.d(TAG, "onCreate")
-        setContentView(R.layout.activity_live_preview)
-
-        preview = findViewById(R.id.preview)
-        if (preview == null) {
-            Log.d(TAG, "Preview is null")
-        }
-
-        graphicOverlay = findViewById(R.id.graphic_overlay)
-        if (graphicOverlay == null) {
-            Log.d(TAG, "graphicOverlay is null")
-        }
-
-        val spinner = findViewById<Spinner>(R.id.spinner)
-        val options: MutableList<String> = ArrayList()
-        options.add(OBJECT_DETECTION)
-        options.add(OBJECT_DETECTION_CUSTOM)
-        options.add(FACE_DETECTION)
-        options.add(TEXT_RECOGNITION)
-        options.add(BARCODE_SCANNING)
-        options.add(IMAGE_LABELING)
-        options.add(IMAGE_LABELING_CUSTOM)
-        options.add(AUTOML_LABELING)
-
-        // Creating adapter for spinner
-        val dataAdapter =
-                ArrayAdapter(this, R.layout.spinner_style, options)
-
-        // Drop down layout style - list view with radio button
-        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item)
-        // attaching data adapter to spinner
-        spinner.adapter = dataAdapter
-        spinner.onItemSelectedListener = this
-
-        val facingSwitch = findViewById<ToggleButton>(R.id.facing_switch)
-        facingSwitch.setOnCheckedChangeListener(this)
-
-        val settingsButton = findViewById<ImageView>(R.id.settings_button)
-        settingsButton.setOnClickListener { v: View? ->
-            val intent = Intent(applicationContext, SettingsActivity::class.java)
-            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE, LaunchSource.LIVE_PREVIEW)
-            startActivity(intent)
-        }
-
-        if (allPermissionsGranted()) {
-            createCameraSource(selectedModel)
-        } else {
-            runtimePermissions
-        }
-    }
-
-    override fun onCreateOptionsMenu(menu: Menu): Boolean {
-        menuInflater.inflate(R.menu.live_preview_menu, menu)
-        return true
-    }
-
-    override fun onOptionsItemSelected(item: MenuItem): Boolean {
-        if (item.itemId == R.id.settings) {
-            val intent = Intent(this, SettingsActivity::class.java)
-            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE, LaunchSource.LIVE_PREVIEW)
-            startActivity(intent)
-            return true
-        }
-        return super.onOptionsItemSelected(item)
-    }
-
-    @Synchronized
-    override fun onItemSelected(
-            parent: AdapterView<*>?,
-            view: View?,
-            pos: Int,
-            id: Long
-    ) {
-        // An item was selected. You can retrieve the selected item using
-        // parent.getItemAtPosition(pos)
-        selectedModel = parent?.getItemAtPosition(pos).toString()
-        Log.d(TAG, "Selected model: $selectedModel")
-        preview?.stop()
-        if (allPermissionsGranted()) {
-            createCameraSource(selectedModel)
-            startCameraSource()
-        } else {
-            runtimePermissions
-        }
-    }
-
-    override fun onNothingSelected(parent: AdapterView<*>?) {
-        // Do nothing.
-    }
-
-    override fun onCheckedChanged(buttonView: CompoundButton, isChecked: Boolean) {
-        Log.d(TAG, "Set facing")
-        if (cameraSource != null) {
-            if (isChecked) {
-                cameraSource?.setFacing(CameraSource.CAMERA_FACING_FRONT)
-            } else {
-                cameraSource?.setFacing(CameraSource.CAMERA_FACING_BACK)
-            }
-        }
-        preview?.stop()
-        startCameraSource()
-    }
-
-    private fun createCameraSource(model: String) {
-        // If there's no existing cameraSource, create one.
-        if (cameraSource == null) {
-            cameraSource = CameraSource(this, graphicOverlay)
-        }
-        try {
-            when (model) {
-                OBJECT_DETECTION -> {
-                    Log.i(TAG, "Using Object Detector Processor")
-                    val objectDetectorOptions =
-                            PreferenceUtils.getObjectDetectorOptionsForLivePreview(this)
-                    cameraSource!!.setMachineLearningFrameProcessor(
-                            ObjectDetectorProcessor(this, objectDetectorOptions)
-                    )
-                }
-                OBJECT_DETECTION_CUSTOM -> {
-                    Log.i(
-                            TAG,
-                            "Using Custom Object Detector Processor"
-                    )
-                    val localModel = LocalModel.Builder()
-                            .setAssetFilePath("custom_models/bird_classifier.tflite")
-                            .build()
-                    val customObjectDetectorOptions =
-                            PreferenceUtils.getCustomObjectDetectorOptionsForLivePreview(this, localModel)
-                    cameraSource!!.setMachineLearningFrameProcessor(
-                            ObjectDetectorProcessor(this, customObjectDetectorOptions)
-                    )
-                }
-                TEXT_RECOGNITION -> {
-                    Log.i(
-                            TAG,
-                            "Using on-device Text recognition Processor"
-                    )
-                    cameraSource!!.setMachineLearningFrameProcessor(TextRecognitionProcessor(this))
-                }
-                FACE_DETECTION -> {
-                    Log.i(TAG, "Using Face Detector Processor")
-                    val faceDetectorOptions =
-                            PreferenceUtils.getFaceDetectorOptionsForLivePreview(this)
-                    cameraSource!!.setMachineLearningFrameProcessor(
-                            FaceDetectorProcessor(this, faceDetectorOptions)
-                    )
-                }
-                BARCODE_SCANNING -> {
-                    Log.i(TAG, "Using Barcode Detector Processor")
-                    cameraSource!!.setMachineLearningFrameProcessor(
-                            BarcodeScannerProcessor(this)
-                    )
-                }
-                IMAGE_LABELING -> {
-                    Log.i(
-                            TAG,
-                            "Using Image Label Detector Processor"
-                    )
-                    cameraSource!!.setMachineLearningFrameProcessor(
-                            LabelDetectorProcessor(this, ImageLabelerOptions.DEFAULT_OPTIONS)
-                    )
-                }
-                IMAGE_LABELING_CUSTOM -> {
-                    Log.i(
-                            TAG,
-                            "Using Custom Image Label Detector Processor"
-                    )
-                    val localClassifier = LocalModel.Builder()
-                            .setAssetFilePath("custom_models/bird_classifier.tflite")
-                            .build()
-                    val customImageLabelerOptions =
-                            CustomImageLabelerOptions.Builder(localClassifier).build()
-                    cameraSource!!.setMachineLearningFrameProcessor(
-                            LabelDetectorProcessor(this, customImageLabelerOptions)
-                    )
-                }
-                AUTOML_LABELING -> cameraSource!!.setMachineLearningFrameProcessor(
-                        AutoMLImageLabelerProcessor(this)
-                )
-                else -> Log.e(TAG, "Unknown model: $model")
-            }
-        } catch (e: Exception) {
-            Log.e(TAG, "Can not create image processor: $model", e)
-            Toast.makeText(
-                    applicationContext, "Can not create image processor: " + e.message,
-                    Toast.LENGTH_LONG
-            ).show()
-        }
-    }
-
-    /**
-     * Starts or restarts the camera source, if it exists. If the camera source doesn't exist yet
-     * (e.g., because onResume was called before the camera source was created), this will be called
-     * again when the camera source is created.
-     */
-    private fun startCameraSource() {
-        if (cameraSource != null) {
-            try {
-                if (preview == null) {
-                    Log.d(TAG, "resume: Preview is null")
-                }
-                if (graphicOverlay == null) {
-                    Log.d(TAG, "resume: graphOverlay is null")
-                }
-                preview!!.start(cameraSource, graphicOverlay)
-            } catch (e: IOException) {
-                Log.e(TAG, "Unable to start camera source.", e)
-                cameraSource!!.release()
-                cameraSource = null
-            }
-        }
-    }
-
-    public override fun onResume() {
-        super.onResume()
-        Log.d(TAG, "onResume")
-        createCameraSource(selectedModel)
-        startCameraSource()
-    }
-
-    /** Stops the camera.  */
-    override fun onPause() {
-        super.onPause()
-        preview?.stop()
-    }
-
-    public override fun onDestroy() {
-        super.onDestroy()
-        if (cameraSource != null) {
-            cameraSource?.release()
-        }
-    }
-
-    private val requiredPermissions: Array<String?>
-        get() = try {
-            val info = this.packageManager
-                    .getPackageInfo(this.packageName, PackageManager.GET_PERMISSIONS)
-            val ps = info.requestedPermissions
-            if (ps != null && ps.size > 0) {
-                ps
-            } else {
-                arrayOfNulls(0)
-            }
-        } catch (e: Exception) {
-            arrayOfNulls(0)
-        }
-
-    private fun allPermissionsGranted(): Boolean {
-        for (permission in requiredPermissions) {
-            if (!isPermissionGranted(this, permission)) {
-                return false
-            }
-        }
-        return true
-    }
-
-    private val runtimePermissions: Unit
-        get() {
-            val allNeededPermissions: MutableList<String?> = ArrayList()
-            for (permission in requiredPermissions) {
-                if (!isPermissionGranted(this, permission)) {
-                    allNeededPermissions.add(permission)
-                }
-            }
-            if (!allNeededPermissions.isEmpty()) {
-                ActivityCompat.requestPermissions(
-                        this,
-                        allNeededPermissions.toTypedArray(),
-                        PERMISSION_REQUESTS
-                )
-            }
-        }
-
-    override fun onRequestPermissionsResult(
-            requestCode: Int,
-            permissions: Array<String>,
-            grantResults: IntArray
-    ) {
-        Log.i(TAG, "Permission granted!")
-        if (allPermissionsGranted()) {
-            createCameraSource(selectedModel)
-        }
-        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
-    }
-
-    companion object {
-        private const val OBJECT_DETECTION = "Object Detection"
-        private const val OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Birds)"
-        private const val FACE_DETECTION = "Face Detection"
-        private const val TEXT_RECOGNITION = "Text Recognition"
-        private const val BARCODE_SCANNING = "Barcode Scanning"
-        private const val IMAGE_LABELING = "Image Labeling"
-        private const val IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Birds)"
-        private const val AUTOML_LABELING = "AutoML Image Labeling"
-        private const val TAG = "LivePreviewActivity"
-        private const val PERMISSION_REQUESTS = 1
-        private fun isPermissionGranted(
-                context: Context,
-                permission: String?
-        ): Boolean {
-            if (ContextCompat.checkSelfPermission(context, permission!!)
-                    == PackageManager.PERMISSION_GRANTED
-            ) {
-                Log.i(TAG, "Permission granted: $permission")
-                return true
-            }
-            Log.i(TAG, "Permission NOT granted: $permission")
-            return false
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin
+
+import android.content.Context
+import android.content.Intent
+import android.content.pm.PackageManager
+import android.os.Bundle
+import android.util.Log
+import android.view.Menu
+import android.view.MenuItem
+import android.view.View
+import android.widget.AdapterView
+import android.widget.AdapterView.OnItemSelectedListener
+import android.widget.ArrayAdapter
+import android.widget.CompoundButton
+import android.widget.ImageView
+import android.widget.Spinner
+import android.widget.Toast
+import android.widget.ToggleButton
+import androidx.appcompat.app.AppCompatActivity
+import androidx.core.app.ActivityCompat
+import androidx.core.content.ContextCompat
+import com.google.android.gms.common.annotation.KeepName
+import com.google.mlkit.common.model.LocalModel
+import com.google.mlkit.vision.demo.CameraSource
+import com.google.mlkit.vision.demo.CameraSourcePreview
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.R
+import com.google.mlkit.vision.demo.kotlin.automl.AutoMLImageLabelerProcessor
+import com.google.mlkit.vision.demo.kotlin.barcodescanner.BarcodeScannerProcessor
+import com.google.mlkit.vision.demo.kotlin.facedetector.FaceDetectorProcessor
+import com.google.mlkit.vision.demo.kotlin.labeldetector.LabelDetectorProcessor
+import com.google.mlkit.vision.demo.kotlin.objectdetector.ObjectDetectorProcessor
+import com.google.mlkit.vision.demo.kotlin.textdetector.TextRecognitionProcessor
+import com.google.mlkit.vision.demo.preference.PreferenceUtils
+import com.google.mlkit.vision.demo.preference.SettingsActivity
+import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource
+import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions
+import com.google.mlkit.vision.label.defaults.ImageLabelerOptions
+import java.io.IOException
+import java.util.ArrayList
+
+/** Live preview demo for ML Kit APIs.  */
+@KeepName
+class LivePreviewActivity :
+        AppCompatActivity(),
+        ActivityCompat.OnRequestPermissionsResultCallback,
+        OnItemSelectedListener,
+        CompoundButton.OnCheckedChangeListener {
+
+    private var cameraSource: CameraSource? = null
+    private var preview: CameraSourcePreview? = null
+    private var graphicOverlay: GraphicOverlay? = null
+    private var selectedModel = OBJECT_DETECTION
+
+    override fun onCreate(savedInstanceState: Bundle?) {
+        super.onCreate(savedInstanceState)
+        Log.d(TAG, "onCreate")
+        setContentView(R.layout.activity_live_preview)
+
+        preview = findViewById(R.id.preview)
+        if (preview == null) {
+            Log.d(TAG, "Preview is null")
+        }
+
+        graphicOverlay = findViewById(R.id.graphic_overlay)
+        if (graphicOverlay == null) {
+            Log.d(TAG, "graphicOverlay is null")
+        }
+
+        val spinner = findViewById<Spinner>(R.id.spinner)
+        val options: MutableList<String> = ArrayList()
+        options.add(OBJECT_DETECTION)
+        options.add(OBJECT_DETECTION_CUSTOM)
+        options.add(FACE_DETECTION)
+        options.add(TEXT_RECOGNITION)
+        options.add(BARCODE_SCANNING)
+        options.add(IMAGE_LABELING)
+        options.add(IMAGE_LABELING_CUSTOM)
+        options.add(AUTOML_LABELING)
+
+        // Creating adapter for spinner
+        val dataAdapter =
+                ArrayAdapter(this, R.layout.spinner_style, options)
+
+        // Drop down layout style - list view with radio button
+        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item)
+        // attaching data adapter to spinner
+        spinner.adapter = dataAdapter
+        spinner.onItemSelectedListener = this
+
+        val facingSwitch = findViewById<ToggleButton>(R.id.facing_switch)
+        facingSwitch.setOnCheckedChangeListener(this)
+
+        val settingsButton = findViewById<ImageView>(R.id.settings_button)
+        settingsButton.setOnClickListener { v: View? ->
+            val intent = Intent(applicationContext, SettingsActivity::class.java)
+            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE, LaunchSource.LIVE_PREVIEW)
+            startActivity(intent)
+        }
+
+        if (allPermissionsGranted()) {
+            createCameraSource(selectedModel)
+        } else {
+            runtimePermissions
+        }
+    }
+
+    override fun onCreateOptionsMenu(menu: Menu): Boolean {
+        menuInflater.inflate(R.menu.live_preview_menu, menu)
+        return true
+    }
+
+    override fun onOptionsItemSelected(item: MenuItem): Boolean {
+        if (item.itemId == R.id.settings) {
+            val intent = Intent(this, SettingsActivity::class.java)
+            intent.putExtra(SettingsActivity.EXTRA_LAUNCH_SOURCE, LaunchSource.LIVE_PREVIEW)
+            startActivity(intent)
+            return true
+        }
+        return super.onOptionsItemSelected(item)
+    }
+
+    @Synchronized
+    override fun onItemSelected(
+            parent: AdapterView<*>?,
+            view: View?,
+            pos: Int,
+            id: Long
+    ) {
+        // An item was selected. You can retrieve the selected item using
+        // parent.getItemAtPosition(pos)
+        selectedModel = parent?.getItemAtPosition(pos).toString()
+        Log.d(TAG, "Selected model: $selectedModel")
+        preview?.stop()
+        if (allPermissionsGranted()) {
+            createCameraSource(selectedModel)
+            startCameraSource()
+        } else {
+            runtimePermissions
+        }
+    }
+
+    override fun onNothingSelected(parent: AdapterView<*>?) {
+        // Do nothing.
+    }
+
+    override fun onCheckedChanged(buttonView: CompoundButton, isChecked: Boolean) {
+        Log.d(TAG, "Set facing")
+        if (cameraSource != null) {
+            if (isChecked) {
+                cameraSource?.setFacing(CameraSource.CAMERA_FACING_FRONT)
+            } else {
+                cameraSource?.setFacing(CameraSource.CAMERA_FACING_BACK)
+            }
+        }
+        preview?.stop()
+        startCameraSource()
+    }
+
+    private fun createCameraSource(model: String) {
+        // If there's no existing cameraSource, create one.
+        if (cameraSource == null) {
+            cameraSource = CameraSource(this, graphicOverlay)
+        }
+        try {
+            when (model) {
+                OBJECT_DETECTION -> {
+                    Log.i(TAG, "Using Object Detector Processor")
+                    val objectDetectorOptions =
+                            PreferenceUtils.getObjectDetectorOptionsForLivePreview(this)
+                    cameraSource!!.setMachineLearningFrameProcessor(
+                            ObjectDetectorProcessor(this, objectDetectorOptions)
+                    )
+                }
+                OBJECT_DETECTION_CUSTOM -> {
+                    Log.i(
+                            TAG,
+                            "Using Custom Object Detector Processor"
+                    )
+                    val localModel = LocalModel.Builder()
+                            .setAssetFilePath("custom_models/bird_classifier.tflite")
+                            .build()
+                    val customObjectDetectorOptions =
+                            PreferenceUtils.getCustomObjectDetectorOptionsForLivePreview(this, localModel)
+                    cameraSource!!.setMachineLearningFrameProcessor(
+                            ObjectDetectorProcessor(this, customObjectDetectorOptions)
+                    )
+                }
+                TEXT_RECOGNITION -> {
+                    Log.i(
+                            TAG,
+                            "Using on-device Text recognition Processor"
+                    )
+                    cameraSource!!.setMachineLearningFrameProcessor(TextRecognitionProcessor(this))
+                }
+                FACE_DETECTION -> {
+                    Log.i(TAG, "Using Face Detector Processor")
+                    val faceDetectorOptions =
+                            PreferenceUtils.getFaceDetectorOptionsForLivePreview(this)
+                    cameraSource!!.setMachineLearningFrameProcessor(
+                            FaceDetectorProcessor(this, faceDetectorOptions)
+                    )
+                }
+                BARCODE_SCANNING -> {
+                    Log.i(TAG, "Using Barcode Detector Processor")
+                    cameraSource!!.setMachineLearningFrameProcessor(
+                            BarcodeScannerProcessor(this)
+                    )
+                }
+                IMAGE_LABELING -> {
+                    Log.i(
+                            TAG,
+                            "Using Image Label Detector Processor"
+                    )
+                    cameraSource!!.setMachineLearningFrameProcessor(
+                            LabelDetectorProcessor(this, ImageLabelerOptions.DEFAULT_OPTIONS)
+                    )
+                }
+                IMAGE_LABELING_CUSTOM -> {
+                    Log.i(
+                            TAG,
+                            "Using Custom Image Label Detector Processor"
+                    )
+                    val localClassifier = LocalModel.Builder()
+                            .setAssetFilePath("custom_models/bird_classifier.tflite")
+                            .build()
+                    val customImageLabelerOptions =
+                            CustomImageLabelerOptions.Builder(localClassifier).build()
+                    cameraSource!!.setMachineLearningFrameProcessor(
+                            LabelDetectorProcessor(this, customImageLabelerOptions)
+                    )
+                }
+                AUTOML_LABELING -> cameraSource!!.setMachineLearningFrameProcessor(
+                        AutoMLImageLabelerProcessor(this)
+                )
+                else -> Log.e(TAG, "Unknown model: $model")
+            }
+        } catch (e: Exception) {
+            Log.e(TAG, "Can not create image processor: $model", e)
+            Toast.makeText(
+                    applicationContext, "Can not create image processor: " + e.message,
+                    Toast.LENGTH_LONG
+            ).show()
+        }
+    }
+
+    /**
+     * Starts or restarts the camera source, if it exists. If the camera source doesn't exist yet
+     * (e.g., because onResume was called before the camera source was created), this will be called
+     * again when the camera source is created.
+     */
+    private fun startCameraSource() {
+        if (cameraSource != null) {
+            try {
+                if (preview == null) {
+                    Log.d(TAG, "resume: Preview is null")
+                }
+                if (graphicOverlay == null) {
+                    Log.d(TAG, "resume: graphOverlay is null")
+                }
+                preview!!.start(cameraSource, graphicOverlay)
+            } catch (e: IOException) {
+                Log.e(TAG, "Unable to start camera source.", e)
+                cameraSource!!.release()
+                cameraSource = null
+            }
+        }
+    }
+
+    public override fun onResume() {
+        super.onResume()
+        Log.d(TAG, "onResume")
+        createCameraSource(selectedModel)
+        startCameraSource()
+    }
+
+    /** Stops the camera.  */
+    override fun onPause() {
+        super.onPause()
+        preview?.stop()
+    }
+
+    public override fun onDestroy() {
+        super.onDestroy()
+        if (cameraSource != null) {
+            cameraSource?.release()
+        }
+    }
+
+    private val requiredPermissions: Array<String?>
+        get() = try {
+            val info = this.packageManager
+                    .getPackageInfo(this.packageName, PackageManager.GET_PERMISSIONS)
+            val ps = info.requestedPermissions
+            if (ps != null && ps.size > 0) {
+                ps
+            } else {
+                arrayOfNulls(0)
+            }
+        } catch (e: Exception) {
+            arrayOfNulls(0)
+        }
+
+    private fun allPermissionsGranted(): Boolean {
+        for (permission in requiredPermissions) {
+            if (!isPermissionGranted(this, permission)) {
+                return false
+            }
+        }
+        return true
+    }
+
+    private val runtimePermissions: Unit
+        get() {
+            val allNeededPermissions: MutableList<String?> = ArrayList()
+            for (permission in requiredPermissions) {
+                if (!isPermissionGranted(this, permission)) {
+                    allNeededPermissions.add(permission)
+                }
+            }
+            if (!allNeededPermissions.isEmpty()) {
+                ActivityCompat.requestPermissions(
+                        this,
+                        allNeededPermissions.toTypedArray(),
+                        PERMISSION_REQUESTS
+                )
+            }
+        }
+
+    override fun onRequestPermissionsResult(
+            requestCode: Int,
+            permissions: Array<String>,
+            grantResults: IntArray
+    ) {
+        Log.i(TAG, "Permission granted!")
+        if (allPermissionsGranted()) {
+            createCameraSource(selectedModel)
+        }
+        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
+    }
+
+    companion object {
+        private const val OBJECT_DETECTION = "Object Detection"
+        private const val OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Birds)"
+        private const val FACE_DETECTION = "Face Detection"
+        private const val TEXT_RECOGNITION = "Text Recognition"
+        private const val BARCODE_SCANNING = "Barcode Scanning"
+        private const val IMAGE_LABELING = "Image Labeling"
+        private const val IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Birds)"
+        private const val AUTOML_LABELING = "AutoML Image Labeling"
+        private const val TAG = "LivePreviewActivity"
+        private const val PERMISSION_REQUESTS = 1
+        private fun isPermissionGranted(
+                context: Context,
+                permission: String?
+        ): Boolean {
+            if (ContextCompat.checkSelfPermission(context, permission!!)
+                    == PackageManager.PERMISSION_GRANTED
+            ) {
+                Log.i(TAG, "Permission granted: $permission")
+                return true
+            }
+            Log.i(TAG, "Permission NOT granted: $permission")
+            return false
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/StillImageActivity.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/StillImageActivity.kt
index 30e511c..ef793e9 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/StillImageActivity.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/StillImageActivity.kt
@@ -1,485 +1,485 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin
-
-import android.app.Activity
-import android.content.ContentValues
-import android.content.Intent
-import android.content.res.Configuration
-import android.graphics.Bitmap
-import android.net.Uri
-import android.os.Bundle
-import android.provider.MediaStore
-import android.util.Log
-import android.util.Pair
-import android.view.Menu
-import android.view.MenuItem
-import android.view.View
-import android.view.ViewTreeObserver
-import android.widget.AdapterView
-import android.widget.AdapterView.OnItemSelectedListener
-import android.widget.ArrayAdapter
-import android.widget.ImageView
-import android.widget.PopupMenu
-import android.widget.Spinner
-import android.widget.Toast
-import androidx.appcompat.app.AppCompatActivity
-import com.google.android.gms.common.annotation.KeepName
-import com.google.mlkit.common.model.LocalModel
-import com.google.mlkit.vision.demo.BitmapUtils
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.R
-import com.google.mlkit.vision.demo.VisionImageProcessor
-import com.google.mlkit.vision.demo.kotlin.automl.AutoMLImageLabelerProcessor
-import com.google.mlkit.vision.demo.kotlin.barcodescanner.BarcodeScannerProcessor
-import com.google.mlkit.vision.demo.kotlin.facedetector.FaceDetectorProcessor
-import com.google.mlkit.vision.demo.kotlin.labeldetector.LabelDetectorProcessor
-import com.google.mlkit.vision.demo.kotlin.objectdetector.ObjectDetectorProcessor
-import com.google.mlkit.vision.demo.kotlin.textdetector.TextRecognitionProcessor
-import com.google.mlkit.vision.demo.preference.PreferenceUtils
-import com.google.mlkit.vision.demo.preference.SettingsActivity
-import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource
-import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions
-import com.google.mlkit.vision.label.defaults.ImageLabelerOptions
-import java.io.IOException
-import java.util.ArrayList
-import kotlin.math.max
-
-/** Activity demonstrating different image detector features with a still image from camera.  */
-@KeepName
-class StillImageActivity : AppCompatActivity() {
-    private var preview: ImageView? = null
-    private var graphicOverlay: GraphicOverlay? = null
-    private var selectedMode =
-            OBJECT_DETECTION
-    private var selectedSize: String? =
-            SIZE_SCREEN
-    private var isLandScape = false
-    private var imageUri: Uri? = null
-    // Max width (portrait mode)
-    private var imageMaxWidth = 0
-    // Max height (portrait mode)
-    private var imageMaxHeight = 0
-    private var imageProcessor: VisionImageProcessor? = null
-    override fun onCreate(savedInstanceState: Bundle?) {
-        super.onCreate(savedInstanceState)
-        setContentView(R.layout.activity_still_image)
-        findViewById<View>(R.id.select_image_button)
-                .setOnClickListener { view: View? ->
-                    // Menu for selecting either: a) take new photo b) select from existing
-                    val popup =
-                            PopupMenu(this@StillImageActivity, view)
-                    popup.setOnMenuItemClickListener { menuItem: MenuItem ->
-                        val itemId =
-                                menuItem.itemId
-                        if (itemId == R.id.select_images_from_local) {
-                            startChooseImageIntentForResult()
-                            return@setOnMenuItemClickListener true
-                        } else if (itemId == R.id.take_photo_using_camera) {
-                            startCameraIntentForResult()
-                            return@setOnMenuItemClickListener true
-                        }
-                        false
-                    }
-                    val inflater = popup.menuInflater
-                    inflater.inflate(R.menu.camera_button_menu, popup.menu)
-                    popup.show()
-                }
-        preview = findViewById(R.id.preview)
-        graphicOverlay = findViewById(R.id.graphic_overlay)
-
-        populateFeatureSelector()
-        populateSizeSelector()
-        isLandScape =
-                resources.configuration.orientation == Configuration.ORIENTATION_LANDSCAPE
-        if (savedInstanceState != null) {
-            imageUri =
-                    savedInstanceState.getParcelable(KEY_IMAGE_URI)
-            imageMaxWidth =
-                    savedInstanceState.getInt(KEY_IMAGE_MAX_WIDTH)
-            imageMaxHeight =
-                    savedInstanceState.getInt(KEY_IMAGE_MAX_HEIGHT)
-            selectedSize =
-                    savedInstanceState.getString(KEY_SELECTED_SIZE)
-        }
-
-        val rootView = findViewById<View>(R.id.root)
-        rootView.viewTreeObserver.addOnGlobalLayoutListener(
-                object : ViewTreeObserver.OnGlobalLayoutListener {
-                        override fun onGlobalLayout() {
-                            rootView.viewTreeObserver.removeOnGlobalLayoutListener(this)
-                            imageMaxWidth = rootView.width
-                            imageMaxHeight =
-                              rootView.height - findViewById<View>(R.id.control).height
-                            if (SIZE_SCREEN == selectedSize) {
-                                tryReloadAndDetectInImage()
-                            }
-                        }
-                })
-
-        val settingsButton = findViewById<ImageView>(R.id.settings_button)
-        settingsButton.setOnClickListener { v: View? ->
-            val intent =
-                    Intent(
-                            applicationContext,
-                            SettingsActivity::class.java
-                    )
-            intent.putExtra(
-                    SettingsActivity.EXTRA_LAUNCH_SOURCE,
-                    LaunchSource.STILL_IMAGE
-            )
-            startActivity(intent)
-        }
-    }
-
-    public override fun onResume() {
-        super.onResume()
-        Log.d(TAG, "onResume")
-        createImageProcessor()
-        tryReloadAndDetectInImage()
-    }
-
-    override fun onCreateOptionsMenu(menu: Menu): Boolean {
-        menuInflater.inflate(R.menu.still_image_menu, menu)
-        return true
-    }
-
-    override fun onOptionsItemSelected(item: MenuItem): Boolean {
-        if (item.itemId == R.id.settings) {
-            val intent = Intent(this, SettingsActivity::class.java)
-            intent.putExtra(
-                    SettingsActivity.EXTRA_LAUNCH_SOURCE,
-                    LaunchSource.STILL_IMAGE
-            )
-            startActivity(intent)
-            return true
-        }
-        return super.onOptionsItemSelected(item)
-    }
-
-    private fun populateFeatureSelector() {
-        val featureSpinner = findViewById<Spinner>(R.id.feature_selector)
-        val options: MutableList<String> = ArrayList()
-        options.add(OBJECT_DETECTION)
-        options.add(OBJECT_DETECTION_CUSTOM)
-        options.add(FACE_DETECTION)
-        options.add(BARCODE_SCANNING)
-        options.add(TEXT_RECOGNITION)
-        options.add(IMAGE_LABELING)
-        options.add(IMAGE_LABELING_CUSTOM)
-        options.add(AUTOML_LABELING)
-        // Creating adapter for featureSpinner
-        val dataAdapter =
-                ArrayAdapter(this, R.layout.spinner_style, options)
-        // Drop down layout style - list view with radio button
-        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item)
-        // attaching data adapter to spinner
-        featureSpinner.adapter = dataAdapter
-        featureSpinner.onItemSelectedListener = object : OnItemSelectedListener {
-            override fun onItemSelected(
-                    parentView: AdapterView<*>,
-                    selectedItemView: View?,
-                    pos: Int,
-                    id: Long
-            ) {
-                if (pos >= 0) {
-                    selectedMode = parentView.getItemAtPosition(pos).toString()
-                    createImageProcessor()
-                    tryReloadAndDetectInImage()
-                }
-            }
-
-            override fun onNothingSelected(arg0: AdapterView<*>?) {}
-        }
-    }
-
-    private fun populateSizeSelector() {
-        val sizeSpinner = findViewById<Spinner>(R.id.size_selector)
-        val options: MutableList<String> = ArrayList()
-        options.add(SIZE_SCREEN)
-        options.add(SIZE_1024_768)
-        options.add(SIZE_640_480)
-        // Creating adapter for featureSpinner
-        val dataAdapter =
-                ArrayAdapter(this, R.layout.spinner_style, options)
-        // Drop down layout style - list view with radio button
-        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item)
-        // attaching data adapter to spinner
-        sizeSpinner.adapter = dataAdapter
-        sizeSpinner.onItemSelectedListener = object : OnItemSelectedListener {
-            override fun onItemSelected(
-                    parentView: AdapterView<*>,
-                    selectedItemView: View?,
-                    pos: Int,
-                    id: Long
-            ) {
-                if (pos >= 0) {
-                    selectedSize = parentView.getItemAtPosition(pos).toString()
-                    createImageProcessor()
-                    tryReloadAndDetectInImage()
-                }
-            }
-
-            override fun onNothingSelected(arg0: AdapterView<*>?) {}
-        }
-    }
-
-    public override fun onSaveInstanceState(outState: Bundle) {
-        super.onSaveInstanceState(outState)
-        outState.putParcelable(
-                KEY_IMAGE_URI,
-                imageUri
-        )
-        outState.putInt(
-                KEY_IMAGE_MAX_WIDTH,
-                imageMaxWidth
-        )
-        outState.putInt(
-                KEY_IMAGE_MAX_HEIGHT,
-                imageMaxHeight
-        )
-        outState.putString(
-                KEY_SELECTED_SIZE,
-                selectedSize
-        )
-    }
-
-    private fun startCameraIntentForResult() { // Clean up last time's image
-        imageUri = null
-        preview!!.setImageBitmap(null)
-        val takePictureIntent = Intent(MediaStore.ACTION_IMAGE_CAPTURE)
-        if (takePictureIntent.resolveActivity(packageManager) != null) {
-            val values = ContentValues()
-            values.put(MediaStore.Images.Media.TITLE, "New Picture")
-            values.put(MediaStore.Images.Media.DESCRIPTION, "From Camera")
-            imageUri = contentResolver.insert(MediaStore.Images.Media.EXTERNAL_CONTENT_URI, values)
-            takePictureIntent.putExtra(MediaStore.EXTRA_OUTPUT, imageUri)
-            startActivityForResult(
-                    takePictureIntent,
-                    REQUEST_IMAGE_CAPTURE
-            )
-        }
-    }
-
-    private fun startChooseImageIntentForResult() {
-        val intent = Intent()
-        intent.type = "image/*"
-        intent.action = Intent.ACTION_GET_CONTENT
-        startActivityForResult(
-                Intent.createChooser(intent, "Select Picture"),
-                REQUEST_CHOOSE_IMAGE
-        )
-    }
-
-    override fun onActivityResult(
-            requestCode: Int,
-            resultCode: Int,
-            data: Intent?
-    ) {
-        if (requestCode == REQUEST_IMAGE_CAPTURE && resultCode == Activity.RESULT_OK) {
-            tryReloadAndDetectInImage()
-        } else if (requestCode == REQUEST_CHOOSE_IMAGE && resultCode == Activity.RESULT_OK) {
-            // In this case, imageUri is returned by the chooser, save it.
-            imageUri = data!!.data
-            tryReloadAndDetectInImage()
-        } else {
-            super.onActivityResult(requestCode, resultCode, data)
-        }
-    }
-
-    private fun tryReloadAndDetectInImage() {
-        Log.d(
-                TAG,
-                "Try reload and detect image"
-        )
-        try {
-            if (imageUri == null) {
-                return
-            }
-
-            if (SIZE_SCREEN == selectedSize && imageMaxWidth == 0) {
-                // UI layout has not finished yet, will reload once it's ready.
-                return
-            }
-
-            val imageBitmap = BitmapUtils.getBitmapFromContentUri(contentResolver, imageUri)
-                ?: return
-            // Clear the overlay first
-            graphicOverlay!!.clear()
-            // Get the dimensions of the image view
-            val targetedSize = targetedWidthHeight
-            // Determine how much to scale down the image
-            val scaleFactor = max(
-                    imageBitmap.width.toFloat() / targetedSize.first.toFloat(),
-                    imageBitmap.height.toFloat() / targetedSize.second.toFloat()
-            )
-            val resizedBitmap = Bitmap.createScaledBitmap(
-                    imageBitmap,
-                    (imageBitmap.width / scaleFactor).toInt(),
-                    (imageBitmap.height / scaleFactor).toInt(),
-                    true
-            )
-            preview!!.setImageBitmap(resizedBitmap)
-            if (imageProcessor != null) {
-                graphicOverlay!!.setImageSourceInfo(
-                        resizedBitmap.width, resizedBitmap.height, /* isFlipped= */false
-                )
-                imageProcessor!!.processBitmap(resizedBitmap, graphicOverlay)
-            } else {
-                Log.e(
-                        TAG,
-                        "Null imageProcessor, please check adb logs for imageProcessor creation error"
-                )
-            }
-        } catch (e: IOException) {
-            Log.e(
-                    TAG,
-                    "Error retrieving saved image"
-            )
-            imageUri = null
-        }
-    }
-
-    private val targetedWidthHeight: Pair<Int, Int>
-        get() {
-            val targetWidth: Int
-            val targetHeight: Int
-            when (selectedSize) {
-                SIZE_SCREEN -> {
-                    targetWidth = imageMaxWidth
-                    targetHeight = imageMaxHeight
-                }
-                SIZE_640_480 -> {
-                    targetWidth = if (isLandScape) 640 else 480
-                    targetHeight = if (isLandScape) 480 else 640
-                }
-                SIZE_1024_768 -> {
-                    targetWidth = if (isLandScape) 1024 else 768
-                    targetHeight = if (isLandScape) 768 else 1024
-                }
-                else -> throw IllegalStateException("Unknown size")
-            }
-            return Pair(targetWidth, targetHeight)
-        }
-
-    private fun createImageProcessor() {
-        try {
-            when (selectedMode) {
-                OBJECT_DETECTION -> {
-                    Log.i(
-                            TAG,
-                            "Using Object Detector Processor"
-                    )
-                    val objectDetectorOptions =
-                            PreferenceUtils.getObjectDetectorOptionsForStillImage(this)
-                    imageProcessor =
-                            ObjectDetectorProcessor(
-                                    this,
-                                    objectDetectorOptions
-                            )
-                }
-                OBJECT_DETECTION_CUSTOM -> {
-                    Log.i(
-                            TAG,
-                            "Using Custom Object Detector Processor"
-                    )
-                    val localModel = LocalModel.Builder()
-                            .setAssetFilePath("custom_models/bird_classifier.tflite")
-                            .build()
-                    val customObjectDetectorOptions =
-                            PreferenceUtils.getCustomObjectDetectorOptionsForStillImage(this, localModel)
-                    imageProcessor =
-                            ObjectDetectorProcessor(
-                                    this,
-                                    customObjectDetectorOptions
-                            )
-                }
-                FACE_DETECTION ->
-                    imageProcessor =
-                            FaceDetectorProcessor(this, null)
-                BARCODE_SCANNING ->
-                    imageProcessor =
-                            BarcodeScannerProcessor(this)
-                TEXT_RECOGNITION ->
-                    imageProcessor =
-                            TextRecognitionProcessor(this)
-                IMAGE_LABELING ->
-                    imageProcessor =
-                            LabelDetectorProcessor(
-                                    this,
-                                    ImageLabelerOptions.DEFAULT_OPTIONS
-                            )
-                IMAGE_LABELING_CUSTOM -> {
-                    Log.i(
-                            TAG,
-                            "Using Custom Image Label Detector Processor"
-                    )
-                    val localClassifier = LocalModel.Builder()
-                            .setAssetFilePath("custom_models/bird_classifier.tflite")
-                            .build()
-                    val customImageLabelerOptions =
-                            CustomImageLabelerOptions.Builder(localClassifier).build()
-                    imageProcessor =
-                            LabelDetectorProcessor(
-                                    this,
-                                    customImageLabelerOptions
-                            )
-                }
-                AUTOML_LABELING ->
-                    imageProcessor =
-                            AutoMLImageLabelerProcessor(this)
-                else -> Log.e(
-                        TAG,
-                        "Unknown selectedMode: $selectedMode"
-                )
-            }
-        } catch (e: Exception) {
-            Log.e(
-                    TAG,
-                    "Can not create image processor: $selectedMode",
-                    e
-            )
-            Toast.makeText(
-                    applicationContext,
-                    "Can not create image processor: " + e.message,
-                    Toast.LENGTH_LONG
-            )
-                    .show()
-        }
-    }
-
-    companion object {
-        private const val TAG = "StillImageActivity"
-        private const val OBJECT_DETECTION = "Object Detection"
-        private const val OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Birds)"
-        private const val FACE_DETECTION = "Face Detection"
-        private const val BARCODE_SCANNING = "Barcode Scanning"
-        private const val TEXT_RECOGNITION = "Text Recognition"
-        private const val IMAGE_LABELING = "Image Labeling"
-        private const val IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Birds)"
-        private const val AUTOML_LABELING = "AutoML Labeling"
-        private const val SIZE_SCREEN = "w:screen" // Match screen width
-        private const val SIZE_1024_768 = "w:1024" // ~1024*768 in a normal ratio
-        private const val SIZE_640_480 = "w:640" // ~640*480 in a normal ratio
-        private const val KEY_IMAGE_URI = "com.google.mlkit.vision.demo.KEY_IMAGE_URI"
-        private const val KEY_IMAGE_MAX_WIDTH = "com.google.mlkit.vision.demo.KEY_IMAGE_MAX_WIDTH"
-        private const val KEY_IMAGE_MAX_HEIGHT = "com.google.mlkit.vision.demo.KEY_IMAGE_MAX_HEIGHT"
-        private const val KEY_SELECTED_SIZE = "com.google.mlkit.vision.demo.KEY_SELECTED_SIZE"
-        private const val REQUEST_IMAGE_CAPTURE = 1001
-        private const val REQUEST_CHOOSE_IMAGE = 1002
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin
+
+import android.app.Activity
+import android.content.ContentValues
+import android.content.Intent
+import android.content.res.Configuration
+import android.graphics.Bitmap
+import android.net.Uri
+import android.os.Bundle
+import android.provider.MediaStore
+import android.util.Log
+import android.util.Pair
+import android.view.Menu
+import android.view.MenuItem
+import android.view.View
+import android.view.ViewTreeObserver
+import android.widget.AdapterView
+import android.widget.AdapterView.OnItemSelectedListener
+import android.widget.ArrayAdapter
+import android.widget.ImageView
+import android.widget.PopupMenu
+import android.widget.Spinner
+import android.widget.Toast
+import androidx.appcompat.app.AppCompatActivity
+import com.google.android.gms.common.annotation.KeepName
+import com.google.mlkit.common.model.LocalModel
+import com.google.mlkit.vision.demo.BitmapUtils
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.R
+import com.google.mlkit.vision.demo.VisionImageProcessor
+import com.google.mlkit.vision.demo.kotlin.automl.AutoMLImageLabelerProcessor
+import com.google.mlkit.vision.demo.kotlin.barcodescanner.BarcodeScannerProcessor
+import com.google.mlkit.vision.demo.kotlin.facedetector.FaceDetectorProcessor
+import com.google.mlkit.vision.demo.kotlin.labeldetector.LabelDetectorProcessor
+import com.google.mlkit.vision.demo.kotlin.objectdetector.ObjectDetectorProcessor
+import com.google.mlkit.vision.demo.kotlin.textdetector.TextRecognitionProcessor
+import com.google.mlkit.vision.demo.preference.PreferenceUtils
+import com.google.mlkit.vision.demo.preference.SettingsActivity
+import com.google.mlkit.vision.demo.preference.SettingsActivity.LaunchSource
+import com.google.mlkit.vision.label.custom.CustomImageLabelerOptions
+import com.google.mlkit.vision.label.defaults.ImageLabelerOptions
+import java.io.IOException
+import java.util.ArrayList
+import kotlin.math.max
+
+/** Activity demonstrating different image detector features with a still image from camera.  */
+@KeepName
+class StillImageActivity : AppCompatActivity() {
+    private var preview: ImageView? = null
+    private var graphicOverlay: GraphicOverlay? = null
+    private var selectedMode =
+            OBJECT_DETECTION
+    private var selectedSize: String? =
+            SIZE_SCREEN
+    private var isLandScape = false
+    private var imageUri: Uri? = null
+    // Max width (portrait mode)
+    private var imageMaxWidth = 0
+    // Max height (portrait mode)
+    private var imageMaxHeight = 0
+    private var imageProcessor: VisionImageProcessor? = null
+    override fun onCreate(savedInstanceState: Bundle?) {
+        super.onCreate(savedInstanceState)
+        setContentView(R.layout.activity_still_image)
+        findViewById<View>(R.id.select_image_button)
+                .setOnClickListener { view: View? ->
+                    // Menu for selecting either: a) take new photo b) select from existing
+                    val popup =
+                            PopupMenu(this@StillImageActivity, view)
+                    popup.setOnMenuItemClickListener { menuItem: MenuItem ->
+                        val itemId =
+                                menuItem.itemId
+                        if (itemId == R.id.select_images_from_local) {
+                            startChooseImageIntentForResult()
+                            return@setOnMenuItemClickListener true
+                        } else if (itemId == R.id.take_photo_using_camera) {
+                            startCameraIntentForResult()
+                            return@setOnMenuItemClickListener true
+                        }
+                        false
+                    }
+                    val inflater = popup.menuInflater
+                    inflater.inflate(R.menu.camera_button_menu, popup.menu)
+                    popup.show()
+                }
+        preview = findViewById(R.id.preview)
+        graphicOverlay = findViewById(R.id.graphic_overlay)
+
+        populateFeatureSelector()
+        populateSizeSelector()
+        isLandScape =
+                resources.configuration.orientation == Configuration.ORIENTATION_LANDSCAPE
+        if (savedInstanceState != null) {
+            imageUri =
+                    savedInstanceState.getParcelable(KEY_IMAGE_URI)
+            imageMaxWidth =
+                    savedInstanceState.getInt(KEY_IMAGE_MAX_WIDTH)
+            imageMaxHeight =
+                    savedInstanceState.getInt(KEY_IMAGE_MAX_HEIGHT)
+            selectedSize =
+                    savedInstanceState.getString(KEY_SELECTED_SIZE)
+        }
+
+        val rootView = findViewById<View>(R.id.root)
+        rootView.viewTreeObserver.addOnGlobalLayoutListener(
+                object : ViewTreeObserver.OnGlobalLayoutListener {
+                        override fun onGlobalLayout() {
+                            rootView.viewTreeObserver.removeOnGlobalLayoutListener(this)
+                            imageMaxWidth = rootView.width
+                            imageMaxHeight =
+                              rootView.height - findViewById<View>(R.id.control).height
+                            if (SIZE_SCREEN == selectedSize) {
+                                tryReloadAndDetectInImage()
+                            }
+                        }
+                })
+
+        val settingsButton = findViewById<ImageView>(R.id.settings_button)
+        settingsButton.setOnClickListener { v: View? ->
+            val intent =
+                    Intent(
+                            applicationContext,
+                            SettingsActivity::class.java
+                    )
+            intent.putExtra(
+                    SettingsActivity.EXTRA_LAUNCH_SOURCE,
+                    LaunchSource.STILL_IMAGE
+            )
+            startActivity(intent)
+        }
+    }
+
+    public override fun onResume() {
+        super.onResume()
+        Log.d(TAG, "onResume")
+        createImageProcessor()
+        tryReloadAndDetectInImage()
+    }
+
+    override fun onCreateOptionsMenu(menu: Menu): Boolean {
+        menuInflater.inflate(R.menu.still_image_menu, menu)
+        return true
+    }
+
+    override fun onOptionsItemSelected(item: MenuItem): Boolean {
+        if (item.itemId == R.id.settings) {
+            val intent = Intent(this, SettingsActivity::class.java)
+            intent.putExtra(
+                    SettingsActivity.EXTRA_LAUNCH_SOURCE,
+                    LaunchSource.STILL_IMAGE
+            )
+            startActivity(intent)
+            return true
+        }
+        return super.onOptionsItemSelected(item)
+    }
+
+    private fun populateFeatureSelector() {
+        val featureSpinner = findViewById<Spinner>(R.id.feature_selector)
+        val options: MutableList<String> = ArrayList()
+        options.add(OBJECT_DETECTION)
+        options.add(OBJECT_DETECTION_CUSTOM)
+        options.add(FACE_DETECTION)
+        options.add(BARCODE_SCANNING)
+        options.add(TEXT_RECOGNITION)
+        options.add(IMAGE_LABELING)
+        options.add(IMAGE_LABELING_CUSTOM)
+        options.add(AUTOML_LABELING)
+        // Creating adapter for featureSpinner
+        val dataAdapter =
+                ArrayAdapter(this, R.layout.spinner_style, options)
+        // Drop down layout style - list view with radio button
+        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item)
+        // attaching data adapter to spinner
+        featureSpinner.adapter = dataAdapter
+        featureSpinner.onItemSelectedListener = object : OnItemSelectedListener {
+            override fun onItemSelected(
+                    parentView: AdapterView<*>,
+                    selectedItemView: View?,
+                    pos: Int,
+                    id: Long
+            ) {
+                if (pos >= 0) {
+                    selectedMode = parentView.getItemAtPosition(pos).toString()
+                    createImageProcessor()
+                    tryReloadAndDetectInImage()
+                }
+            }
+
+            override fun onNothingSelected(arg0: AdapterView<*>?) {}
+        }
+    }
+
+    private fun populateSizeSelector() {
+        val sizeSpinner = findViewById<Spinner>(R.id.size_selector)
+        val options: MutableList<String> = ArrayList()
+        options.add(SIZE_SCREEN)
+        options.add(SIZE_1024_768)
+        options.add(SIZE_640_480)
+        // Creating adapter for featureSpinner
+        val dataAdapter =
+                ArrayAdapter(this, R.layout.spinner_style, options)
+        // Drop down layout style - list view with radio button
+        dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item)
+        // attaching data adapter to spinner
+        sizeSpinner.adapter = dataAdapter
+        sizeSpinner.onItemSelectedListener = object : OnItemSelectedListener {
+            override fun onItemSelected(
+                    parentView: AdapterView<*>,
+                    selectedItemView: View?,
+                    pos: Int,
+                    id: Long
+            ) {
+                if (pos >= 0) {
+                    selectedSize = parentView.getItemAtPosition(pos).toString()
+                    createImageProcessor()
+                    tryReloadAndDetectInImage()
+                }
+            }
+
+            override fun onNothingSelected(arg0: AdapterView<*>?) {}
+        }
+    }
+
+    public override fun onSaveInstanceState(outState: Bundle) {
+        super.onSaveInstanceState(outState)
+        outState.putParcelable(
+                KEY_IMAGE_URI,
+                imageUri
+        )
+        outState.putInt(
+                KEY_IMAGE_MAX_WIDTH,
+                imageMaxWidth
+        )
+        outState.putInt(
+                KEY_IMAGE_MAX_HEIGHT,
+                imageMaxHeight
+        )
+        outState.putString(
+                KEY_SELECTED_SIZE,
+                selectedSize
+        )
+    }
+
+    private fun startCameraIntentForResult() { // Clean up last time's image
+        imageUri = null
+        preview!!.setImageBitmap(null)
+        val takePictureIntent = Intent(MediaStore.ACTION_IMAGE_CAPTURE)
+        if (takePictureIntent.resolveActivity(packageManager) != null) {
+            val values = ContentValues()
+            values.put(MediaStore.Images.Media.TITLE, "New Picture")
+            values.put(MediaStore.Images.Media.DESCRIPTION, "From Camera")
+            imageUri = contentResolver.insert(MediaStore.Images.Media.EXTERNAL_CONTENT_URI, values)
+            takePictureIntent.putExtra(MediaStore.EXTRA_OUTPUT, imageUri)
+            startActivityForResult(
+                    takePictureIntent,
+                    REQUEST_IMAGE_CAPTURE
+            )
+        }
+    }
+
+    private fun startChooseImageIntentForResult() {
+        val intent = Intent()
+        intent.type = "image/*"
+        intent.action = Intent.ACTION_GET_CONTENT
+        startActivityForResult(
+                Intent.createChooser(intent, "Select Picture"),
+                REQUEST_CHOOSE_IMAGE
+        )
+    }
+
+    override fun onActivityResult(
+            requestCode: Int,
+            resultCode: Int,
+            data: Intent?
+    ) {
+        if (requestCode == REQUEST_IMAGE_CAPTURE && resultCode == Activity.RESULT_OK) {
+            tryReloadAndDetectInImage()
+        } else if (requestCode == REQUEST_CHOOSE_IMAGE && resultCode == Activity.RESULT_OK) {
+            // In this case, imageUri is returned by the chooser, save it.
+            imageUri = data!!.data
+            tryReloadAndDetectInImage()
+        } else {
+            super.onActivityResult(requestCode, resultCode, data)
+        }
+    }
+
+    private fun tryReloadAndDetectInImage() {
+        Log.d(
+                TAG,
+                "Try reload and detect image"
+        )
+        try {
+            if (imageUri == null) {
+                return
+            }
+
+            if (SIZE_SCREEN == selectedSize && imageMaxWidth == 0) {
+                // UI layout has not finished yet, will reload once it's ready.
+                return
+            }
+
+            val imageBitmap = BitmapUtils.getBitmapFromContentUri(contentResolver, imageUri)
+                ?: return
+            // Clear the overlay first
+            graphicOverlay!!.clear()
+            // Get the dimensions of the image view
+            val targetedSize = targetedWidthHeight
+            // Determine how much to scale down the image
+            val scaleFactor = max(
+                    imageBitmap.width.toFloat() / targetedSize.first.toFloat(),
+                    imageBitmap.height.toFloat() / targetedSize.second.toFloat()
+            )
+            val resizedBitmap = Bitmap.createScaledBitmap(
+                    imageBitmap,
+                    (imageBitmap.width / scaleFactor).toInt(),
+                    (imageBitmap.height / scaleFactor).toInt(),
+                    true
+            )
+            preview!!.setImageBitmap(resizedBitmap)
+            if (imageProcessor != null) {
+                graphicOverlay!!.setImageSourceInfo(
+                        resizedBitmap.width, resizedBitmap.height, /* isFlipped= */false
+                )
+                imageProcessor!!.processBitmap(resizedBitmap, graphicOverlay)
+            } else {
+                Log.e(
+                        TAG,
+                        "Null imageProcessor, please check adb logs for imageProcessor creation error"
+                )
+            }
+        } catch (e: IOException) {
+            Log.e(
+                    TAG,
+                    "Error retrieving saved image"
+            )
+            imageUri = null
+        }
+    }
+
+    private val targetedWidthHeight: Pair<Int, Int>
+        get() {
+            val targetWidth: Int
+            val targetHeight: Int
+            when (selectedSize) {
+                SIZE_SCREEN -> {
+                    targetWidth = imageMaxWidth
+                    targetHeight = imageMaxHeight
+                }
+                SIZE_640_480 -> {
+                    targetWidth = if (isLandScape) 640 else 480
+                    targetHeight = if (isLandScape) 480 else 640
+                }
+                SIZE_1024_768 -> {
+                    targetWidth = if (isLandScape) 1024 else 768
+                    targetHeight = if (isLandScape) 768 else 1024
+                }
+                else -> throw IllegalStateException("Unknown size")
+            }
+            return Pair(targetWidth, targetHeight)
+        }
+
+    private fun createImageProcessor() {
+        try {
+            when (selectedMode) {
+                OBJECT_DETECTION -> {
+                    Log.i(
+                            TAG,
+                            "Using Object Detector Processor"
+                    )
+                    val objectDetectorOptions =
+                            PreferenceUtils.getObjectDetectorOptionsForStillImage(this)
+                    imageProcessor =
+                            ObjectDetectorProcessor(
+                                    this,
+                                    objectDetectorOptions
+                            )
+                }
+                OBJECT_DETECTION_CUSTOM -> {
+                    Log.i(
+                            TAG,
+                            "Using Custom Object Detector Processor"
+                    )
+                    val localModel = LocalModel.Builder()
+                            .setAssetFilePath("custom_models/bird_classifier.tflite")
+                            .build()
+                    val customObjectDetectorOptions =
+                            PreferenceUtils.getCustomObjectDetectorOptionsForStillImage(this, localModel)
+                    imageProcessor =
+                            ObjectDetectorProcessor(
+                                    this,
+                                    customObjectDetectorOptions
+                            )
+                }
+                FACE_DETECTION ->
+                    imageProcessor =
+                            FaceDetectorProcessor(this, null)
+                BARCODE_SCANNING ->
+                    imageProcessor =
+                            BarcodeScannerProcessor(this)
+                TEXT_RECOGNITION ->
+                    imageProcessor =
+                            TextRecognitionProcessor(this)
+                IMAGE_LABELING ->
+                    imageProcessor =
+                            LabelDetectorProcessor(
+                                    this,
+                                    ImageLabelerOptions.DEFAULT_OPTIONS
+                            )
+                IMAGE_LABELING_CUSTOM -> {
+                    Log.i(
+                            TAG,
+                            "Using Custom Image Label Detector Processor"
+                    )
+                    val localClassifier = LocalModel.Builder()
+                            .setAssetFilePath("custom_models/bird_classifier.tflite")
+                            .build()
+                    val customImageLabelerOptions =
+                            CustomImageLabelerOptions.Builder(localClassifier).build()
+                    imageProcessor =
+                            LabelDetectorProcessor(
+                                    this,
+                                    customImageLabelerOptions
+                            )
+                }
+                AUTOML_LABELING ->
+                    imageProcessor =
+                            AutoMLImageLabelerProcessor(this)
+                else -> Log.e(
+                        TAG,
+                        "Unknown selectedMode: $selectedMode"
+                )
+            }
+        } catch (e: Exception) {
+            Log.e(
+                    TAG,
+                    "Can not create image processor: $selectedMode",
+                    e
+            )
+            Toast.makeText(
+                    applicationContext,
+                    "Can not create image processor: " + e.message,
+                    Toast.LENGTH_LONG
+            )
+                    .show()
+        }
+    }
+
+    companion object {
+        private const val TAG = "StillImageActivity"
+        private const val OBJECT_DETECTION = "Object Detection"
+        private const val OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Birds)"
+        private const val FACE_DETECTION = "Face Detection"
+        private const val BARCODE_SCANNING = "Barcode Scanning"
+        private const val TEXT_RECOGNITION = "Text Recognition"
+        private const val IMAGE_LABELING = "Image Labeling"
+        private const val IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Birds)"
+        private const val AUTOML_LABELING = "AutoML Labeling"
+        private const val SIZE_SCREEN = "w:screen" // Match screen width
+        private const val SIZE_1024_768 = "w:1024" // ~1024*768 in a normal ratio
+        private const val SIZE_640_480 = "w:640" // ~640*480 in a normal ratio
+        private const val KEY_IMAGE_URI = "com.google.mlkit.vision.demo.KEY_IMAGE_URI"
+        private const val KEY_IMAGE_MAX_WIDTH = "com.google.mlkit.vision.demo.KEY_IMAGE_MAX_WIDTH"
+        private const val KEY_IMAGE_MAX_HEIGHT = "com.google.mlkit.vision.demo.KEY_IMAGE_MAX_HEIGHT"
+        private const val KEY_SELECTED_SIZE = "com.google.mlkit.vision.demo.KEY_SELECTED_SIZE"
+        private const val REQUEST_IMAGE_CAPTURE = 1001
+        private const val REQUEST_CHOOSE_IMAGE = 1002
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/TaskExt.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/TaskExt.kt
index 8db5ab9..a8c539c 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/TaskExt.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/TaskExt.kt
@@ -1,68 +1,68 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin
-
-import com.google.android.gms.tasks.OnCanceledListener
-import com.google.android.gms.tasks.OnCompleteListener
-import com.google.android.gms.tasks.OnFailureListener
-import com.google.android.gms.tasks.OnSuccessListener
-import com.google.android.gms.tasks.Task
-import java.util.concurrent.Executor
-
-/**
- * Quality-of-life helper to allow using trailing lambda syntax for adding a success listener to a
- * [Task].
- */
-fun <TResult> Task<TResult>.addOnSuccessListener(
-        executor: Executor,
-        listener: (TResult) -> Unit
-): Task<TResult> {
-    return addOnSuccessListener(executor, OnSuccessListener(listener))
-}
-
-/**
- * Quality-of-life helper to allow using trailing lambda syntax for adding a failure listener to a
- * [Task].
- */
-fun <TResult> Task<TResult>.addOnFailureListener(
-        executor: Executor,
-        listener: (Exception) -> Unit
-): Task<TResult> {
-    return addOnFailureListener(executor, OnFailureListener(listener))
-}
-
-/**
- * Quality-of-life helper to allow using trailing lambda syntax for adding a completion listener to
- * a [Task].
- */
-fun <TResult> Task<TResult>.addOnCompleteListener(
-        executor: Executor,
-        listener: (Task<TResult>) -> Unit
-): Task<TResult> {
-    return addOnCompleteListener(executor, OnCompleteListener(listener))
-}
-
-/**
- * Quality-of-life helper to allow using trailing lambda syntax for adding a cancellation listener
- * to a [Task].
- */
-fun <TResult> Task<TResult>.addOnCanceledListener(
-        executor: Executor,
-        listener: () -> Unit
-): Task<TResult> {
-    return addOnCanceledListener(executor, OnCanceledListener(listener))
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin
+
+import com.google.android.gms.tasks.OnCanceledListener
+import com.google.android.gms.tasks.OnCompleteListener
+import com.google.android.gms.tasks.OnFailureListener
+import com.google.android.gms.tasks.OnSuccessListener
+import com.google.android.gms.tasks.Task
+import java.util.concurrent.Executor
+
+/**
+ * Quality-of-life helper to allow using trailing lambda syntax for adding a success listener to a
+ * [Task].
+ */
+fun <TResult> Task<TResult>.addOnSuccessListener(
+        executor: Executor,
+        listener: (TResult) -> Unit
+): Task<TResult> {
+    return addOnSuccessListener(executor, OnSuccessListener(listener))
+}
+
+/**
+ * Quality-of-life helper to allow using trailing lambda syntax for adding a failure listener to a
+ * [Task].
+ */
+fun <TResult> Task<TResult>.addOnFailureListener(
+        executor: Executor,
+        listener: (Exception) -> Unit
+): Task<TResult> {
+    return addOnFailureListener(executor, OnFailureListener(listener))
+}
+
+/**
+ * Quality-of-life helper to allow using trailing lambda syntax for adding a completion listener to
+ * a [Task].
+ */
+fun <TResult> Task<TResult>.addOnCompleteListener(
+        executor: Executor,
+        listener: (Task<TResult>) -> Unit
+): Task<TResult> {
+    return addOnCompleteListener(executor, OnCompleteListener(listener))
+}
+
+/**
+ * Quality-of-life helper to allow using trailing lambda syntax for adding a cancellation listener
+ * to a [Task].
+ */
+fun <TResult> Task<TResult>.addOnCanceledListener(
+        executor: Executor,
+        listener: () -> Unit
+): Task<TResult> {
+    return addOnCanceledListener(executor, OnCanceledListener(listener))
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/VisionProcessorBase.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/VisionProcessorBase.kt
index 5afa7d1..daf161c 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/VisionProcessorBase.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/VisionProcessorBase.kt
@@ -1,265 +1,265 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin
-
-import android.app.ActivityManager
-import android.content.Context
-import android.graphics.Bitmap
-import android.os.Build.VERSION_CODES
-import android.os.SystemClock
-import android.util.Log
-import android.widget.Toast
-import androidx.annotation.GuardedBy
-import androidx.annotation.RequiresApi
-import androidx.camera.core.ExperimentalGetImage
-import androidx.camera.core.ImageProxy
-import com.google.android.gms.tasks.Task
-import com.google.android.gms.tasks.TaskExecutors
-import com.google.mlkit.vision.common.InputImage
-import com.google.mlkit.vision.demo.BitmapUtils
-import com.google.mlkit.vision.demo.CameraImageGraphic
-import com.google.mlkit.vision.demo.FrameMetadata
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.InferenceInfoGraphic
-import com.google.mlkit.vision.demo.ScopedExecutor
-import com.google.mlkit.vision.demo.VisionImageProcessor
-import com.google.mlkit.vision.demo.preference.PreferenceUtils
-import java.nio.ByteBuffer
-import java.util.Timer
-import java.util.TimerTask
-
-/**
- * Abstract base class for ML Kit frame processors. Subclasses need to implement {@link
- * #onSuccess(T, FrameMetadata, GraphicOverlay)} to define what they want to with the detection
- * results and {@link #detectInImage(VisionImage)} to specify the detector object.
- *
- * @param <T> The type of the detected feature.
- */
-abstract class VisionProcessorBase<T>(context: Context) : VisionImageProcessor {
-
-    companion object {
-        const val MANUAL_TESTING_LOG = "LogTagForTest"
-        private const val TAG = "VisionProcessorBase"
-    }
-
-    private var activityManager: ActivityManager =
-            context.getSystemService(Context.ACTIVITY_SERVICE) as ActivityManager
-    private val fpsTimer = Timer()
-    private val executor = ScopedExecutor(TaskExecutors.MAIN_THREAD)
-
-    // Whether this processor is already shut down
-    private var isShutdown = false
-
-    // Used to calculate latency, running in the same thread, no sync needed.
-    private var numRuns = 0
-    private var totalRunMs: Long = 0
-    private var maxRunMs: Long = 0
-    private var minRunMs = Long.MAX_VALUE
-
-    // Frame count that have been processed so far in an one second interval to calculate FPS.
-    private var frameProcessedInOneSecondInterval = 0
-    private var framesPerSecond = 0
-
-    // To keep the latest images and its metadata.
-    @GuardedBy("this")
-    private var latestImage: ByteBuffer? = null
-    @GuardedBy("this")
-    private var latestImageMetaData: FrameMetadata? = null
-    // To keep the images and metadata in process.
-    @GuardedBy("this")
-    private var processingImage: ByteBuffer? = null
-    @GuardedBy("this")
-    private var processingMetaData: FrameMetadata? = null
-
-    init {
-        fpsTimer.scheduleAtFixedRate(
-                object : TimerTask() {
-                    override fun run() {
-                        framesPerSecond = frameProcessedInOneSecondInterval
-                        frameProcessedInOneSecondInterval = 0
-                    }
-                },
-                0,
-                1000
-        )
-    }
-
-    // -----------------Code for processing single still image----------------------------------------
-    override fun processBitmap(bitmap: Bitmap?, graphicOverlay: GraphicOverlay) {
-        requestDetectInImage(
-                InputImage.fromBitmap(bitmap!!, 0),
-                graphicOverlay, /* originalCameraImage= */
-                null, /* shouldShowFps= */
-                false
-        )
-    }
-
-    // -----------------Code for processing live preview frame from Camera1 API-----------------------
-    @Synchronized
-    override fun processByteBuffer(
-            data: ByteBuffer?,
-            frameMetadata: FrameMetadata?,
-            graphicOverlay: GraphicOverlay
-    ) {
-        latestImage = data
-        latestImageMetaData = frameMetadata
-        if (processingImage == null && processingMetaData == null) {
-            processLatestImage(graphicOverlay)
-        }
-    }
-
-    @Synchronized
-    private fun processLatestImage(graphicOverlay: GraphicOverlay) {
-        processingImage = latestImage
-        processingMetaData = latestImageMetaData
-        latestImage = null
-        latestImageMetaData = null
-        if (processingImage != null && processingMetaData != null && !isShutdown) {
-            processImage(processingImage!!, processingMetaData!!, graphicOverlay)
-        }
-    }
-
-    private fun processImage(
-            data: ByteBuffer,
-            frameMetadata: FrameMetadata,
-            graphicOverlay: GraphicOverlay
-    ) {
-        // If live viewport is on (that is the underneath surface view takes care of the camera preview
-        // drawing), skip the unnecessary bitmap creation that used for the manual preview drawing.
-        val bitmap =
-                if (PreferenceUtils.isCameraLiveViewportEnabled(graphicOverlay.context)) null
-                else BitmapUtils.getBitmap(data, frameMetadata)
-        requestDetectInImage(
-                InputImage.fromByteBuffer(
-                        data,
-                        frameMetadata.width,
-                        frameMetadata.height,
-                        frameMetadata.rotation,
-                        InputImage.IMAGE_FORMAT_NV21
-                ),
-                graphicOverlay,
-                bitmap, /* shouldShowFps= */
-                true
-        )
-                .addOnSuccessListener(executor) { processLatestImage(graphicOverlay) }
-    }
-
-    // -----------------Code for processing live preview frame from CameraX API-----------------------
-    @RequiresApi(VERSION_CODES.KITKAT)
-    @ExperimentalGetImage
-    override fun processImageProxy(image: ImageProxy, graphicOverlay: GraphicOverlay) {
-        if (isShutdown) {
-            return
-        }
-        var bitmap: Bitmap? = null
-        if (!PreferenceUtils.isCameraLiveViewportEnabled(graphicOverlay.context)) {
-            bitmap = BitmapUtils.getBitmap(image)
-        }
-        requestDetectInImage(
-                InputImage.fromMediaImage(image.image!!, image.imageInfo.rotationDegrees),
-                graphicOverlay, /* originalCameraImage= */
-                bitmap, /* shouldShowFps= */
-                true
-        )
-                // When the image is from CameraX analysis use case, must call image.close() on received
-                // images when finished using them. Otherwise, new images may not be received or the camera
-                // may stall.
-                .addOnCompleteListener { image.close() }
-    }
-
-    // -----------------Common processing logic-------------------------------------------------------
-    private fun requestDetectInImage(
-            image: InputImage,
-            graphicOverlay: GraphicOverlay,
-            originalCameraImage: Bitmap?,
-            shouldShowFps: Boolean
-    ): Task<T> {
-        val startMs = SystemClock.elapsedRealtime()
-        return detectInImage(image).addOnSuccessListener(executor) { results: T ->
-            val currentLatencyMs = SystemClock.elapsedRealtime() - startMs
-            numRuns++
-            frameProcessedInOneSecondInterval++
-            totalRunMs += currentLatencyMs
-            maxRunMs = Math.max(currentLatencyMs, maxRunMs)
-            minRunMs = Math.min(currentLatencyMs, minRunMs)
-            // Only log inference info once per second. When frameProcessedInOneSecondInterval is
-            // equal to 1, it means this is the first frame processed during the current second.
-            if (frameProcessedInOneSecondInterval == 1) {
-                Log.d(TAG, "Max latency is: $maxRunMs")
-                Log.d(TAG, "Min latency is: $minRunMs")
-                Log.d(
-                        TAG,
-                        "Num of Runs: " + numRuns + ", Avg latency is: " + totalRunMs / numRuns
-                )
-                val mi = ActivityManager.MemoryInfo()
-                activityManager.getMemoryInfo(mi)
-                val availableMegs = mi.availMem / 0x100000L
-                Log.d(
-                        TAG,
-                        "Memory available in system: $availableMegs MB"
-                )
-            }
-            graphicOverlay.clear()
-            if (originalCameraImage != null) {
-                graphicOverlay.add(
-                        CameraImageGraphic(
-                                graphicOverlay,
-                                originalCameraImage
-                        )
-                )
-            }
-            this@VisionProcessorBase.onSuccess(results, graphicOverlay)
-            graphicOverlay.add(
-                    InferenceInfoGraphic(
-                            graphicOverlay,
-                            currentLatencyMs.toDouble(),
-                            if (shouldShowFps) framesPerSecond else null
-                    )
-            )
-            graphicOverlay.postInvalidate()
-        }
-                .addOnFailureListener(executor) { e: Exception ->
-                    graphicOverlay.clear()
-                    graphicOverlay.postInvalidate()
-                    Toast.makeText(
-                            graphicOverlay.context,
-                            "Failed to process.\nError: " +
-                                    e.localizedMessage +
-                                    "\nCause: " +
-                                    e.cause,
-                            Toast.LENGTH_LONG
-                    )
-                            .show()
-                    e.printStackTrace()
-                    this@VisionProcessorBase.onFailure(e)
-                }
-    }
-
-    override fun stop() {
-        executor.shutdown()
-        isShutdown = true
-        numRuns = 0
-        totalRunMs = 0
-        fpsTimer.cancel()
-    }
-
-    protected abstract fun detectInImage(image: InputImage): Task<T>
-
-    protected abstract fun onSuccess(results: T, graphicOverlay: GraphicOverlay)
-
-    protected abstract fun onFailure(e: Exception)
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin
+
+import android.app.ActivityManager
+import android.content.Context
+import android.graphics.Bitmap
+import android.os.Build.VERSION_CODES
+import android.os.SystemClock
+import android.util.Log
+import android.widget.Toast
+import androidx.annotation.GuardedBy
+import androidx.annotation.RequiresApi
+import androidx.camera.core.ExperimentalGetImage
+import androidx.camera.core.ImageProxy
+import com.google.android.gms.tasks.Task
+import com.google.android.gms.tasks.TaskExecutors
+import com.google.mlkit.vision.common.InputImage
+import com.google.mlkit.vision.demo.BitmapUtils
+import com.google.mlkit.vision.demo.CameraImageGraphic
+import com.google.mlkit.vision.demo.FrameMetadata
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.InferenceInfoGraphic
+import com.google.mlkit.vision.demo.ScopedExecutor
+import com.google.mlkit.vision.demo.VisionImageProcessor
+import com.google.mlkit.vision.demo.preference.PreferenceUtils
+import java.nio.ByteBuffer
+import java.util.Timer
+import java.util.TimerTask
+
+/**
+ * Abstract base class for ML Kit frame processors. Subclasses need to implement {@link
+ * #onSuccess(T, FrameMetadata, GraphicOverlay)} to define what they want to with the detection
+ * results and {@link #detectInImage(VisionImage)} to specify the detector object.
+ *
+ * @param <T> The type of the detected feature.
+ */
+abstract class VisionProcessorBase<T>(context: Context) : VisionImageProcessor {
+
+    companion object {
+        const val MANUAL_TESTING_LOG = "LogTagForTest"
+        private const val TAG = "VisionProcessorBase"
+    }
+
+    private var activityManager: ActivityManager =
+            context.getSystemService(Context.ACTIVITY_SERVICE) as ActivityManager
+    private val fpsTimer = Timer()
+    private val executor = ScopedExecutor(TaskExecutors.MAIN_THREAD)
+
+    // Whether this processor is already shut down
+    private var isShutdown = false
+
+    // Used to calculate latency, running in the same thread, no sync needed.
+    private var numRuns = 0
+    private var totalRunMs: Long = 0
+    private var maxRunMs: Long = 0
+    private var minRunMs = Long.MAX_VALUE
+
+    // Frame count that have been processed so far in an one second interval to calculate FPS.
+    private var frameProcessedInOneSecondInterval = 0
+    private var framesPerSecond = 0
+
+    // To keep the latest images and its metadata.
+    @GuardedBy("this")
+    private var latestImage: ByteBuffer? = null
+    @GuardedBy("this")
+    private var latestImageMetaData: FrameMetadata? = null
+    // To keep the images and metadata in process.
+    @GuardedBy("this")
+    private var processingImage: ByteBuffer? = null
+    @GuardedBy("this")
+    private var processingMetaData: FrameMetadata? = null
+
+    init {
+        fpsTimer.scheduleAtFixedRate(
+                object : TimerTask() {
+                    override fun run() {
+                        framesPerSecond = frameProcessedInOneSecondInterval
+                        frameProcessedInOneSecondInterval = 0
+                    }
+                },
+                0,
+                1000
+        )
+    }
+
+    // -----------------Code for processing single still image----------------------------------------
+    override fun processBitmap(bitmap: Bitmap?, graphicOverlay: GraphicOverlay) {
+        requestDetectInImage(
+                InputImage.fromBitmap(bitmap!!, 0),
+                graphicOverlay, /* originalCameraImage= */
+                null, /* shouldShowFps= */
+                false
+        )
+    }
+
+    // -----------------Code for processing live preview frame from Camera1 API-----------------------
+    @Synchronized
+    override fun processByteBuffer(
+            data: ByteBuffer?,
+            frameMetadata: FrameMetadata?,
+            graphicOverlay: GraphicOverlay
+    ) {
+        latestImage = data
+        latestImageMetaData = frameMetadata
+        if (processingImage == null && processingMetaData == null) {
+            processLatestImage(graphicOverlay)
+        }
+    }
+
+    @Synchronized
+    private fun processLatestImage(graphicOverlay: GraphicOverlay) {
+        processingImage = latestImage
+        processingMetaData = latestImageMetaData
+        latestImage = null
+        latestImageMetaData = null
+        if (processingImage != null && processingMetaData != null && !isShutdown) {
+            processImage(processingImage!!, processingMetaData!!, graphicOverlay)
+        }
+    }
+
+    private fun processImage(
+            data: ByteBuffer,
+            frameMetadata: FrameMetadata,
+            graphicOverlay: GraphicOverlay
+    ) {
+        // If live viewport is on (that is the underneath surface view takes care of the camera preview
+        // drawing), skip the unnecessary bitmap creation that used for the manual preview drawing.
+        val bitmap =
+                if (PreferenceUtils.isCameraLiveViewportEnabled(graphicOverlay.context)) null
+                else BitmapUtils.getBitmap(data, frameMetadata)
+        requestDetectInImage(
+                InputImage.fromByteBuffer(
+                        data,
+                        frameMetadata.width,
+                        frameMetadata.height,
+                        frameMetadata.rotation,
+                        InputImage.IMAGE_FORMAT_NV21
+                ),
+                graphicOverlay,
+                bitmap, /* shouldShowFps= */
+                true
+        )
+                .addOnSuccessListener(executor) { processLatestImage(graphicOverlay) }
+    }
+
+    // -----------------Code for processing live preview frame from CameraX API-----------------------
+    @RequiresApi(VERSION_CODES.KITKAT)
+    @ExperimentalGetImage
+    override fun processImageProxy(image: ImageProxy, graphicOverlay: GraphicOverlay) {
+        if (isShutdown) {
+            return
+        }
+        var bitmap: Bitmap? = null
+        if (!PreferenceUtils.isCameraLiveViewportEnabled(graphicOverlay.context)) {
+            bitmap = BitmapUtils.getBitmap(image)
+        }
+        requestDetectInImage(
+                InputImage.fromMediaImage(image.image!!, image.imageInfo.rotationDegrees),
+                graphicOverlay, /* originalCameraImage= */
+                bitmap, /* shouldShowFps= */
+                true
+        )
+                // When the image is from CameraX analysis use case, must call image.close() on received
+                // images when finished using them. Otherwise, new images may not be received or the camera
+                // may stall.
+                .addOnCompleteListener { image.close() }
+    }
+
+    // -----------------Common processing logic-------------------------------------------------------
+    private fun requestDetectInImage(
+            image: InputImage,
+            graphicOverlay: GraphicOverlay,
+            originalCameraImage: Bitmap?,
+            shouldShowFps: Boolean
+    ): Task<T> {
+        val startMs = SystemClock.elapsedRealtime()
+        return detectInImage(image).addOnSuccessListener(executor) { results: T ->
+            val currentLatencyMs = SystemClock.elapsedRealtime() - startMs
+            numRuns++
+            frameProcessedInOneSecondInterval++
+            totalRunMs += currentLatencyMs
+            maxRunMs = Math.max(currentLatencyMs, maxRunMs)
+            minRunMs = Math.min(currentLatencyMs, minRunMs)
+            // Only log inference info once per second. When frameProcessedInOneSecondInterval is
+            // equal to 1, it means this is the first frame processed during the current second.
+            if (frameProcessedInOneSecondInterval == 1) {
+                Log.d(TAG, "Max latency is: $maxRunMs")
+                Log.d(TAG, "Min latency is: $minRunMs")
+                Log.d(
+                        TAG,
+                        "Num of Runs: " + numRuns + ", Avg latency is: " + totalRunMs / numRuns
+                )
+                val mi = ActivityManager.MemoryInfo()
+                activityManager.getMemoryInfo(mi)
+                val availableMegs = mi.availMem / 0x100000L
+                Log.d(
+                        TAG,
+                        "Memory available in system: $availableMegs MB"
+                )
+            }
+            graphicOverlay.clear()
+            if (originalCameraImage != null) {
+                graphicOverlay.add(
+                        CameraImageGraphic(
+                                graphicOverlay,
+                                originalCameraImage
+                        )
+                )
+            }
+            this@VisionProcessorBase.onSuccess(results, graphicOverlay)
+            graphicOverlay.add(
+                    InferenceInfoGraphic(
+                            graphicOverlay,
+                            currentLatencyMs.toDouble(),
+                            if (shouldShowFps) framesPerSecond else null
+                    )
+            )
+            graphicOverlay.postInvalidate()
+        }
+                .addOnFailureListener(executor) { e: Exception ->
+                    graphicOverlay.clear()
+                    graphicOverlay.postInvalidate()
+                    Toast.makeText(
+                            graphicOverlay.context,
+                            "Failed to process.\nError: " +
+                                    e.localizedMessage +
+                                    "\nCause: " +
+                                    e.cause,
+                            Toast.LENGTH_LONG
+                    )
+                            .show()
+                    e.printStackTrace()
+                    this@VisionProcessorBase.onFailure(e)
+                }
+    }
+
+    override fun stop() {
+        executor.shutdown()
+        isShutdown = true
+        numRuns = 0
+        totalRunMs = 0
+        fpsTimer.cancel()
+    }
+
+    protected abstract fun detectInImage(image: InputImage): Task<T>
+
+    protected abstract fun onSuccess(results: T, graphicOverlay: GraphicOverlay)
+
+    protected abstract fun onFailure(e: Exception)
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/automl/AutoMLImageLabelerProcessor.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/automl/AutoMLImageLabelerProcessor.kt
index c377a12..17b1eb9 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/automl/AutoMLImageLabelerProcessor.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/automl/AutoMLImageLabelerProcessor.kt
@@ -1,76 +1,76 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.automl
-
-import android.content.Context
-import android.util.Log
-import com.google.android.gms.tasks.Task
-import com.google.mlkit.vision.common.InputImage
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.automl.LabelGraphic
-import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
-import com.google.mlkit.vision.label.ImageLabel
-import com.google.mlkit.vision.label.ImageLabeler
-import com.google.mlkit.vision.label.ImageLabeling
-import com.google.mlkit.vision.label.automl.AutoMLImageLabelerLocalModel
-import com.google.mlkit.vision.label.automl.AutoMLImageLabelerOptions
-import java.io.IOException
-
-/** AutoML image labeler demo.  */
-class AutoMLImageLabelerProcessor(context: Context) :
-        VisionProcessorBase<List<ImageLabel>>(context) {
-    private val imageLabeler: ImageLabeler
-
-    init {
-        Log.d(TAG, "Local model used.")
-        val localModel = AutoMLImageLabelerLocalModel.Builder()
-                .setAssetFilePath("automl/manifest.json")
-                .build()
-        imageLabeler = ImageLabeling.getClient(
-                AutoMLImageLabelerOptions.Builder(localModel).setConfidenceThreshold(0f).build()
-        )
-    }
-
-    override fun stop() {
-        super.stop()
-        try {
-            imageLabeler.close()
-        } catch (e: IOException) {
-            Log.e(
-                    TAG,
-                    "Exception thrown while trying to close the image labeler",
-                    e
-            )
-        }
-    }
-
-    override fun detectInImage(image: InputImage): Task<List<ImageLabel>> {
-        return imageLabeler.process(image)
-    }
-
-    override fun onSuccess(results: List<ImageLabel>, graphicOverlay: GraphicOverlay) {
-        graphicOverlay.add(LabelGraphic(graphicOverlay, results))
-    }
-
-    override fun onFailure(e: Exception) {
-        Log.w(TAG, "Label detection failed.", e)
-    }
-
-    companion object {
-        private const val TAG = "AutoMLProcessor"
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.automl
+
+import android.content.Context
+import android.util.Log
+import com.google.android.gms.tasks.Task
+import com.google.mlkit.vision.common.InputImage
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.automl.LabelGraphic
+import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
+import com.google.mlkit.vision.label.ImageLabel
+import com.google.mlkit.vision.label.ImageLabeler
+import com.google.mlkit.vision.label.ImageLabeling
+import com.google.mlkit.vision.label.automl.AutoMLImageLabelerLocalModel
+import com.google.mlkit.vision.label.automl.AutoMLImageLabelerOptions
+import java.io.IOException
+
+/** AutoML image labeler demo.  */
+class AutoMLImageLabelerProcessor(context: Context) :
+        VisionProcessorBase<List<ImageLabel>>(context) {
+    private val imageLabeler: ImageLabeler
+
+    init {
+        Log.d(TAG, "Local model used.")
+        val localModel = AutoMLImageLabelerLocalModel.Builder()
+                .setAssetFilePath("automl/manifest.json")
+                .build()
+        imageLabeler = ImageLabeling.getClient(
+                AutoMLImageLabelerOptions.Builder(localModel).setConfidenceThreshold(0f).build()
+        )
+    }
+
+    override fun stop() {
+        super.stop()
+        try {
+            imageLabeler.close()
+        } catch (e: IOException) {
+            Log.e(
+                    TAG,
+                    "Exception thrown while trying to close the image labeler",
+                    e
+            )
+        }
+    }
+
+    override fun detectInImage(image: InputImage): Task<List<ImageLabel>> {
+        return imageLabeler.process(image)
+    }
+
+    override fun onSuccess(results: List<ImageLabel>, graphicOverlay: GraphicOverlay) {
+        graphicOverlay.add(LabelGraphic(graphicOverlay, results))
+    }
+
+    override fun onFailure(e: Exception) {
+        Log.w(TAG, "Label detection failed.", e)
+    }
+
+    companion object {
+        private const val TAG = "AutoMLProcessor"
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/automl/LabelGraphic.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/automl/LabelGraphic.kt
index e660753..07be83b 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/automl/LabelGraphic.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/automl/LabelGraphic.kt
@@ -1,54 +1,54 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.automl
-
-import android.graphics.Canvas
-import android.graphics.Color
-import android.graphics.Paint
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
-import com.google.mlkit.vision.label.ImageLabel
-
-/** Graphic instance for rendering a label within an associated graphic overlay view.  */
-class LabelGraphic(
-        private val overlay: GraphicOverlay,
-        private val labels: List<ImageLabel>
-) : Graphic(overlay) {
-
-    private val textPaint: Paint = Paint()
-
-    init {
-        textPaint.color = Color.RED
-        textPaint.textSize = TEXT_SIZE
-    }
-
-    @Synchronized
-    override fun draw(canvas: Canvas) {
-        val x = overlay.width / 8.0f
-        var y = TEXT_SIZE * 4
-        for (label in labels) {
-            canvas.drawText(label.text + " (index: " + label.index + ")", x, y, textPaint)
-            y += TEXT_SIZE
-            canvas.drawText("confidence: " + label.confidence, x, y, textPaint)
-            y += TEXT_SIZE
-        }
-    }
-
-    companion object {
-        private const val TEXT_SIZE = 70.0f
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.automl
+
+import android.graphics.Canvas
+import android.graphics.Color
+import android.graphics.Paint
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
+import com.google.mlkit.vision.label.ImageLabel
+
+/** Graphic instance for rendering a label within an associated graphic overlay view.  */
+class LabelGraphic(
+        private val overlay: GraphicOverlay,
+        private val labels: List<ImageLabel>
+) : Graphic(overlay) {
+
+    private val textPaint: Paint = Paint()
+
+    init {
+        textPaint.color = Color.RED
+        textPaint.textSize = TEXT_SIZE
+    }
+
+    @Synchronized
+    override fun draw(canvas: Canvas) {
+        val x = overlay.width / 8.0f
+        var y = TEXT_SIZE * 4
+        for (label in labels) {
+            canvas.drawText(label.text + " (index: " + label.index + ")", x, y, textPaint)
+            y += TEXT_SIZE
+            canvas.drawText("confidence: " + label.confidence, x, y, textPaint)
+            y += TEXT_SIZE
+        }
+    }
+
+    companion object {
+        private const val TEXT_SIZE = 70.0f
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/barcodescanner/BarcodeGraphic.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/barcodescanner/BarcodeGraphic.kt
index 2fa4084..5a5331c 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/barcodescanner/BarcodeGraphic.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/barcodescanner/BarcodeGraphic.kt
@@ -1,85 +1,85 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.barcodescanner
-
-import android.graphics.Canvas
-import android.graphics.Color
-import android.graphics.Paint
-import android.graphics.RectF
-import com.google.mlkit.vision.barcode.Barcode
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
-
-/** Graphic instance for rendering Barcode position and content information in an overlay view.  */
-class BarcodeGraphic constructor(overlay: GraphicOverlay?, private val barcode: Barcode?) :
-  Graphic(overlay) {
-  private val rectPaint: Paint = Paint()
-  private val barcodePaint: Paint
-  private val labelPaint: Paint
-
-  init {
-    rectPaint.color = MARKER_COLOR
-    rectPaint.style = Paint.Style.STROKE
-    rectPaint.strokeWidth = STROKE_WIDTH
-    barcodePaint = Paint()
-    barcodePaint.color = TEXT_COLOR
-    barcodePaint.textSize = TEXT_SIZE
-    labelPaint = Paint()
-    labelPaint.color = MARKER_COLOR
-    labelPaint.style = Paint.Style.FILL
-  }
-
-  /**
-   * Draws the barcode block annotations for position, size, and raw value on the supplied canvas.
-   */
-  override fun draw(canvas: Canvas) {
-    checkNotNull(barcode) { "Attempting to draw a null barcode." }
-    // Draws the bounding box around the BarcodeBlock.
-    val rect = RectF(barcode.boundingBox)
-    rect.left = translateX(rect.left)
-    rect.top = translateY(rect.top)
-    rect.right = translateX(rect.right)
-    rect.bottom = translateY(rect.bottom)
-    canvas.drawRect(rect, rectPaint)
-    // Draws other object info.
-    val lineHeight =
-      TEXT_SIZE + 2 * STROKE_WIDTH
-    val textWidth = barcodePaint.measureText(barcode.rawValue)
-    val left = if (isImageFlipped) rect.right else rect.left
-    canvas.drawRect(
-      left - STROKE_WIDTH,
-      rect.top - lineHeight,
-      left + textWidth + 2 * STROKE_WIDTH,
-      rect.top,
-      labelPaint
-    )
-    // Renders the barcode at the bottom of the box.
-    canvas.drawText(
-      barcode.rawValue!!,
-      left,
-      rect.top - STROKE_WIDTH,
-      barcodePaint
-    )
-  }
-
-  companion object {
-    private const val TEXT_COLOR = Color.BLACK
-    private const val MARKER_COLOR = Color.WHITE
-    private const val TEXT_SIZE = 54.0f
-    private const val STROKE_WIDTH = 4.0f
-  }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.barcodescanner
+
+import android.graphics.Canvas
+import android.graphics.Color
+import android.graphics.Paint
+import android.graphics.RectF
+import com.google.mlkit.vision.barcode.Barcode
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
+
+/** Graphic instance for rendering Barcode position and content information in an overlay view.  */
+class BarcodeGraphic constructor(overlay: GraphicOverlay?, private val barcode: Barcode?) :
+  Graphic(overlay) {
+  private val rectPaint: Paint = Paint()
+  private val barcodePaint: Paint
+  private val labelPaint: Paint
+
+  init {
+    rectPaint.color = MARKER_COLOR
+    rectPaint.style = Paint.Style.STROKE
+    rectPaint.strokeWidth = STROKE_WIDTH
+    barcodePaint = Paint()
+    barcodePaint.color = TEXT_COLOR
+    barcodePaint.textSize = TEXT_SIZE
+    labelPaint = Paint()
+    labelPaint.color = MARKER_COLOR
+    labelPaint.style = Paint.Style.FILL
+  }
+
+  /**
+   * Draws the barcode block annotations for position, size, and raw value on the supplied canvas.
+   */
+  override fun draw(canvas: Canvas) {
+    checkNotNull(barcode) { "Attempting to draw a null barcode." }
+    // Draws the bounding box around the BarcodeBlock.
+    val rect = RectF(barcode.boundingBox)
+    rect.left = translateX(rect.left)
+    rect.top = translateY(rect.top)
+    rect.right = translateX(rect.right)
+    rect.bottom = translateY(rect.bottom)
+    canvas.drawRect(rect, rectPaint)
+    // Draws other object info.
+    val lineHeight =
+      TEXT_SIZE + 2 * STROKE_WIDTH
+    val textWidth = barcodePaint.measureText(barcode.rawValue)
+    val left = if (isImageFlipped) rect.right else rect.left
+    canvas.drawRect(
+      left - STROKE_WIDTH,
+      rect.top - lineHeight,
+      left + textWidth + 2 * STROKE_WIDTH,
+      rect.top,
+      labelPaint
+    )
+    // Renders the barcode at the bottom of the box.
+    canvas.drawText(
+      barcode.rawValue!!,
+      left,
+      rect.top - STROKE_WIDTH,
+      barcodePaint
+    )
+  }
+
+  companion object {
+    private const val TEXT_COLOR = Color.BLACK
+    private const val MARKER_COLOR = Color.WHITE
+    private const val TEXT_SIZE = 54.0f
+    private const val STROKE_WIDTH = 4.0f
+  }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/barcodescanner/BarcodeScannerProcessor.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/barcodescanner/BarcodeScannerProcessor.kt
index 2fa63a6..6679f89 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/barcodescanner/BarcodeScannerProcessor.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/barcodescanner/BarcodeScannerProcessor.kt
@@ -1,162 +1,162 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.barcodescanner
-
-import android.content.Context
-import android.util.Log
-import com.google.android.gms.tasks.Task
-import com.google.mlkit.vision.barcode.Barcode
-import com.google.mlkit.vision.barcode.BarcodeScanner
-import com.google.mlkit.vision.barcode.BarcodeScanning
-import com.google.mlkit.vision.common.InputImage
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
-
-/** Barcode Detector Demo.  */
-class BarcodeScannerProcessor(context: Context) : VisionProcessorBase<List<Barcode>>(context) {
-
-    // Note that if you know which format of barcode your app is dealing with, detection will be
-    // faster to specify the supported barcode formats one by one, e.g.
-    // BarcodeScannerOptions.Builder()
-    //     .setBarcodeFormats(Barcode.FORMAT_QR_CODE)
-    //     .build();
-    private val barcodeScanner: BarcodeScanner = BarcodeScanning.getClient()
-
-    override fun stop() {
-        super.stop()
-        barcodeScanner.close()
-    }
-
-    override fun detectInImage(image: InputImage): Task<List<Barcode>> {
-        return barcodeScanner.process(image)
-    }
-
-    override fun onSuccess(barcodes: List<Barcode>, graphicOverlay: GraphicOverlay) {
-        if (barcodes.isEmpty()) {
-            Log.v(MANUAL_TESTING_LOG, "No barcode has been detected")
-        }
-        for (i in barcodes.indices) {
-            val barcode = barcodes[i]
-            graphicOverlay.add(BarcodeGraphic(graphicOverlay, barcode))
-            logExtrasForTesting(barcode)
-        }
-    }
-
-    override fun onFailure(e: Exception) {
-        Log.e(TAG, "Barcode detection failed $e")
-    }
-
-    companion object {
-        private const val TAG = "BarcodeProcessor"
-
-        private fun logExtrasForTesting(barcode: Barcode?) {
-            if (barcode != null) {
-                Log.v(
-                        MANUAL_TESTING_LOG,
-                        String.format(
-                                "Detected barcode's bounding box: %s",
-                                barcode.boundingBox!!.flattenToString()
-                        )
-                )
-                Log.v(
-                        MANUAL_TESTING_LOG,
-                        String.format(
-                                "Expected corner point size is 4, get %d",
-                                barcode.cornerPoints!!.size
-                        )
-                )
-                for (point in barcode.cornerPoints!!) {
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            String.format(
-                                    "Corner point is located at: x = %d, y = %d",
-                                    point.x,
-                                    point.y
-                            )
-                    )
-                }
-                Log.v(
-                        MANUAL_TESTING_LOG,
-                        "barcode display value: " + barcode.displayValue
-                )
-                Log.v(
-                        MANUAL_TESTING_LOG,
-                        "barcode raw value: " + barcode.rawValue
-                )
-                val dl = barcode.driverLicense
-                if (dl != null) {
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license city: " + dl.addressCity
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license state: " + dl.addressState
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license street: " + dl.addressStreet
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license zip code: " + dl.addressZip
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license birthday: " + dl.birthDate
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license document type: " + dl.documentType
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license expiry date: " + dl.expiryDate
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license first name: " + dl.firstName
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license middle name: " + dl.middleName
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license last name: " + dl.lastName
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license gender: " + dl.gender
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license issue date: " + dl.issueDate
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license issue country: " + dl.issuingCountry
-                    )
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            "driver license number: " + dl.licenseNumber
-                    )
-                }
-            }
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.barcodescanner
+
+import android.content.Context
+import android.util.Log
+import com.google.android.gms.tasks.Task
+import com.google.mlkit.vision.barcode.Barcode
+import com.google.mlkit.vision.barcode.BarcodeScanner
+import com.google.mlkit.vision.barcode.BarcodeScanning
+import com.google.mlkit.vision.common.InputImage
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
+
+/** Barcode Detector Demo.  */
+class BarcodeScannerProcessor(context: Context) : VisionProcessorBase<List<Barcode>>(context) {
+
+    // Note that if you know which format of barcode your app is dealing with, detection will be
+    // faster to specify the supported barcode formats one by one, e.g.
+    // BarcodeScannerOptions.Builder()
+    //     .setBarcodeFormats(Barcode.FORMAT_QR_CODE)
+    //     .build();
+    private val barcodeScanner: BarcodeScanner = BarcodeScanning.getClient()
+
+    override fun stop() {
+        super.stop()
+        barcodeScanner.close()
+    }
+
+    override fun detectInImage(image: InputImage): Task<List<Barcode>> {
+        return barcodeScanner.process(image)
+    }
+
+    override fun onSuccess(barcodes: List<Barcode>, graphicOverlay: GraphicOverlay) {
+        if (barcodes.isEmpty()) {
+            Log.v(MANUAL_TESTING_LOG, "No barcode has been detected")
+        }
+        for (i in barcodes.indices) {
+            val barcode = barcodes[i]
+            graphicOverlay.add(BarcodeGraphic(graphicOverlay, barcode))
+            logExtrasForTesting(barcode)
+        }
+    }
+
+    override fun onFailure(e: Exception) {
+        Log.e(TAG, "Barcode detection failed $e")
+    }
+
+    companion object {
+        private const val TAG = "BarcodeProcessor"
+
+        private fun logExtrasForTesting(barcode: Barcode?) {
+            if (barcode != null) {
+                Log.v(
+                        MANUAL_TESTING_LOG,
+                        String.format(
+                                "Detected barcode's bounding box: %s",
+                                barcode.boundingBox!!.flattenToString()
+                        )
+                )
+                Log.v(
+                        MANUAL_TESTING_LOG,
+                        String.format(
+                                "Expected corner point size is 4, get %d",
+                                barcode.cornerPoints!!.size
+                        )
+                )
+                for (point in barcode.cornerPoints!!) {
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            String.format(
+                                    "Corner point is located at: x = %d, y = %d",
+                                    point.x,
+                                    point.y
+                            )
+                    )
+                }
+                Log.v(
+                        MANUAL_TESTING_LOG,
+                        "barcode display value: " + barcode.displayValue
+                )
+                Log.v(
+                        MANUAL_TESTING_LOG,
+                        "barcode raw value: " + barcode.rawValue
+                )
+                val dl = barcode.driverLicense
+                if (dl != null) {
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license city: " + dl.addressCity
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license state: " + dl.addressState
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license street: " + dl.addressStreet
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license zip code: " + dl.addressZip
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license birthday: " + dl.birthDate
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license document type: " + dl.documentType
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license expiry date: " + dl.expiryDate
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license first name: " + dl.firstName
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license middle name: " + dl.middleName
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license last name: " + dl.lastName
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license gender: " + dl.gender
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license issue date: " + dl.issueDate
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license issue country: " + dl.issuingCountry
+                    )
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            "driver license number: " + dl.licenseNumber
+                    )
+                }
+            }
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/facedetector/FaceDetectorProcessor.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/facedetector/FaceDetectorProcessor.kt
index dba7350..f4cf3d1 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/facedetector/FaceDetectorProcessor.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/facedetector/FaceDetectorProcessor.kt
@@ -1,154 +1,154 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.facedetector
-
-import android.content.Context
-import android.util.Log
-import com.google.android.gms.tasks.Task
-import com.google.mlkit.vision.common.InputImage
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
-import com.google.mlkit.vision.face.Face
-import com.google.mlkit.vision.face.FaceDetection
-import com.google.mlkit.vision.face.FaceDetector
-import com.google.mlkit.vision.face.FaceDetectorOptions
-import com.google.mlkit.vision.face.FaceLandmark
-import java.util.Locale
-
-/** Face Detector Demo.  */
-class FaceDetectorProcessor(context: Context, detectorOptions: FaceDetectorOptions?) :
-  VisionProcessorBase<List<Face>>(context) {
-
-  private val detector: FaceDetector
-
-  init {
-    val options = detectorOptions
-      ?: FaceDetectorOptions.Builder()
-        .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)
-        .enableTracking()
-        .build()
-
-    detector = FaceDetection.getClient(options)
-
-    Log.v(MANUAL_TESTING_LOG, "Face detector options: $options")
-  }
-
-  override fun stop() {
-    super.stop()
-    detector.close()
-  }
-
-  override fun detectInImage(image: InputImage): Task<List<Face>> {
-    return detector.process(image)
-  }
-
-  override fun onSuccess(faces: List<Face>, graphicOverlay: GraphicOverlay) {
-    for (face in faces) {
-      graphicOverlay.add(FaceGraphic(graphicOverlay, face))
-      logExtrasForTesting(face)
-    }
-  }
-
-  override fun onFailure(e: Exception) {
-    Log.e(TAG, "Face detection failed $e")
-  }
-
-  companion object {
-    private const val TAG = "FaceDetectorProcessor"
-    private fun logExtrasForTesting(face: Face?) {
-      if (face != null) {
-        Log.v(
-          MANUAL_TESTING_LOG,
-          "face bounding box: " + face.boundingBox.flattenToString()
-        )
-        Log.v(
-          MANUAL_TESTING_LOG,
-          "face Euler Angle X: " + face.headEulerAngleX
-        )
-        Log.v(
-          MANUAL_TESTING_LOG,
-          "face Euler Angle Y: " + face.headEulerAngleY
-        )
-        Log.v(
-          MANUAL_TESTING_LOG,
-          "face Euler Angle Z: " + face.headEulerAngleZ
-        )
-        // All landmarks
-        val landMarkTypes = intArrayOf(
-          FaceLandmark.MOUTH_BOTTOM,
-          FaceLandmark.MOUTH_RIGHT,
-          FaceLandmark.MOUTH_LEFT,
-          FaceLandmark.RIGHT_EYE,
-          FaceLandmark.LEFT_EYE,
-          FaceLandmark.RIGHT_EAR,
-          FaceLandmark.LEFT_EAR,
-          FaceLandmark.RIGHT_CHEEK,
-          FaceLandmark.LEFT_CHEEK,
-          FaceLandmark.NOSE_BASE
-        )
-        val landMarkTypesStrings = arrayOf(
-          "MOUTH_BOTTOM",
-          "MOUTH_RIGHT",
-          "MOUTH_LEFT",
-          "RIGHT_EYE",
-          "LEFT_EYE",
-          "RIGHT_EAR",
-          "LEFT_EAR",
-          "RIGHT_CHEEK",
-          "LEFT_CHEEK",
-          "NOSE_BASE"
-        )
-        for (i in landMarkTypes.indices) {
-          val landmark = face.getLandmark(landMarkTypes[i])
-          if (landmark == null) {
-            Log.v(
-              MANUAL_TESTING_LOG,
-              "No landmark of type: " + landMarkTypesStrings[i] + " has been detected"
-            )
-          } else {
-            val landmarkPosition = landmark.position
-            val landmarkPositionStr =
-              String.format(Locale.US, "x: %f , y: %f", landmarkPosition.x, landmarkPosition.y)
-            Log.v(
-              MANUAL_TESTING_LOG,
-              "Position for face landmark: " +
-                landMarkTypesStrings[i] +
-                " is :" +
-                landmarkPositionStr
-            )
-          }
-        }
-        Log.v(
-          MANUAL_TESTING_LOG,
-          "face left eye open probability: " + face.leftEyeOpenProbability
-        )
-        Log.v(
-          MANUAL_TESTING_LOG,
-          "face right eye open probability: " + face.rightEyeOpenProbability
-        )
-        Log.v(
-          MANUAL_TESTING_LOG,
-          "face smiling probability: " + face.smilingProbability
-        )
-        Log.v(
-          MANUAL_TESTING_LOG,
-          "face tracking id: " + face.trackingId
-        )
-      }
-    }
-  }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.facedetector
+
+import android.content.Context
+import android.util.Log
+import com.google.android.gms.tasks.Task
+import com.google.mlkit.vision.common.InputImage
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
+import com.google.mlkit.vision.face.Face
+import com.google.mlkit.vision.face.FaceDetection
+import com.google.mlkit.vision.face.FaceDetector
+import com.google.mlkit.vision.face.FaceDetectorOptions
+import com.google.mlkit.vision.face.FaceLandmark
+import java.util.Locale
+
+/** Face Detector Demo.  */
+class FaceDetectorProcessor(context: Context, detectorOptions: FaceDetectorOptions?) :
+  VisionProcessorBase<List<Face>>(context) {
+
+  private val detector: FaceDetector
+
+  init {
+    val options = detectorOptions
+      ?: FaceDetectorOptions.Builder()
+        .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)
+        .enableTracking()
+        .build()
+
+    detector = FaceDetection.getClient(options)
+
+    Log.v(MANUAL_TESTING_LOG, "Face detector options: $options")
+  }
+
+  override fun stop() {
+    super.stop()
+    detector.close()
+  }
+
+  override fun detectInImage(image: InputImage): Task<List<Face>> {
+    return detector.process(image)
+  }
+
+  override fun onSuccess(faces: List<Face>, graphicOverlay: GraphicOverlay) {
+    for (face in faces) {
+      graphicOverlay.add(FaceGraphic(graphicOverlay, face))
+      logExtrasForTesting(face)
+    }
+  }
+
+  override fun onFailure(e: Exception) {
+    Log.e(TAG, "Face detection failed $e")
+  }
+
+  companion object {
+    private const val TAG = "FaceDetectorProcessor"
+    private fun logExtrasForTesting(face: Face?) {
+      if (face != null) {
+        Log.v(
+          MANUAL_TESTING_LOG,
+          "face bounding box: " + face.boundingBox.flattenToString()
+        )
+        Log.v(
+          MANUAL_TESTING_LOG,
+          "face Euler Angle X: " + face.headEulerAngleX
+        )
+        Log.v(
+          MANUAL_TESTING_LOG,
+          "face Euler Angle Y: " + face.headEulerAngleY
+        )
+        Log.v(
+          MANUAL_TESTING_LOG,
+          "face Euler Angle Z: " + face.headEulerAngleZ
+        )
+        // All landmarks
+        val landMarkTypes = intArrayOf(
+          FaceLandmark.MOUTH_BOTTOM,
+          FaceLandmark.MOUTH_RIGHT,
+          FaceLandmark.MOUTH_LEFT,
+          FaceLandmark.RIGHT_EYE,
+          FaceLandmark.LEFT_EYE,
+          FaceLandmark.RIGHT_EAR,
+          FaceLandmark.LEFT_EAR,
+          FaceLandmark.RIGHT_CHEEK,
+          FaceLandmark.LEFT_CHEEK,
+          FaceLandmark.NOSE_BASE
+        )
+        val landMarkTypesStrings = arrayOf(
+          "MOUTH_BOTTOM",
+          "MOUTH_RIGHT",
+          "MOUTH_LEFT",
+          "RIGHT_EYE",
+          "LEFT_EYE",
+          "RIGHT_EAR",
+          "LEFT_EAR",
+          "RIGHT_CHEEK",
+          "LEFT_CHEEK",
+          "NOSE_BASE"
+        )
+        for (i in landMarkTypes.indices) {
+          val landmark = face.getLandmark(landMarkTypes[i])
+          if (landmark == null) {
+            Log.v(
+              MANUAL_TESTING_LOG,
+              "No landmark of type: " + landMarkTypesStrings[i] + " has been detected"
+            )
+          } else {
+            val landmarkPosition = landmark.position
+            val landmarkPositionStr =
+              String.format(Locale.US, "x: %f , y: %f", landmarkPosition.x, landmarkPosition.y)
+            Log.v(
+              MANUAL_TESTING_LOG,
+              "Position for face landmark: " +
+                landMarkTypesStrings[i] +
+                " is :" +
+                landmarkPositionStr
+            )
+          }
+        }
+        Log.v(
+          MANUAL_TESTING_LOG,
+          "face left eye open probability: " + face.leftEyeOpenProbability
+        )
+        Log.v(
+          MANUAL_TESTING_LOG,
+          "face right eye open probability: " + face.rightEyeOpenProbability
+        )
+        Log.v(
+          MANUAL_TESTING_LOG,
+          "face smiling probability: " + face.smilingProbability
+        )
+        Log.v(
+          MANUAL_TESTING_LOG,
+          "face tracking id: " + face.trackingId
+        )
+      }
+    }
+  }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/facedetector/FaceGraphic.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/facedetector/FaceGraphic.kt
index 095d8dc..a5f7eea 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/facedetector/FaceGraphic.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/facedetector/FaceGraphic.kt
@@ -1,253 +1,253 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.facedetector
-
-import android.graphics.Canvas
-import android.graphics.Color
-import android.graphics.Paint
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
-import com.google.mlkit.vision.face.Face
-import com.google.mlkit.vision.face.FaceLandmark
-import com.google.mlkit.vision.face.FaceLandmark.LandmarkType
-import java.util.Locale
-
-/**
- * Graphic instance for rendering face position, contour, and landmarks within the associated
- * graphic overlay view.
- */
-class FaceGraphic constructor(overlay: GraphicOverlay?, private val face: Face) : Graphic(overlay) {
-    private val facePositionPaint: Paint
-    private val numColors = COLORS.size
-    private val idPaints = Array(numColors) { Paint() }
-    private val boxPaints = Array(numColors) { Paint() }
-    private val labelPaints = Array(numColors) { Paint() }
-
-    init {
-        val selectedColor = Color.WHITE
-        facePositionPaint = Paint()
-        facePositionPaint.color = selectedColor
-        for (i in 0 until numColors) {
-            idPaints[i] = Paint()
-            idPaints[i].color = COLORS[i][0]
-            idPaints[i].textSize = ID_TEXT_SIZE
-            boxPaints[i] = Paint()
-            boxPaints[i].color = COLORS[i][1]
-            boxPaints[i].style = Paint.Style.STROKE
-            boxPaints[i].strokeWidth = BOX_STROKE_WIDTH
-            labelPaints[i] = Paint()
-            labelPaints[i].color = COLORS[i][1]
-            labelPaints[i].style = Paint.Style.FILL
-        }
-    }
-
-    /** Draws the face annotations for position on the supplied canvas.  */
-    override fun draw(canvas: Canvas) {
-        val face = face ?: return
-        // Draws a circle at the position of the detected face, with the face's track id below.
-        val x = translateX(face.boundingBox.centerX().toFloat())
-        val y = translateY(face.boundingBox.centerY().toFloat())
-        canvas.drawCircle(x, y, FACE_POSITION_RADIUS, facePositionPaint)
-
-        // Calculate positions.
-        val left = x - scale(face.boundingBox.width() / 2.0f)
-        val top = y - scale(face.boundingBox.height() / 2.0f)
-        val right = x + scale(face.boundingBox.width() / 2.0f)
-        val bottom = y + scale(face.boundingBox.height() / 2.0f)
-        val lineHeight = ID_TEXT_SIZE + BOX_STROKE_WIDTH
-        var yLabelOffset = -lineHeight
-
-        // Decide color based on face ID
-        val colorID = if (face.trackingId == null) 0 else Math.abs(face.trackingId!! % NUM_COLORS)
-
-        // Calculate width and height of label box
-        var textWidth = idPaints[colorID].measureText("ID: " + face.trackingId)
-        if (face.smilingProbability != null) {
-            yLabelOffset -= lineHeight
-            textWidth =
-                    Math.max(
-                            textWidth,
-                            idPaints[colorID].measureText(
-                                    String.format(
-                                            Locale.US,
-                                            "Happiness: %.2f",
-                                            face.smilingProbability
-                                    )
-                            )
-                    )
-        }
-
-        if (face.leftEyeOpenProbability != null) {
-            yLabelOffset -= lineHeight
-            textWidth =
-                    Math.max(
-                            textWidth,
-                            idPaints[colorID].measureText(
-                                    String.format(
-                                            Locale.US,
-                                            "Left eye: %.2f",
-                                            face.leftEyeOpenProbability
-                                    )
-                            )
-                    )
-        }
-
-        if (face.rightEyeOpenProbability != null) {
-            yLabelOffset -= lineHeight
-            textWidth =
-                    Math.max(
-                            textWidth,
-                            idPaints[colorID].measureText(
-                                    String.format(
-                                            Locale.US,
-                                            "Right eye: %.2f",
-                                            face.leftEyeOpenProbability
-                                    )
-                            )
-                    )
-        }
-
-        // Draw labels
-        canvas.drawRect(
-                left - BOX_STROKE_WIDTH,
-                top + yLabelOffset,
-                left + textWidth + 2 * BOX_STROKE_WIDTH,
-                top,
-                labelPaints[colorID]
-        )
-        yLabelOffset += ID_TEXT_SIZE
-        canvas.drawRect(left, top, right, bottom, boxPaints[colorID])
-        canvas.drawText(
-                "ID: " + face.trackingId, left, top + yLabelOffset,
-                idPaints[colorID]
-        )
-        yLabelOffset += lineHeight
-
-        // Draws all face contours.
-        for (contour in face.allContours) {
-            for (point in contour.points) {
-                canvas.drawCircle(
-                        translateX(point.x),
-                        translateY(point.y),
-                        FACE_POSITION_RADIUS,
-                        facePositionPaint
-                )
-            }
-        }
-
-        // Draws smiling and left/right eye open probabilities.
-        if (face.smilingProbability != null) {
-            canvas.drawText(
-                    "Smiling: " + String.format(Locale.US, "%.2f", face.smilingProbability),
-                    left,
-                    top + yLabelOffset,
-                    idPaints[colorID]
-            )
-            yLabelOffset += lineHeight
-        }
-
-        val leftEye = face.getLandmark(FaceLandmark.LEFT_EYE)
-        if (leftEye != null && face.leftEyeOpenProbability != null) {
-            canvas.drawText(
-                    "Left eye open: " + String.format(Locale.US, "%.2f", face.leftEyeOpenProbability),
-                    translateX(leftEye.position.x) + ID_X_OFFSET,
-                    translateY(leftEye.position.y) + ID_Y_OFFSET,
-                    idPaints[colorID]
-            )
-        } else if (leftEye != null && face.leftEyeOpenProbability == null) {
-            canvas.drawText(
-                    "Left eye",
-                    left,
-                    top + yLabelOffset,
-                    idPaints[colorID]
-            )
-            yLabelOffset += lineHeight
-        } else if (leftEye == null && face.leftEyeOpenProbability != null) {
-            canvas.drawText(
-                    "Left eye open: " + String.format(Locale.US, "%.2f", face.leftEyeOpenProbability),
-                    left,
-                    top + yLabelOffset,
-                    idPaints[colorID]
-            )
-            yLabelOffset += lineHeight
-        }
-        val rightEye = face.getLandmark(FaceLandmark.RIGHT_EYE)
-        if (rightEye != null && face.rightEyeOpenProbability != null) {
-            canvas.drawText(
-                    "Right eye open: " + String.format(Locale.US, "%.2f", face.rightEyeOpenProbability),
-                    translateX(rightEye.position.x) + ID_X_OFFSET,
-                    translateY(rightEye.position.y) + ID_Y_OFFSET,
-                    idPaints[colorID]
-            )
-        } else if (rightEye != null && face.rightEyeOpenProbability == null) {
-            canvas.drawText(
-                    "Right eye",
-                    left,
-                    top + yLabelOffset,
-                    idPaints[colorID]
-            )
-            yLabelOffset += lineHeight
-        } else if (rightEye == null && face.rightEyeOpenProbability != null) {
-            canvas.drawText(
-                    "Right eye open: " + String.format(Locale.US, "%.2f", face.rightEyeOpenProbability),
-                    left,
-                    top + yLabelOffset,
-                    idPaints[colorID]
-            )
-        }
-
-        // Draw facial landmarks
-        drawFaceLandmark(canvas, FaceLandmark.LEFT_EYE)
-        drawFaceLandmark(canvas, FaceLandmark.RIGHT_EYE)
-        drawFaceLandmark(canvas, FaceLandmark.LEFT_CHEEK)
-        drawFaceLandmark(canvas, FaceLandmark.RIGHT_CHEEK)
-    }
-
-    private fun drawFaceLandmark(canvas: Canvas, @LandmarkType landmarkType: Int) {
-        val faceLandmark = face.getLandmark(landmarkType)
-        if (faceLandmark != null) {
-            canvas.drawCircle(
-                    translateX(faceLandmark.position.x),
-                    translateY(faceLandmark.position.y),
-                    FACE_POSITION_RADIUS,
-                    facePositionPaint
-            )
-        }
-    }
-
-    companion object {
-        private const val FACE_POSITION_RADIUS = 4.0f
-        private const val ID_TEXT_SIZE = 30.0f
-        private const val ID_Y_OFFSET = 40.0f
-        private const val ID_X_OFFSET = -40.0f
-        private const val BOX_STROKE_WIDTH = 5.0f
-        private const val NUM_COLORS = 10
-        private val COLORS =
-                arrayOf(
-                        intArrayOf(Color.BLACK, Color.WHITE),
-                        intArrayOf(Color.WHITE, Color.MAGENTA),
-                        intArrayOf(Color.BLACK, Color.LTGRAY),
-                        intArrayOf(Color.WHITE, Color.RED),
-                        intArrayOf(Color.WHITE, Color.BLUE),
-                        intArrayOf(Color.WHITE, Color.DKGRAY),
-                        intArrayOf(Color.BLACK, Color.CYAN),
-                        intArrayOf(Color.BLACK, Color.YELLOW),
-                        intArrayOf(Color.WHITE, Color.BLACK),
-                        intArrayOf(Color.BLACK, Color.GREEN)
-                )
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.facedetector
+
+import android.graphics.Canvas
+import android.graphics.Color
+import android.graphics.Paint
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
+import com.google.mlkit.vision.face.Face
+import com.google.mlkit.vision.face.FaceLandmark
+import com.google.mlkit.vision.face.FaceLandmark.LandmarkType
+import java.util.Locale
+
+/**
+ * Graphic instance for rendering face position, contour, and landmarks within the associated
+ * graphic overlay view.
+ */
+class FaceGraphic constructor(overlay: GraphicOverlay?, private val face: Face) : Graphic(overlay) {
+    private val facePositionPaint: Paint
+    private val numColors = COLORS.size
+    private val idPaints = Array(numColors) { Paint() }
+    private val boxPaints = Array(numColors) { Paint() }
+    private val labelPaints = Array(numColors) { Paint() }
+
+    init {
+        val selectedColor = Color.WHITE
+        facePositionPaint = Paint()
+        facePositionPaint.color = selectedColor
+        for (i in 0 until numColors) {
+            idPaints[i] = Paint()
+            idPaints[i].color = COLORS[i][0]
+            idPaints[i].textSize = ID_TEXT_SIZE
+            boxPaints[i] = Paint()
+            boxPaints[i].color = COLORS[i][1]
+            boxPaints[i].style = Paint.Style.STROKE
+            boxPaints[i].strokeWidth = BOX_STROKE_WIDTH
+            labelPaints[i] = Paint()
+            labelPaints[i].color = COLORS[i][1]
+            labelPaints[i].style = Paint.Style.FILL
+        }
+    }
+
+    /** Draws the face annotations for position on the supplied canvas.  */
+    override fun draw(canvas: Canvas) {
+        val face = face ?: return
+        // Draws a circle at the position of the detected face, with the face's track id below.
+        val x = translateX(face.boundingBox.centerX().toFloat())
+        val y = translateY(face.boundingBox.centerY().toFloat())
+        canvas.drawCircle(x, y, FACE_POSITION_RADIUS, facePositionPaint)
+
+        // Calculate positions.
+        val left = x - scale(face.boundingBox.width() / 2.0f)
+        val top = y - scale(face.boundingBox.height() / 2.0f)
+        val right = x + scale(face.boundingBox.width() / 2.0f)
+        val bottom = y + scale(face.boundingBox.height() / 2.0f)
+        val lineHeight = ID_TEXT_SIZE + BOX_STROKE_WIDTH
+        var yLabelOffset = -lineHeight
+
+        // Decide color based on face ID
+        val colorID = if (face.trackingId == null) 0 else Math.abs(face.trackingId!! % NUM_COLORS)
+
+        // Calculate width and height of label box
+        var textWidth = idPaints[colorID].measureText("ID: " + face.trackingId)
+        if (face.smilingProbability != null) {
+            yLabelOffset -= lineHeight
+            textWidth =
+                    Math.max(
+                            textWidth,
+                            idPaints[colorID].measureText(
+                                    String.format(
+                                            Locale.US,
+                                            "Happiness: %.2f",
+                                            face.smilingProbability
+                                    )
+                            )
+                    )
+        }
+
+        if (face.leftEyeOpenProbability != null) {
+            yLabelOffset -= lineHeight
+            textWidth =
+                    Math.max(
+                            textWidth,
+                            idPaints[colorID].measureText(
+                                    String.format(
+                                            Locale.US,
+                                            "Left eye: %.2f",
+                                            face.leftEyeOpenProbability
+                                    )
+                            )
+                    )
+        }
+
+        if (face.rightEyeOpenProbability != null) {
+            yLabelOffset -= lineHeight
+            textWidth =
+                    Math.max(
+                            textWidth,
+                            idPaints[colorID].measureText(
+                                    String.format(
+                                            Locale.US,
+                                            "Right eye: %.2f",
+                                            face.leftEyeOpenProbability
+                                    )
+                            )
+                    )
+        }
+
+        // Draw labels
+        canvas.drawRect(
+                left - BOX_STROKE_WIDTH,
+                top + yLabelOffset,
+                left + textWidth + 2 * BOX_STROKE_WIDTH,
+                top,
+                labelPaints[colorID]
+        )
+        yLabelOffset += ID_TEXT_SIZE
+        canvas.drawRect(left, top, right, bottom, boxPaints[colorID])
+        canvas.drawText(
+                "ID: " + face.trackingId, left, top + yLabelOffset,
+                idPaints[colorID]
+        )
+        yLabelOffset += lineHeight
+
+        // Draws all face contours.
+        for (contour in face.allContours) {
+            for (point in contour.points) {
+                canvas.drawCircle(
+                        translateX(point.x),
+                        translateY(point.y),
+                        FACE_POSITION_RADIUS,
+                        facePositionPaint
+                )
+            }
+        }
+
+        // Draws smiling and left/right eye open probabilities.
+        if (face.smilingProbability != null) {
+            canvas.drawText(
+                    "Smiling: " + String.format(Locale.US, "%.2f", face.smilingProbability),
+                    left,
+                    top + yLabelOffset,
+                    idPaints[colorID]
+            )
+            yLabelOffset += lineHeight
+        }
+
+        val leftEye = face.getLandmark(FaceLandmark.LEFT_EYE)
+        if (leftEye != null && face.leftEyeOpenProbability != null) {
+            canvas.drawText(
+                    "Left eye open: " + String.format(Locale.US, "%.2f", face.leftEyeOpenProbability),
+                    translateX(leftEye.position.x) + ID_X_OFFSET,
+                    translateY(leftEye.position.y) + ID_Y_OFFSET,
+                    idPaints[colorID]
+            )
+        } else if (leftEye != null && face.leftEyeOpenProbability == null) {
+            canvas.drawText(
+                    "Left eye",
+                    left,
+                    top + yLabelOffset,
+                    idPaints[colorID]
+            )
+            yLabelOffset += lineHeight
+        } else if (leftEye == null && face.leftEyeOpenProbability != null) {
+            canvas.drawText(
+                    "Left eye open: " + String.format(Locale.US, "%.2f", face.leftEyeOpenProbability),
+                    left,
+                    top + yLabelOffset,
+                    idPaints[colorID]
+            )
+            yLabelOffset += lineHeight
+        }
+        val rightEye = face.getLandmark(FaceLandmark.RIGHT_EYE)
+        if (rightEye != null && face.rightEyeOpenProbability != null) {
+            canvas.drawText(
+                    "Right eye open: " + String.format(Locale.US, "%.2f", face.rightEyeOpenProbability),
+                    translateX(rightEye.position.x) + ID_X_OFFSET,
+                    translateY(rightEye.position.y) + ID_Y_OFFSET,
+                    idPaints[colorID]
+            )
+        } else if (rightEye != null && face.rightEyeOpenProbability == null) {
+            canvas.drawText(
+                    "Right eye",
+                    left,
+                    top + yLabelOffset,
+                    idPaints[colorID]
+            )
+            yLabelOffset += lineHeight
+        } else if (rightEye == null && face.rightEyeOpenProbability != null) {
+            canvas.drawText(
+                    "Right eye open: " + String.format(Locale.US, "%.2f", face.rightEyeOpenProbability),
+                    left,
+                    top + yLabelOffset,
+                    idPaints[colorID]
+            )
+        }
+
+        // Draw facial landmarks
+        drawFaceLandmark(canvas, FaceLandmark.LEFT_EYE)
+        drawFaceLandmark(canvas, FaceLandmark.RIGHT_EYE)
+        drawFaceLandmark(canvas, FaceLandmark.LEFT_CHEEK)
+        drawFaceLandmark(canvas, FaceLandmark.RIGHT_CHEEK)
+    }
+
+    private fun drawFaceLandmark(canvas: Canvas, @LandmarkType landmarkType: Int) {
+        val faceLandmark = face.getLandmark(landmarkType)
+        if (faceLandmark != null) {
+            canvas.drawCircle(
+                    translateX(faceLandmark.position.x),
+                    translateY(faceLandmark.position.y),
+                    FACE_POSITION_RADIUS,
+                    facePositionPaint
+            )
+        }
+    }
+
+    companion object {
+        private const val FACE_POSITION_RADIUS = 4.0f
+        private const val ID_TEXT_SIZE = 30.0f
+        private const val ID_Y_OFFSET = 40.0f
+        private const val ID_X_OFFSET = -40.0f
+        private const val BOX_STROKE_WIDTH = 5.0f
+        private const val NUM_COLORS = 10
+        private val COLORS =
+                arrayOf(
+                        intArrayOf(Color.BLACK, Color.WHITE),
+                        intArrayOf(Color.WHITE, Color.MAGENTA),
+                        intArrayOf(Color.BLACK, Color.LTGRAY),
+                        intArrayOf(Color.WHITE, Color.RED),
+                        intArrayOf(Color.WHITE, Color.BLUE),
+                        intArrayOf(Color.WHITE, Color.DKGRAY),
+                        intArrayOf(Color.BLACK, Color.CYAN),
+                        intArrayOf(Color.BLACK, Color.YELLOW),
+                        intArrayOf(Color.WHITE, Color.BLACK),
+                        intArrayOf(Color.BLACK, Color.GREEN)
+                )
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/labeldetector/LabelDetectorProcessor.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/labeldetector/LabelDetectorProcessor.kt
index eb5b7d5..e9d5816 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/labeldetector/LabelDetectorProcessor.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/labeldetector/LabelDetectorProcessor.kt
@@ -1,79 +1,79 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.labeldetector
-
-import android.content.Context
-import android.util.Log
-import com.google.android.gms.tasks.Task
-import com.google.mlkit.vision.common.InputImage
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
-import com.google.mlkit.vision.demo.labeldetector.LabelGraphic
-import com.google.mlkit.vision.label.ImageLabel
-import com.google.mlkit.vision.label.ImageLabeler
-import com.google.mlkit.vision.label.ImageLabelerOptionsBase
-import com.google.mlkit.vision.label.ImageLabeling
-import java.io.IOException
-
-/** Custom InputImage Classifier Demo.  */
-class LabelDetectorProcessor(context: Context, options: ImageLabelerOptionsBase) :
-        VisionProcessorBase<List<ImageLabel>>(context) {
-
-    private val imageLabeler: ImageLabeler = ImageLabeling.getClient(options)
-
-    override fun stop() {
-        super.stop()
-        try {
-            imageLabeler.close()
-        } catch (e: IOException) {
-            Log.e(
-                    TAG,
-                    "Exception thrown while trying to close ImageLabelerClient: $e"
-            )
-        }
-    }
-
-    override fun detectInImage(image: InputImage): Task<List<ImageLabel>> {
-        return imageLabeler.process(image)
-    }
-
-    override fun onSuccess(labels: List<ImageLabel>, graphicOverlay: GraphicOverlay) {
-        graphicOverlay.add(LabelGraphic(graphicOverlay, labels))
-        logExtrasForTesting(labels)
-    }
-
-    override fun onFailure(e: Exception) {
-        Log.w(TAG, "Label detection failed.$e")
-    }
-
-    companion object {
-        private const val TAG = "LabelDetectorProcessor"
-
-        private fun logExtrasForTesting(labels: List<ImageLabel>?) {
-            if (labels == null) {
-                Log.v(MANUAL_TESTING_LOG, "No labels detected")
-            } else {
-                for (label in labels) {
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            String.format("Label %s, confidence %f", label.text, label.confidence)
-                    )
-                }
-            }
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.labeldetector
+
+import android.content.Context
+import android.util.Log
+import com.google.android.gms.tasks.Task
+import com.google.mlkit.vision.common.InputImage
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
+import com.google.mlkit.vision.demo.labeldetector.LabelGraphic
+import com.google.mlkit.vision.label.ImageLabel
+import com.google.mlkit.vision.label.ImageLabeler
+import com.google.mlkit.vision.label.ImageLabelerOptionsBase
+import com.google.mlkit.vision.label.ImageLabeling
+import java.io.IOException
+
+/** Custom InputImage Classifier Demo.  */
+class LabelDetectorProcessor(context: Context, options: ImageLabelerOptionsBase) :
+        VisionProcessorBase<List<ImageLabel>>(context) {
+
+    private val imageLabeler: ImageLabeler = ImageLabeling.getClient(options)
+
+    override fun stop() {
+        super.stop()
+        try {
+            imageLabeler.close()
+        } catch (e: IOException) {
+            Log.e(
+                    TAG,
+                    "Exception thrown while trying to close ImageLabelerClient: $e"
+            )
+        }
+    }
+
+    override fun detectInImage(image: InputImage): Task<List<ImageLabel>> {
+        return imageLabeler.process(image)
+    }
+
+    override fun onSuccess(labels: List<ImageLabel>, graphicOverlay: GraphicOverlay) {
+        graphicOverlay.add(LabelGraphic(graphicOverlay, labels))
+        logExtrasForTesting(labels)
+    }
+
+    override fun onFailure(e: Exception) {
+        Log.w(TAG, "Label detection failed.$e")
+    }
+
+    companion object {
+        private const val TAG = "LabelDetectorProcessor"
+
+        private fun logExtrasForTesting(labels: List<ImageLabel>?) {
+            if (labels == null) {
+                Log.v(MANUAL_TESTING_LOG, "No labels detected")
+            } else {
+                for (label in labels) {
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            String.format("Label %s, confidence %f", label.text, label.confidence)
+                    )
+                }
+            }
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/labeldetector/LabelGraphic.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/labeldetector/LabelGraphic.kt
index bbd3f1c..c4690ac 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/labeldetector/LabelGraphic.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/labeldetector/LabelGraphic.kt
@@ -1,101 +1,101 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.labeldetector
-
-import android.graphics.Canvas
-import android.graphics.Color
-import android.graphics.Paint
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
-import com.google.mlkit.vision.label.ImageLabel
-import java.util.Locale
-
-/** Graphic instance for rendering a label within an associated graphic overlay view.  */
-class LabelGraphic(
-        private val overlay: GraphicOverlay,
-        private val labels: List<ImageLabel>
-) : Graphic(overlay) {
-    private val textPaint: Paint = Paint()
-    private val labelPaint: Paint
-
-    init {
-        textPaint.color = Color.WHITE
-        textPaint.textSize = TEXT_SIZE
-        labelPaint = Paint()
-        labelPaint.color = Color.BLACK
-        labelPaint.style = Paint.Style.FILL
-        labelPaint.alpha = 200
-    }
-
-    @Synchronized
-    override fun draw(canvas: Canvas) {
-        // First try to find maxWidth and totalHeight in order to draw to the center of the screen.
-        var maxWidth = 0f
-        val totalHeight = labels.size * 2 * TEXT_SIZE
-        for (label in labels) {
-            val line1Width = textPaint.measureText(label.text)
-            val line2Width =
-                    textPaint.measureText(
-                            String.format(
-                                    Locale.US,
-                                    LABEL_FORMAT,
-                                    label.confidence * 100,
-                                    label.index
-                            )
-                    )
-
-            maxWidth = Math.max(maxWidth, Math.max(line1Width, line2Width))
-        }
-
-        val x = Math.max(0f, overlay.width / 2.0f - maxWidth / 2.0f)
-        var y = Math.max(200f, overlay.height / 2.0f - totalHeight / 2.0f)
-
-        if (!labels.isEmpty()) {
-            val padding = 20f
-            canvas.drawRect(
-                    x - padding,
-                    y - padding,
-                    x + maxWidth + padding,
-                    y + totalHeight + padding,
-                    labelPaint
-            )
-        }
-
-        for (label in labels) {
-            if (y + TEXT_SIZE * 2 > overlay.height) {
-                break
-            }
-            canvas.drawText(label.text, x, y + TEXT_SIZE, textPaint)
-            y += TEXT_SIZE
-            canvas.drawText(
-                    String.format(
-                            Locale.US,
-                            LABEL_FORMAT,
-                            label.confidence * 100,
-                            label.index
-                    ),
-                    x, y + TEXT_SIZE, textPaint
-            )
-            y += TEXT_SIZE
-        }
-    }
-
-    companion object {
-        private const val TEXT_SIZE = 70.0f
-        private const val LABEL_FORMAT = "%.2f%% confidence (index: %d)"
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.labeldetector
+
+import android.graphics.Canvas
+import android.graphics.Color
+import android.graphics.Paint
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
+import com.google.mlkit.vision.label.ImageLabel
+import java.util.Locale
+
+/** Graphic instance for rendering a label within an associated graphic overlay view.  */
+class LabelGraphic(
+        private val overlay: GraphicOverlay,
+        private val labels: List<ImageLabel>
+) : Graphic(overlay) {
+    private val textPaint: Paint = Paint()
+    private val labelPaint: Paint
+
+    init {
+        textPaint.color = Color.WHITE
+        textPaint.textSize = TEXT_SIZE
+        labelPaint = Paint()
+        labelPaint.color = Color.BLACK
+        labelPaint.style = Paint.Style.FILL
+        labelPaint.alpha = 200
+    }
+
+    @Synchronized
+    override fun draw(canvas: Canvas) {
+        // First try to find maxWidth and totalHeight in order to draw to the center of the screen.
+        var maxWidth = 0f
+        val totalHeight = labels.size * 2 * TEXT_SIZE
+        for (label in labels) {
+            val line1Width = textPaint.measureText(label.text)
+            val line2Width =
+                    textPaint.measureText(
+                            String.format(
+                                    Locale.US,
+                                    LABEL_FORMAT,
+                                    label.confidence * 100,
+                                    label.index
+                            )
+                    )
+
+            maxWidth = Math.max(maxWidth, Math.max(line1Width, line2Width))
+        }
+
+        val x = Math.max(0f, overlay.width / 2.0f - maxWidth / 2.0f)
+        var y = Math.max(200f, overlay.height / 2.0f - totalHeight / 2.0f)
+
+        if (!labels.isEmpty()) {
+            val padding = 20f
+            canvas.drawRect(
+                    x - padding,
+                    y - padding,
+                    x + maxWidth + padding,
+                    y + totalHeight + padding,
+                    labelPaint
+            )
+        }
+
+        for (label in labels) {
+            if (y + TEXT_SIZE * 2 > overlay.height) {
+                break
+            }
+            canvas.drawText(label.text, x, y + TEXT_SIZE, textPaint)
+            y += TEXT_SIZE
+            canvas.drawText(
+                    String.format(
+                            Locale.US,
+                            LABEL_FORMAT,
+                            label.confidence * 100,
+                            label.index
+                    ),
+                    x, y + TEXT_SIZE, textPaint
+            )
+            y += TEXT_SIZE
+        }
+    }
+
+    companion object {
+        private const val TEXT_SIZE = 70.0f
+        private const val LABEL_FORMAT = "%.2f%% confidence (index: %d)"
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/objectdetector/ObjectDetectorProcessor.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/objectdetector/ObjectDetectorProcessor.kt
index c4ef965..19dec0b 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/objectdetector/ObjectDetectorProcessor.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/objectdetector/ObjectDetectorProcessor.kt
@@ -1,67 +1,67 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.objectdetector
-
-import android.content.Context
-import android.util.Log
-import com.google.android.gms.tasks.Task
-import com.google.mlkit.vision.common.InputImage
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
-import com.google.mlkit.vision.objects.DetectedObject
-import com.google.mlkit.vision.objects.ObjectDetection
-import com.google.mlkit.vision.objects.ObjectDetector
-import com.google.mlkit.vision.objects.ObjectDetectorOptionsBase
-import java.io.IOException
-
-/** A processor to run object detector.  */
-class ObjectDetectorProcessor(context: Context, options: ObjectDetectorOptionsBase) :
-        VisionProcessorBase<List<DetectedObject>>(context) {
-
-    private val detector: ObjectDetector = ObjectDetection.getClient(options)
-
-    override fun stop() {
-        super.stop()
-        try {
-            detector.close()
-        } catch (e: IOException) {
-            Log.e(
-                    TAG,
-                    "Exception thrown while trying to close object detector!",
-                    e
-            )
-        }
-    }
-
-    override fun detectInImage(image: InputImage): Task<List<DetectedObject>> {
-        return detector.process(image)
-    }
-
-    override fun onSuccess(results: List<DetectedObject>, graphicOverlay: GraphicOverlay) {
-        for (result in results) {
-            graphicOverlay.add(ObjectGraphic(graphicOverlay, result))
-        }
-    }
-
-    override fun onFailure(e: Exception) {
-        Log.e(TAG, "Object detection failed!", e)
-    }
-
-    companion object {
-        private const val TAG = "ObjectDetectorProcessor"
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.objectdetector
+
+import android.content.Context
+import android.util.Log
+import com.google.android.gms.tasks.Task
+import com.google.mlkit.vision.common.InputImage
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
+import com.google.mlkit.vision.objects.DetectedObject
+import com.google.mlkit.vision.objects.ObjectDetection
+import com.google.mlkit.vision.objects.ObjectDetector
+import com.google.mlkit.vision.objects.ObjectDetectorOptionsBase
+import java.io.IOException
+
+/** A processor to run object detector.  */
+class ObjectDetectorProcessor(context: Context, options: ObjectDetectorOptionsBase) :
+        VisionProcessorBase<List<DetectedObject>>(context) {
+
+    private val detector: ObjectDetector = ObjectDetection.getClient(options)
+
+    override fun stop() {
+        super.stop()
+        try {
+            detector.close()
+        } catch (e: IOException) {
+            Log.e(
+                    TAG,
+                    "Exception thrown while trying to close object detector!",
+                    e
+            )
+        }
+    }
+
+    override fun detectInImage(image: InputImage): Task<List<DetectedObject>> {
+        return detector.process(image)
+    }
+
+    override fun onSuccess(results: List<DetectedObject>, graphicOverlay: GraphicOverlay) {
+        for (result in results) {
+            graphicOverlay.add(ObjectGraphic(graphicOverlay, result))
+        }
+    }
+
+    override fun onFailure(e: Exception) {
+        Log.e(TAG, "Object detection failed!", e)
+    }
+
+    companion object {
+        private const val TAG = "ObjectDetectorProcessor"
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/objectdetector/ObjectGraphic.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/objectdetector/ObjectGraphic.kt
index 57ba091..9093eb2 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/objectdetector/ObjectGraphic.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/objectdetector/ObjectGraphic.kt
@@ -1,150 +1,150 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.objectdetector
-
-import android.graphics.Canvas
-import android.graphics.Color
-import android.graphics.Paint
-import android.graphics.RectF
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
-import com.google.mlkit.vision.objects.DetectedObject
-import java.util.Locale
-
-/** Draw the detected object info in preview.  */
-class ObjectGraphic constructor(
-        overlay: GraphicOverlay?,
-        private val detectedObject: DetectedObject
-) : Graphic(overlay) {
-
-    private val numColors = COLORS.size
-
-    private val boxPaints = Array(numColors) { Paint() }
-    private val textPaints = Array(numColors) { Paint() }
-    private val labelPaints = Array(numColors) { Paint() }
-
-    init {
-        for (i in 0 until numColors) {
-            textPaints[i] = Paint()
-            textPaints[i].color = COLORS[i][0]
-            textPaints[i].textSize = TEXT_SIZE
-            boxPaints[i] = Paint()
-            boxPaints[i].color = COLORS[i][1]
-            boxPaints[i].style = Paint.Style.STROKE
-            boxPaints[i].strokeWidth = STROKE_WIDTH
-            labelPaints[i] = Paint()
-            labelPaints[i].color = COLORS[i][1]
-            labelPaints[i].style = Paint.Style.FILL
-        }
-    }
-
-    override fun draw(canvas: Canvas) {
-        // Decide color based on object tracking ID
-        val colorID =
-                if (detectedObject.trackingId == null) 0
-                else Math.abs(detectedObject.trackingId!! % NUM_COLORS)
-        var textWidth =
-                textPaints[colorID].measureText("Tracking ID: " + detectedObject.trackingId)
-        val lineHeight = TEXT_SIZE + STROKE_WIDTH
-        var yLabelOffset = -lineHeight
-
-        // Calculate width and height of label box
-        for (label in detectedObject.labels) {
-            textWidth =
-                    Math.max(textWidth, textPaints[colorID].measureText(label.text))
-            textWidth = Math.max(
-                    textWidth,
-                    textPaints[colorID].measureText(
-                            String.format(
-                                    Locale.US,
-                                    LABEL_FORMAT,
-                                    label.confidence * 100,
-                                    label.index
-                            )
-                    )
-            )
-            yLabelOffset -= 2 * lineHeight
-        }
-
-        // Draws the bounding box.
-        val rect = RectF(detectedObject.boundingBox)
-        rect.left = translateX(rect.left)
-        rect.top = translateY(rect.top)
-        rect.right = translateX(rect.right)
-        rect.bottom = translateY(rect.bottom)
-        canvas.drawRect(rect, boxPaints[colorID])
-
-        // Draws other object info.
-        val left = if (isImageFlipped) rect.right else rect.left
-        canvas.drawRect(
-                left - STROKE_WIDTH,
-                rect.top + yLabelOffset,
-                left + textWidth + 2 * STROKE_WIDTH,
-                rect.top,
-                labelPaints[colorID]
-        )
-        yLabelOffset += TEXT_SIZE
-        canvas.drawText(
-                "Tracking ID: " + detectedObject.trackingId,
-                left,
-                rect.top + yLabelOffset,
-                textPaints[colorID]
-        )
-        yLabelOffset += lineHeight
-        for (label in detectedObject.labels) {
-            canvas.drawText(
-                    label.text + " (index: " + label.index + ")",
-                    left,
-                    rect.top + yLabelOffset,
-                    textPaints[colorID]
-            )
-            yLabelOffset += lineHeight
-            canvas.drawText(
-                    String.format(
-                            Locale.US,
-                            LABEL_FORMAT,
-                            label.confidence * 100,
-                            label.index
-                    ),
-                    left,
-                    rect.top + yLabelOffset,
-                    textPaints[colorID]
-            )
-            yLabelOffset += lineHeight
-        }
-    }
-
-    companion object {
-        private const val TEXT_SIZE = 54.0f
-        private const val STROKE_WIDTH = 4.0f
-        private const val NUM_COLORS = 10
-        private val COLORS =
-                arrayOf(
-                        intArrayOf(Color.BLACK, Color.WHITE),
-                        intArrayOf(Color.WHITE, Color.MAGENTA),
-                        intArrayOf(Color.BLACK, Color.LTGRAY),
-                        intArrayOf(Color.WHITE, Color.RED),
-                        intArrayOf(Color.WHITE, Color.BLUE),
-                        intArrayOf(Color.WHITE, Color.DKGRAY),
-                        intArrayOf(Color.BLACK, Color.CYAN),
-                        intArrayOf(Color.BLACK, Color.YELLOW),
-                        intArrayOf(Color.WHITE, Color.BLACK),
-                        intArrayOf(Color.BLACK, Color.GREEN)
-                )
-        private const val LABEL_FORMAT = "%.2f%% confidence (index: %d)"
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.objectdetector
+
+import android.graphics.Canvas
+import android.graphics.Color
+import android.graphics.Paint
+import android.graphics.RectF
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
+import com.google.mlkit.vision.objects.DetectedObject
+import java.util.Locale
+
+/** Draw the detected object info in preview.  */
+class ObjectGraphic constructor(
+        overlay: GraphicOverlay?,
+        private val detectedObject: DetectedObject
+) : Graphic(overlay) {
+
+    private val numColors = COLORS.size
+
+    private val boxPaints = Array(numColors) { Paint() }
+    private val textPaints = Array(numColors) { Paint() }
+    private val labelPaints = Array(numColors) { Paint() }
+
+    init {
+        for (i in 0 until numColors) {
+            textPaints[i] = Paint()
+            textPaints[i].color = COLORS[i][0]
+            textPaints[i].textSize = TEXT_SIZE
+            boxPaints[i] = Paint()
+            boxPaints[i].color = COLORS[i][1]
+            boxPaints[i].style = Paint.Style.STROKE
+            boxPaints[i].strokeWidth = STROKE_WIDTH
+            labelPaints[i] = Paint()
+            labelPaints[i].color = COLORS[i][1]
+            labelPaints[i].style = Paint.Style.FILL
+        }
+    }
+
+    override fun draw(canvas: Canvas) {
+        // Decide color based on object tracking ID
+        val colorID =
+                if (detectedObject.trackingId == null) 0
+                else Math.abs(detectedObject.trackingId!! % NUM_COLORS)
+        var textWidth =
+                textPaints[colorID].measureText("Tracking ID: " + detectedObject.trackingId)
+        val lineHeight = TEXT_SIZE + STROKE_WIDTH
+        var yLabelOffset = -lineHeight
+
+        // Calculate width and height of label box
+        for (label in detectedObject.labels) {
+            textWidth =
+                    Math.max(textWidth, textPaints[colorID].measureText(label.text))
+            textWidth = Math.max(
+                    textWidth,
+                    textPaints[colorID].measureText(
+                            String.format(
+                                    Locale.US,
+                                    LABEL_FORMAT,
+                                    label.confidence * 100,
+                                    label.index
+                            )
+                    )
+            )
+            yLabelOffset -= 2 * lineHeight
+        }
+
+        // Draws the bounding box.
+        val rect = RectF(detectedObject.boundingBox)
+        rect.left = translateX(rect.left)
+        rect.top = translateY(rect.top)
+        rect.right = translateX(rect.right)
+        rect.bottom = translateY(rect.bottom)
+        canvas.drawRect(rect, boxPaints[colorID])
+
+        // Draws other object info.
+        val left = if (isImageFlipped) rect.right else rect.left
+        canvas.drawRect(
+                left - STROKE_WIDTH,
+                rect.top + yLabelOffset,
+                left + textWidth + 2 * STROKE_WIDTH,
+                rect.top,
+                labelPaints[colorID]
+        )
+        yLabelOffset += TEXT_SIZE
+        canvas.drawText(
+                "Tracking ID: " + detectedObject.trackingId,
+                left,
+                rect.top + yLabelOffset,
+                textPaints[colorID]
+        )
+        yLabelOffset += lineHeight
+        for (label in detectedObject.labels) {
+            canvas.drawText(
+                    label.text + " (index: " + label.index + ")",
+                    left,
+                    rect.top + yLabelOffset,
+                    textPaints[colorID]
+            )
+            yLabelOffset += lineHeight
+            canvas.drawText(
+                    String.format(
+                            Locale.US,
+                            LABEL_FORMAT,
+                            label.confidence * 100,
+                            label.index
+                    ),
+                    left,
+                    rect.top + yLabelOffset,
+                    textPaints[colorID]
+            )
+            yLabelOffset += lineHeight
+        }
+    }
+
+    companion object {
+        private const val TEXT_SIZE = 54.0f
+        private const val STROKE_WIDTH = 4.0f
+        private const val NUM_COLORS = 10
+        private val COLORS =
+                arrayOf(
+                        intArrayOf(Color.BLACK, Color.WHITE),
+                        intArrayOf(Color.WHITE, Color.MAGENTA),
+                        intArrayOf(Color.BLACK, Color.LTGRAY),
+                        intArrayOf(Color.WHITE, Color.RED),
+                        intArrayOf(Color.WHITE, Color.BLUE),
+                        intArrayOf(Color.WHITE, Color.DKGRAY),
+                        intArrayOf(Color.BLACK, Color.CYAN),
+                        intArrayOf(Color.BLACK, Color.YELLOW),
+                        intArrayOf(Color.WHITE, Color.BLACK),
+                        intArrayOf(Color.BLACK, Color.GREEN)
+                )
+        private const val LABEL_FORMAT = "%.2f%% confidence (index: %d)"
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/textdetector/TextGraphic.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/textdetector/TextGraphic.kt
index 275170d..bd41692 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/textdetector/TextGraphic.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/textdetector/TextGraphic.kt
@@ -1,128 +1,128 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.textdetector
-
-import android.graphics.Canvas
-import android.graphics.Color
-import android.graphics.Paint
-import android.graphics.RectF
-import android.util.Log
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
-import com.google.mlkit.vision.text.Text
-import java.util.Arrays
-
-/**
- * Graphic instance for rendering TextBlock position, size, and ID within an associated graphic
- * overlay view.
- */
-class TextGraphic constructor(overlay: GraphicOverlay?, private val text: Text) :
-        Graphic(overlay) {
-
-    private val rectPaint: Paint = Paint()
-    private val textPaint: Paint
-    private val labelPaint: Paint
-
-    init {
-        rectPaint.color = MARKER_COLOR
-        rectPaint.style = Paint.Style.STROKE
-        rectPaint.strokeWidth = STROKE_WIDTH
-        textPaint = Paint()
-        textPaint.color = TEXT_COLOR
-        textPaint.textSize = TEXT_SIZE
-        labelPaint = Paint()
-        labelPaint.color = MARKER_COLOR
-        labelPaint.style = Paint.Style.FILL
-        // Redraw the overlay, as this graphic has been added.
-        postInvalidate()
-    }
-
-    /** Draws the text block annotations for position, size, and raw value on the supplied canvas.  */
-    override fun draw(canvas: Canvas) {
-        Log.d(TAG, "Text is: " + text.text)
-        for (textBlock in text.textBlocks) { // Renders the text at the bottom of the box.
-            Log.d(TAG, "TextBlock text is: " + textBlock.text)
-            Log.d(
-                    TAG,
-                    "TextBlock boundingbox is: " + textBlock.boundingBox
-            )
-            Log.d(
-                    TAG,
-                    "TextBlock cornerpoint is: " + Arrays.toString(textBlock.cornerPoints)
-            )
-            for (line in textBlock.lines) {
-                Log.d(TAG, "Line text is: " + line.text)
-                Log.d(
-                        TAG,
-                        "Line boundingbox is: " + line.boundingBox
-                )
-                Log.d(
-                        TAG,
-                        "Line cornerpoint is: " + Arrays.toString(line.cornerPoints)
-                )
-                // Draws the bounding box around the TextBlock.
-                val rect = RectF(line.boundingBox)
-                rect.left = translateX(rect.left)
-                rect.top = translateY(rect.top)
-                rect.right = translateX(rect.right)
-                rect.bottom = translateY(rect.bottom)
-                canvas.drawRect(rect, rectPaint)
-                val lineHeight =
-                        TEXT_SIZE + 2 * STROKE_WIDTH
-                val textWidth = textPaint.measureText(line.text)
-                val left = if (isImageFlipped) rect.right else rect.left
-                canvas.drawRect(
-                        left - STROKE_WIDTH,
-                        rect.top - lineHeight,
-                        left + textWidth + 2 * STROKE_WIDTH,
-                        rect.top,
-                        labelPaint
-                )
-                // Renders the text at the bottom of the box.
-                canvas.drawText(
-                        line.text,
-                        left,
-                        rect.top - STROKE_WIDTH,
-                        textPaint
-                )
-                for (element in line.elements) {
-                    Log.d(TAG, "Element text is: " + element.text)
-                    Log.d(
-                            TAG,
-                            "Element boundingbox is: " + element.boundingBox
-                    )
-                    Log.d(
-                            TAG,
-                            "Element cornerpoint is: " + Arrays.toString(element.cornerPoints)
-                    )
-                    Log.d(
-                            TAG,
-                            "Element language is: " + element.recognizedLanguage
-                    )
-                }
-            }
-        }
-    }
-
-    companion object {
-        private const val TAG = "TextGraphic"
-        private const val TEXT_COLOR = Color.BLACK
-        private const val MARKER_COLOR = Color.WHITE
-        private const val TEXT_SIZE = 54.0f
-        private const val STROKE_WIDTH = 4.0f
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.textdetector
+
+import android.graphics.Canvas
+import android.graphics.Color
+import android.graphics.Paint
+import android.graphics.RectF
+import android.util.Log
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic
+import com.google.mlkit.vision.text.Text
+import java.util.Arrays
+
+/**
+ * Graphic instance for rendering TextBlock position, size, and ID within an associated graphic
+ * overlay view.
+ */
+class TextGraphic constructor(overlay: GraphicOverlay?, private val text: Text) :
+        Graphic(overlay) {
+
+    private val rectPaint: Paint = Paint()
+    private val textPaint: Paint
+    private val labelPaint: Paint
+
+    init {
+        rectPaint.color = MARKER_COLOR
+        rectPaint.style = Paint.Style.STROKE
+        rectPaint.strokeWidth = STROKE_WIDTH
+        textPaint = Paint()
+        textPaint.color = TEXT_COLOR
+        textPaint.textSize = TEXT_SIZE
+        labelPaint = Paint()
+        labelPaint.color = MARKER_COLOR
+        labelPaint.style = Paint.Style.FILL
+        // Redraw the overlay, as this graphic has been added.
+        postInvalidate()
+    }
+
+    /** Draws the text block annotations for position, size, and raw value on the supplied canvas.  */
+    override fun draw(canvas: Canvas) {
+        Log.d(TAG, "Text is: " + text.text)
+        for (textBlock in text.textBlocks) { // Renders the text at the bottom of the box.
+            Log.d(TAG, "TextBlock text is: " + textBlock.text)
+            Log.d(
+                    TAG,
+                    "TextBlock boundingbox is: " + textBlock.boundingBox
+            )
+            Log.d(
+                    TAG,
+                    "TextBlock cornerpoint is: " + Arrays.toString(textBlock.cornerPoints)
+            )
+            for (line in textBlock.lines) {
+                Log.d(TAG, "Line text is: " + line.text)
+                Log.d(
+                        TAG,
+                        "Line boundingbox is: " + line.boundingBox
+                )
+                Log.d(
+                        TAG,
+                        "Line cornerpoint is: " + Arrays.toString(line.cornerPoints)
+                )
+                // Draws the bounding box around the TextBlock.
+                val rect = RectF(line.boundingBox)
+                rect.left = translateX(rect.left)
+                rect.top = translateY(rect.top)
+                rect.right = translateX(rect.right)
+                rect.bottom = translateY(rect.bottom)
+                canvas.drawRect(rect, rectPaint)
+                val lineHeight =
+                        TEXT_SIZE + 2 * STROKE_WIDTH
+                val textWidth = textPaint.measureText(line.text)
+                val left = if (isImageFlipped) rect.right else rect.left
+                canvas.drawRect(
+                        left - STROKE_WIDTH,
+                        rect.top - lineHeight,
+                        left + textWidth + 2 * STROKE_WIDTH,
+                        rect.top,
+                        labelPaint
+                )
+                // Renders the text at the bottom of the box.
+                canvas.drawText(
+                        line.text,
+                        left,
+                        rect.top - STROKE_WIDTH,
+                        textPaint
+                )
+                for (element in line.elements) {
+                    Log.d(TAG, "Element text is: " + element.text)
+                    Log.d(
+                            TAG,
+                            "Element boundingbox is: " + element.boundingBox
+                    )
+                    Log.d(
+                            TAG,
+                            "Element cornerpoint is: " + Arrays.toString(element.cornerPoints)
+                    )
+                    Log.d(
+                            TAG,
+                            "Element language is: " + element.recognizedLanguage
+                    )
+                }
+            }
+        }
+    }
+
+    companion object {
+        private const val TAG = "TextGraphic"
+        private const val TEXT_COLOR = Color.BLACK
+        private const val MARKER_COLOR = Color.WHITE
+        private const val TEXT_SIZE = 54.0f
+        private const val STROKE_WIDTH = 4.0f
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/textdetector/TextRecognitionProcessor.kt b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/textdetector/TextRecognitionProcessor.kt
index 51c913a..bf2beb7 100644
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/textdetector/TextRecognitionProcessor.kt
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/kotlin/textdetector/TextRecognitionProcessor.kt
@@ -1,107 +1,107 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.kotlin.textdetector
-
-import android.content.Context
-import android.util.Log
-import com.google.android.gms.tasks.Task
-import com.google.mlkit.vision.common.InputImage
-import com.google.mlkit.vision.demo.GraphicOverlay
-import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
-import com.google.mlkit.vision.text.Text
-import com.google.mlkit.vision.text.TextRecognition
-import com.google.mlkit.vision.text.TextRecognizer
-
-/** Processor for the text detector demo.  */
-class TextRecognitionProcessor(context: Context) : VisionProcessorBase<Text>(context) {
-    private val textRecognizer: TextRecognizer = TextRecognition.getClient()
-
-    override fun stop() {
-        super.stop()
-        textRecognizer.close()
-    }
-
-    override fun detectInImage(image: InputImage): Task<Text> {
-        return textRecognizer.process(image)
-    }
-
-    override fun onSuccess(text: Text, graphicOverlay: GraphicOverlay) {
-        Log.d(TAG, "On-device Text detection successful")
-        logExtrasForTesting(text)
-        graphicOverlay.add(TextGraphic(graphicOverlay, text))
-    }
-
-    override fun onFailure(e: Exception) {
-        Log.w(TAG, "Text detection failed.$e")
-    }
-
-    companion object {
-        private const val TAG = "TextRecProcessor"
-        private fun logExtrasForTesting(text: Text?) {
-            if (text != null) {
-                Log.v(
-                        MANUAL_TESTING_LOG,
-                        "Detected text has : " + text.textBlocks.size + " blocks"
-                )
-                for (i in text.textBlocks.indices) {
-                    val lines = text.textBlocks[i].lines
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            String.format("Detected text block %d has %d lines", i, lines.size)
-                    )
-                    for (j in lines.indices) {
-                        val elements =
-                                lines[j].elements
-                        Log.v(
-                                MANUAL_TESTING_LOG,
-                                String.format("Detected text line %d has %d elements", j, elements.size)
-                        )
-                        for (k in elements.indices) {
-                            val element = elements[k]
-                            Log.v(
-                                    MANUAL_TESTING_LOG,
-                                    String.format("Detected text element %d says: %s", k, element.text)
-                            )
-                            Log.v(
-                                    MANUAL_TESTING_LOG,
-                                    String.format(
-                                            "Detected text element %d has a bounding box: %s",
-                                            k, element.boundingBox!!.flattenToString()
-                                    )
-                            )
-                            Log.v(
-                                    MANUAL_TESTING_LOG,
-                                    String.format(
-                                            "Expected corner point size is 4, get %d", element.cornerPoints!!.size
-                                    )
-                            )
-                            for (point in element.cornerPoints!!) {
-                                Log.v(
-                                        MANUAL_TESTING_LOG,
-                                        String.format(
-                                                "Corner point for element %d is located at: x - %d, y = %d",
-                                                k, point.x, point.y
-                                        )
-                                )
-                            }
-                        }
-                    }
-                }
-            }
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.kotlin.textdetector
+
+import android.content.Context
+import android.util.Log
+import com.google.android.gms.tasks.Task
+import com.google.mlkit.vision.common.InputImage
+import com.google.mlkit.vision.demo.GraphicOverlay
+import com.google.mlkit.vision.demo.kotlin.VisionProcessorBase
+import com.google.mlkit.vision.text.Text
+import com.google.mlkit.vision.text.TextRecognition
+import com.google.mlkit.vision.text.TextRecognizer
+
+/** Processor for the text detector demo.  */
+class TextRecognitionProcessor(context: Context) : VisionProcessorBase<Text>(context) {
+    private val textRecognizer: TextRecognizer = TextRecognition.getClient()
+
+    override fun stop() {
+        super.stop()
+        textRecognizer.close()
+    }
+
+    override fun detectInImage(image: InputImage): Task<Text> {
+        return textRecognizer.process(image)
+    }
+
+    override fun onSuccess(text: Text, graphicOverlay: GraphicOverlay) {
+        Log.d(TAG, "On-device Text detection successful")
+        logExtrasForTesting(text)
+        graphicOverlay.add(TextGraphic(graphicOverlay, text))
+    }
+
+    override fun onFailure(e: Exception) {
+        Log.w(TAG, "Text detection failed.$e")
+    }
+
+    companion object {
+        private const val TAG = "TextRecProcessor"
+        private fun logExtrasForTesting(text: Text?) {
+            if (text != null) {
+                Log.v(
+                        MANUAL_TESTING_LOG,
+                        "Detected text has : " + text.textBlocks.size + " blocks"
+                )
+                for (i in text.textBlocks.indices) {
+                    val lines = text.textBlocks[i].lines
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            String.format("Detected text block %d has %d lines", i, lines.size)
+                    )
+                    for (j in lines.indices) {
+                        val elements =
+                                lines[j].elements
+                        Log.v(
+                                MANUAL_TESTING_LOG,
+                                String.format("Detected text line %d has %d elements", j, elements.size)
+                        )
+                        for (k in elements.indices) {
+                            val element = elements[k]
+                            Log.v(
+                                    MANUAL_TESTING_LOG,
+                                    String.format("Detected text element %d says: %s", k, element.text)
+                            )
+                            Log.v(
+                                    MANUAL_TESTING_LOG,
+                                    String.format(
+                                            "Detected text element %d has a bounding box: %s",
+                                            k, element.boundingBox!!.flattenToString()
+                                    )
+                            )
+                            Log.v(
+                                    MANUAL_TESTING_LOG,
+                                    String.format(
+                                            "Expected corner point size is 4, get %d", element.cornerPoints!!.size
+                                    )
+                            )
+                            for (point in element.cornerPoints!!) {
+                                Log.v(
+                                        MANUAL_TESTING_LOG,
+                                        String.format(
+                                                "Corner point for element %d is located at: x - %d, y = %d",
+                                                k, point.x, point.y
+                                        )
+                                )
+                            }
+                        }
+                    }
+                }
+            }
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/labeldetector/LabelDetectorProcessor.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/labeldetector/LabelDetectorProcessor.java
index e718448..3d1b275 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/labeldetector/LabelDetectorProcessor.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/labeldetector/LabelDetectorProcessor.java
@@ -1,89 +1,89 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.labeldetector;
-
-import android.content.Context;
-import android.util.Log;
-
-import androidx.annotation.NonNull;
-
-import com.google.android.gms.tasks.Task;
-import com.google.mlkit.vision.common.InputImage;
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.demo.VisionProcessorBase;
-import com.google.mlkit.vision.label.ImageLabel;
-import com.google.mlkit.vision.label.ImageLabeler;
-import com.google.mlkit.vision.label.ImageLabelerOptionsBase;
-import com.google.mlkit.vision.label.ImageLabeling;
-
-import java.io.IOException;
-import java.util.List;
-
-/**
- * Custom InputImage Classifier Demo.
- */
-public class LabelDetectorProcessor extends VisionProcessorBase<List<ImageLabel>> {
-
-    private static final String TAG = "LabelDetectorProcessor";
-
-    private final ImageLabeler imageLabeler;
-
-    public LabelDetectorProcessor(Context context, ImageLabelerOptionsBase options) {
-        super(context);
-        imageLabeler = ImageLabeling.getClient(options);
-    }
-
-    @Override
-    public void stop() {
-        super.stop();
-        try {
-            imageLabeler.close();
-        } catch (IOException e) {
-            Log.e(TAG, "Exception thrown while trying to close ImageLabelerClient: " + e);
-        }
-    }
-
-    @Override
-    protected Task<List<ImageLabel>> detectInImage(InputImage image) {
-        return imageLabeler.process(image);
-    }
-
-    @Override
-    protected void onSuccess(
-            @NonNull List<ImageLabel> labels, @NonNull GraphicOverlay graphicOverlay) {
-        graphicOverlay.add(new LabelGraphic(graphicOverlay, labels));
-        logExtrasForTesting(labels);
-    }
-
-    private static void logExtrasForTesting(List<ImageLabel> labels) {
-        if (labels == null) {
-            Log.v(MANUAL_TESTING_LOG, "No labels detected");
-        } else {
-            for (ImageLabel label : labels) {
-                Log.v(
-                        MANUAL_TESTING_LOG,
-                        String.format("Label %s, confidence %f", label.getText(), label.getConfidence()));
-            }
-        }
-    }
-
-    @Override
-    protected void onFailure(@NonNull Exception e) {
-        Log.w(TAG, "Label detection failed." + e);
-    }
-}
-
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.labeldetector;
+
+import android.content.Context;
+import android.util.Log;
+
+import androidx.annotation.NonNull;
+
+import com.google.android.gms.tasks.Task;
+import com.google.mlkit.vision.common.InputImage;
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.demo.VisionProcessorBase;
+import com.google.mlkit.vision.label.ImageLabel;
+import com.google.mlkit.vision.label.ImageLabeler;
+import com.google.mlkit.vision.label.ImageLabelerOptionsBase;
+import com.google.mlkit.vision.label.ImageLabeling;
+
+import java.io.IOException;
+import java.util.List;
+
+/**
+ * Custom InputImage Classifier Demo.
+ */
+public class LabelDetectorProcessor extends VisionProcessorBase<List<ImageLabel>> {
+
+    private static final String TAG = "LabelDetectorProcessor";
+
+    private final ImageLabeler imageLabeler;
+
+    public LabelDetectorProcessor(Context context, ImageLabelerOptionsBase options) {
+        super(context);
+        imageLabeler = ImageLabeling.getClient(options);
+    }
+
+    @Override
+    public void stop() {
+        super.stop();
+        try {
+            imageLabeler.close();
+        } catch (IOException e) {
+            Log.e(TAG, "Exception thrown while trying to close ImageLabelerClient: " + e);
+        }
+    }
+
+    @Override
+    protected Task<List<ImageLabel>> detectInImage(InputImage image) {
+        return imageLabeler.process(image);
+    }
+
+    @Override
+    protected void onSuccess(
+            @NonNull List<ImageLabel> labels, @NonNull GraphicOverlay graphicOverlay) {
+        graphicOverlay.add(new LabelGraphic(graphicOverlay, labels));
+        logExtrasForTesting(labels);
+    }
+
+    private static void logExtrasForTesting(List<ImageLabel> labels) {
+        if (labels == null) {
+            Log.v(MANUAL_TESTING_LOG, "No labels detected");
+        } else {
+            for (ImageLabel label : labels) {
+                Log.v(
+                        MANUAL_TESTING_LOG,
+                        String.format("Label %s, confidence %f", label.getText(), label.getConfidence()));
+            }
+        }
+    }
+
+    @Override
+    protected void onFailure(@NonNull Exception e) {
+        Log.w(TAG, "Label detection failed." + e);
+    }
+}
+
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/labeldetector/LabelGraphic.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/labeldetector/LabelGraphic.java
index febf1b7..6ec3215 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/labeldetector/LabelGraphic.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/labeldetector/LabelGraphic.java
@@ -1,93 +1,93 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.labeldetector;
-
-import android.graphics.Canvas;
-import android.graphics.Color;
-import android.graphics.Paint;
-
-import com.google.common.primitives.Floats;
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.label.ImageLabel;
-
-import java.util.List;
-import java.util.Locale;
-
-/**
- * Graphic instance for rendering a label within an associated graphic overlay view.
- */
-public class LabelGraphic extends GraphicOverlay.Graphic {
-
-    private static final float TEXT_SIZE = 70.0f;
-    private static final String LABEL_FORMAT = "%.2f%% confidence (index: %d)";
-
-    private final Paint textPaint;
-    private final Paint labelPaint;
-    private final GraphicOverlay overlay;
-
-    private final List<ImageLabel> labels;
-
-    public LabelGraphic(GraphicOverlay overlay, List<ImageLabel> labels) {
-        super(overlay);
-        this.overlay = overlay;
-        this.labels = labels;
-        textPaint = new Paint();
-        textPaint.setColor(Color.WHITE);
-        textPaint.setTextSize(TEXT_SIZE);
-
-        labelPaint = new Paint();
-        labelPaint.setColor(Color.BLACK);
-        labelPaint.setStyle(Paint.Style.FILL);
-        labelPaint.setAlpha(200);
-    }
-
-    @Override
-    public synchronized void draw(Canvas canvas) {
-        // First try to find maxWidth and totalHeight in order to draw to the center of the screen.
-        float maxWidth = 0;
-        float totalHeight = labels.size() * 2 * TEXT_SIZE;
-        for (ImageLabel label : labels) {
-            float line1Width = textPaint.measureText(label.getText());
-            float line2Width = textPaint.measureText(
-                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex()));
-            maxWidth = Floats.max(maxWidth, line1Width, line2Width);
-        }
-        float x = Math.max(0, overlay.getWidth() / 2.0f - maxWidth / 2.0f);
-        float y = Math.max(200, overlay.getHeight() / 2.0f - totalHeight / 2.0f);
-
-        if (!labels.isEmpty()) {
-            float padding = 20;
-            canvas.drawRect(x - padding,
-                    y - padding,
-                    x + maxWidth + padding,
-                    y + totalHeight + padding,
-                    labelPaint);
-        }
-
-        for (ImageLabel label : labels) {
-            if (y + TEXT_SIZE * 2 > overlay.getHeight()) {
-                break;
-            }
-            canvas.drawText(label.getText(), x, y + TEXT_SIZE, textPaint);
-            y += TEXT_SIZE;
-            canvas.drawText(
-                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex()),
-                    x, y + TEXT_SIZE, textPaint);
-            y += TEXT_SIZE;
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.labeldetector;
+
+import android.graphics.Canvas;
+import android.graphics.Color;
+import android.graphics.Paint;
+
+import com.google.common.primitives.Floats;
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.label.ImageLabel;
+
+import java.util.List;
+import java.util.Locale;
+
+/**
+ * Graphic instance for rendering a label within an associated graphic overlay view.
+ */
+public class LabelGraphic extends GraphicOverlay.Graphic {
+
+    private static final float TEXT_SIZE = 70.0f;
+    private static final String LABEL_FORMAT = "%.2f%% confidence (index: %d)";
+
+    private final Paint textPaint;
+    private final Paint labelPaint;
+    private final GraphicOverlay overlay;
+
+    private final List<ImageLabel> labels;
+
+    public LabelGraphic(GraphicOverlay overlay, List<ImageLabel> labels) {
+        super(overlay);
+        this.overlay = overlay;
+        this.labels = labels;
+        textPaint = new Paint();
+        textPaint.setColor(Color.WHITE);
+        textPaint.setTextSize(TEXT_SIZE);
+
+        labelPaint = new Paint();
+        labelPaint.setColor(Color.BLACK);
+        labelPaint.setStyle(Paint.Style.FILL);
+        labelPaint.setAlpha(200);
+    }
+
+    @Override
+    public synchronized void draw(Canvas canvas) {
+        // First try to find maxWidth and totalHeight in order to draw to the center of the screen.
+        float maxWidth = 0;
+        float totalHeight = labels.size() * 2 * TEXT_SIZE;
+        for (ImageLabel label : labels) {
+            float line1Width = textPaint.measureText(label.getText());
+            float line2Width = textPaint.measureText(
+                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex()));
+            maxWidth = Floats.max(maxWidth, line1Width, line2Width);
+        }
+        float x = Math.max(0, overlay.getWidth() / 2.0f - maxWidth / 2.0f);
+        float y = Math.max(200, overlay.getHeight() / 2.0f - totalHeight / 2.0f);
+
+        if (!labels.isEmpty()) {
+            float padding = 20;
+            canvas.drawRect(x - padding,
+                    y - padding,
+                    x + maxWidth + padding,
+                    y + totalHeight + padding,
+                    labelPaint);
+        }
+
+        for (ImageLabel label : labels) {
+            if (y + TEXT_SIZE * 2 > overlay.getHeight()) {
+                break;
+            }
+            canvas.drawText(label.getText(), x, y + TEXT_SIZE, textPaint);
+            y += TEXT_SIZE;
+            canvas.drawText(
+                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex()),
+                    x, y + TEXT_SIZE, textPaint);
+            y += TEXT_SIZE;
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/objectdetector/ObjectDetectorProcessor.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/objectdetector/ObjectDetectorProcessor.java
index 434f648..19d1a77 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/objectdetector/ObjectDetectorProcessor.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/objectdetector/ObjectDetectorProcessor.java
@@ -1,77 +1,77 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.objectdetector;
-
-import android.content.Context;
-import android.util.Log;
-
-import androidx.annotation.NonNull;
-
-import com.google.android.gms.tasks.Task;
-import com.google.mlkit.vision.common.InputImage;
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.demo.VisionProcessorBase;
-import com.google.mlkit.vision.objects.DetectedObject;
-import com.google.mlkit.vision.objects.ObjectDetection;
-import com.google.mlkit.vision.objects.ObjectDetector;
-import com.google.mlkit.vision.objects.ObjectDetectorOptionsBase;
-
-import java.io.IOException;
-import java.util.List;
-
-/**
- * A processor to run object detector.
- */
-public class ObjectDetectorProcessor extends VisionProcessorBase<List<DetectedObject>> {
-
-    private static final String TAG = "ObjectDetectorProcessor";
-
-    private final ObjectDetector detector;
-
-    public ObjectDetectorProcessor(Context context, ObjectDetectorOptionsBase options) {
-        super(context);
-        detector = ObjectDetection.getClient(options);
-    }
-
-    @Override
-    public void stop() {
-        super.stop();
-        try {
-            detector.close();
-        } catch (IOException e) {
-            Log.e(TAG, "Exception thrown while trying to close object detector!", e);
-        }
-    }
-
-    @Override
-    protected Task<List<DetectedObject>> detectInImage(InputImage image) {
-        return detector.process(image);
-    }
-
-    @Override
-    protected void onSuccess(
-            @NonNull List<DetectedObject> results, @NonNull GraphicOverlay graphicOverlay) {
-        for (DetectedObject object : results) {
-            graphicOverlay.add(new ObjectGraphic(graphicOverlay, object));
-        }
-    }
-
-    @Override
-    protected void onFailure(@NonNull Exception e) {
-        Log.e(TAG, "Object detection failed!", e);
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.objectdetector;
+
+import android.content.Context;
+import android.util.Log;
+
+import androidx.annotation.NonNull;
+
+import com.google.android.gms.tasks.Task;
+import com.google.mlkit.vision.common.InputImage;
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.demo.VisionProcessorBase;
+import com.google.mlkit.vision.objects.DetectedObject;
+import com.google.mlkit.vision.objects.ObjectDetection;
+import com.google.mlkit.vision.objects.ObjectDetector;
+import com.google.mlkit.vision.objects.ObjectDetectorOptionsBase;
+
+import java.io.IOException;
+import java.util.List;
+
+/**
+ * A processor to run object detector.
+ */
+public class ObjectDetectorProcessor extends VisionProcessorBase<List<DetectedObject>> {
+
+    private static final String TAG = "ObjectDetectorProcessor";
+
+    private final ObjectDetector detector;
+
+    public ObjectDetectorProcessor(Context context, ObjectDetectorOptionsBase options) {
+        super(context);
+        detector = ObjectDetection.getClient(options);
+    }
+
+    @Override
+    public void stop() {
+        super.stop();
+        try {
+            detector.close();
+        } catch (IOException e) {
+            Log.e(TAG, "Exception thrown while trying to close object detector!", e);
+        }
+    }
+
+    @Override
+    protected Task<List<DetectedObject>> detectInImage(InputImage image) {
+        return detector.process(image);
+    }
+
+    @Override
+    protected void onSuccess(
+            @NonNull List<DetectedObject> results, @NonNull GraphicOverlay graphicOverlay) {
+        for (DetectedObject object : results) {
+            graphicOverlay.add(new ObjectGraphic(graphicOverlay, object));
+        }
+    }
+
+    @Override
+    protected void onFailure(@NonNull Exception e) {
+        Log.e(TAG, "Object detection failed!", e);
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/objectdetector/ObjectGraphic.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/objectdetector/ObjectGraphic.java
index bb02139..33dad53 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/objectdetector/ObjectGraphic.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/objectdetector/ObjectGraphic.java
@@ -1,141 +1,141 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.objectdetector;
-
-import android.graphics.Canvas;
-import android.graphics.Color;
-import android.graphics.Paint;
-import android.graphics.RectF;
-
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic;
-import com.google.mlkit.vision.objects.DetectedObject;
-import com.google.mlkit.vision.objects.DetectedObject.Label;
-
-import java.util.Locale;
-
-/**
- * Draw the detected object info in preview.
- */
-public class ObjectGraphic extends Graphic {
-
-    private static final float TEXT_SIZE = 54.0f;
-    private static final float STROKE_WIDTH = 4.0f;
-    private static final int NUM_COLORS = 10;
-    private static final int[][] COLORS = new int[][]{
-            // {Text color, background color}
-            {Color.BLACK, Color.WHITE},
-            {Color.WHITE, Color.MAGENTA},
-            {Color.BLACK, Color.LTGRAY},
-            {Color.WHITE, Color.RED},
-            {Color.WHITE, Color.BLUE},
-            {Color.WHITE, Color.DKGRAY},
-            {Color.BLACK, Color.CYAN},
-            {Color.BLACK, Color.YELLOW},
-            {Color.WHITE, Color.BLACK},
-            {Color.BLACK, Color.GREEN}
-    };
-    private static final String LABEL_FORMAT = "%.2f%% confidence (index: %d)";
-
-    private final DetectedObject object;
-    private final Paint[] boxPaints;
-    private final Paint[] textPaints;
-    private final Paint[] labelPaints;
-
-    ObjectGraphic(GraphicOverlay overlay, DetectedObject object) {
-        super(overlay);
-
-        this.object = object;
-
-        int numColors = COLORS.length;
-        textPaints = new Paint[numColors];
-        boxPaints = new Paint[numColors];
-        labelPaints = new Paint[numColors];
-        for (int i = 0; i < numColors; i++) {
-            textPaints[i] = new Paint();
-            textPaints[i].setColor(COLORS[i][0] /* text color */);
-            textPaints[i].setTextSize(TEXT_SIZE);
-
-            boxPaints[i] = new Paint();
-            boxPaints[i].setColor(COLORS[i][1] /* background color */);
-            boxPaints[i].setStyle(Paint.Style.STROKE);
-            boxPaints[i].setStrokeWidth(STROKE_WIDTH);
-
-            labelPaints[i] = new Paint();
-            labelPaints[i].setColor(COLORS[i][1] /* background color */);
-            labelPaints[i].setStyle(Paint.Style.FILL);
-        }
-    }
-
-    @Override
-    public void draw(Canvas canvas) {
-        // Decide color based on object tracking ID
-        int colorID = object.getTrackingId() == null
-                ? 0 : Math.abs(object.getTrackingId() % NUM_COLORS);
-        float textWidth = textPaints[colorID].measureText("Tracking ID: " + object.getTrackingId());
-        float lineHeight = TEXT_SIZE + STROKE_WIDTH;
-        float yLabelOffset = -lineHeight;
-
-        // Calculate width and height of label box
-        for (Label label : object.getLabels()) {
-            textWidth = Math.max(textWidth, textPaints[colorID].measureText(label.getText()));
-            textWidth = Math.max(textWidth, textPaints[colorID].measureText(
-                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex())));
-            yLabelOffset -= 2 * lineHeight;
-        }
-
-        // Draws the bounding box.
-        RectF rect = new RectF(object.getBoundingBox());
-        rect.left = translateX(rect.left);
-        rect.top = translateY(rect.top);
-        rect.right = translateX(rect.right);
-        rect.bottom = translateY(rect.bottom);
-        canvas.drawRect(rect, boxPaints[colorID]);
-
-        // Draws other object info.
-        float left = isImageFlipped() ? rect.right : rect.left;
-        canvas.drawRect(
-                left - STROKE_WIDTH,
-                rect.top + yLabelOffset,
-                left + textWidth + (2 * STROKE_WIDTH),
-                rect.top,
-                labelPaints[colorID]);
-        yLabelOffset += TEXT_SIZE;
-        canvas.drawText(
-                "Tracking ID: " + object.getTrackingId(),
-                left,
-                rect.top + yLabelOffset,
-                textPaints[colorID]);
-        yLabelOffset += lineHeight;
-
-        for (Label label : object.getLabels()) {
-            canvas.drawText(
-                    label.getText(),
-                    left,
-                    rect.top + yLabelOffset,
-                    textPaints[colorID]);
-            yLabelOffset += lineHeight;
-            canvas.drawText(
-                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex()),
-                    left,
-                    rect.top + yLabelOffset,
-                    textPaints[colorID]);
-
-            yLabelOffset += lineHeight;
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.objectdetector;
+
+import android.graphics.Canvas;
+import android.graphics.Color;
+import android.graphics.Paint;
+import android.graphics.RectF;
+
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic;
+import com.google.mlkit.vision.objects.DetectedObject;
+import com.google.mlkit.vision.objects.DetectedObject.Label;
+
+import java.util.Locale;
+
+/**
+ * Draw the detected object info in preview.
+ */
+public class ObjectGraphic extends Graphic {
+
+    private static final float TEXT_SIZE = 54.0f;
+    private static final float STROKE_WIDTH = 4.0f;
+    private static final int NUM_COLORS = 10;
+    private static final int[][] COLORS = new int[][]{
+            // {Text color, background color}
+            {Color.BLACK, Color.WHITE},
+            {Color.WHITE, Color.MAGENTA},
+            {Color.BLACK, Color.LTGRAY},
+            {Color.WHITE, Color.RED},
+            {Color.WHITE, Color.BLUE},
+            {Color.WHITE, Color.DKGRAY},
+            {Color.BLACK, Color.CYAN},
+            {Color.BLACK, Color.YELLOW},
+            {Color.WHITE, Color.BLACK},
+            {Color.BLACK, Color.GREEN}
+    };
+    private static final String LABEL_FORMAT = "%.2f%% confidence (index: %d)";
+
+    private final DetectedObject object;
+    private final Paint[] boxPaints;
+    private final Paint[] textPaints;
+    private final Paint[] labelPaints;
+
+    ObjectGraphic(GraphicOverlay overlay, DetectedObject object) {
+        super(overlay);
+
+        this.object = object;
+
+        int numColors = COLORS.length;
+        textPaints = new Paint[numColors];
+        boxPaints = new Paint[numColors];
+        labelPaints = new Paint[numColors];
+        for (int i = 0; i < numColors; i++) {
+            textPaints[i] = new Paint();
+            textPaints[i].setColor(COLORS[i][0] /* text color */);
+            textPaints[i].setTextSize(TEXT_SIZE);
+
+            boxPaints[i] = new Paint();
+            boxPaints[i].setColor(COLORS[i][1] /* background color */);
+            boxPaints[i].setStyle(Paint.Style.STROKE);
+            boxPaints[i].setStrokeWidth(STROKE_WIDTH);
+
+            labelPaints[i] = new Paint();
+            labelPaints[i].setColor(COLORS[i][1] /* background color */);
+            labelPaints[i].setStyle(Paint.Style.FILL);
+        }
+    }
+
+    @Override
+    public void draw(Canvas canvas) {
+        // Decide color based on object tracking ID
+        int colorID = object.getTrackingId() == null
+                ? 0 : Math.abs(object.getTrackingId() % NUM_COLORS);
+        float textWidth = textPaints[colorID].measureText("Tracking ID: " + object.getTrackingId());
+        float lineHeight = TEXT_SIZE + STROKE_WIDTH;
+        float yLabelOffset = -lineHeight;
+
+        // Calculate width and height of label box
+        for (Label label : object.getLabels()) {
+            textWidth = Math.max(textWidth, textPaints[colorID].measureText(label.getText()));
+            textWidth = Math.max(textWidth, textPaints[colorID].measureText(
+                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex())));
+            yLabelOffset -= 2 * lineHeight;
+        }
+
+        // Draws the bounding box.
+        RectF rect = new RectF(object.getBoundingBox());
+        rect.left = translateX(rect.left);
+        rect.top = translateY(rect.top);
+        rect.right = translateX(rect.right);
+        rect.bottom = translateY(rect.bottom);
+        canvas.drawRect(rect, boxPaints[colorID]);
+
+        // Draws other object info.
+        float left = isImageFlipped() ? rect.right : rect.left;
+        canvas.drawRect(
+                left - STROKE_WIDTH,
+                rect.top + yLabelOffset,
+                left + textWidth + (2 * STROKE_WIDTH),
+                rect.top,
+                labelPaints[colorID]);
+        yLabelOffset += TEXT_SIZE;
+        canvas.drawText(
+                "Tracking ID: " + object.getTrackingId(),
+                left,
+                rect.top + yLabelOffset,
+                textPaints[colorID]);
+        yLabelOffset += lineHeight;
+
+        for (Label label : object.getLabels()) {
+            canvas.drawText(
+                    label.getText(),
+                    left,
+                    rect.top + yLabelOffset,
+                    textPaints[colorID]);
+            yLabelOffset += lineHeight;
+            canvas.drawText(
+                    String.format(Locale.US, LABEL_FORMAT, label.getConfidence() * 100, label.getIndex()),
+                    left,
+                    rect.top + yLabelOffset,
+                    textPaints[colorID]);
+
+            yLabelOffset += lineHeight;
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/CameraXLivePreviewPreferenceFragment.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/CameraXLivePreviewPreferenceFragment.java
index 5bfbe61..a3e57fc 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/CameraXLivePreviewPreferenceFragment.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/CameraXLivePreviewPreferenceFragment.java
@@ -1,27 +1,27 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.preference;
-
-/**
- * Configures CameraX live preview demo settings.
- */
-public class CameraXLivePreviewPreferenceFragment extends LivePreviewPreferenceFragment {
-
-    public CameraXLivePreviewPreferenceFragment() {
-        isCameraXSetting = true;
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.preference;
+
+/**
+ * Configures CameraX live preview demo settings.
+ */
+public class CameraXLivePreviewPreferenceFragment extends LivePreviewPreferenceFragment {
+
+    public CameraXLivePreviewPreferenceFragment() {
+        isCameraXSetting = true;
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/LivePreviewPreferenceFragment.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/LivePreviewPreferenceFragment.java
index c99d663..9da242d 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/LivePreviewPreferenceFragment.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/LivePreviewPreferenceFragment.java
@@ -1,208 +1,208 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.preference;
-
-import android.hardware.Camera;
-import android.os.Bundle;
-import android.preference.EditTextPreference;
-import android.preference.ListPreference;
-import android.preference.PreferenceCategory;
-import android.preference.PreferenceFragment;
-import android.widget.Toast;
-
-import androidx.annotation.StringRes;
-
-import com.google.mlkit.vision.demo.CameraSource;
-import com.google.mlkit.vision.demo.CameraSource.SizePair;
-import com.google.mlkit.vision.demo.R;
-
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-/**
- * Configures live preview demo settings.
- */
-public class LivePreviewPreferenceFragment extends PreferenceFragment {
-
-    protected boolean isCameraXSetting;
-
-    @Override
-    public void onCreate(Bundle savedInstanceState) {
-        super.onCreate(savedInstanceState);
-
-        addPreferencesFromResource(R.xml.preference_live_preview);
-        setUpCameraPreferences();
-        setUpFaceDetectionPreferences();
-    }
-
-    private void setUpCameraPreferences() {
-        PreferenceCategory cameraPreference =
-                (PreferenceCategory) findPreference(getString(R.string.pref_category_key_camera));
-
-        if (isCameraXSetting) {
-            cameraPreference.removePreference(
-                    findPreference(getString(R.string.pref_key_rear_camera_preview_size)));
-            cameraPreference.removePreference(
-                    findPreference(getString(R.string.pref_key_front_camera_preview_size)));
-            setUpCameraXTargetAnalysisSizePreference();
-        } else {
-            cameraPreference.removePreference(
-                    findPreference(getString(R.string.pref_key_camerax_target_analysis_size)));
-            setUpCameraPreviewSizePreference(
-                    R.string.pref_key_rear_camera_preview_size,
-                    R.string.pref_key_rear_camera_picture_size,
-                    CameraSource.CAMERA_FACING_BACK);
-            setUpCameraPreviewSizePreference(
-                    R.string.pref_key_front_camera_preview_size,
-                    R.string.pref_key_front_camera_picture_size,
-                    CameraSource.CAMERA_FACING_FRONT);
-        }
-    }
-
-    private void setUpCameraPreviewSizePreference(
-            @StringRes int previewSizePrefKeyId, @StringRes int pictureSizePrefKeyId, int cameraId) {
-        ListPreference previewSizePreference =
-                (ListPreference) findPreference(getString(previewSizePrefKeyId));
-
-        Camera camera = null;
-        try {
-            camera = Camera.open(cameraId);
-
-            List<SizePair> previewSizeList = CameraSource.generateValidPreviewSizeList(camera);
-            String[] previewSizeStringValues = new String[previewSizeList.size()];
-            Map<String, String> previewToPictureSizeStringMap = new HashMap<>();
-            for (int i = 0; i < previewSizeList.size(); i++) {
-                SizePair sizePair = previewSizeList.get(i);
-                previewSizeStringValues[i] = sizePair.preview.toString();
-                if (sizePair.picture != null) {
-                    previewToPictureSizeStringMap.put(
-                            sizePair.preview.toString(), sizePair.picture.toString());
-                }
-            }
-            previewSizePreference.setEntries(previewSizeStringValues);
-            previewSizePreference.setEntryValues(previewSizeStringValues);
-
-            if (previewSizePreference.getEntry() == null) {
-                // First time of opening the Settings page.
-                SizePair sizePair =
-                        CameraSource.selectSizePair(
-                                camera,
-                                CameraSource.DEFAULT_REQUESTED_CAMERA_PREVIEW_WIDTH,
-                                CameraSource.DEFAULT_REQUESTED_CAMERA_PREVIEW_HEIGHT);
-                String previewSizeString = sizePair.preview.toString();
-                previewSizePreference.setValue(previewSizeString);
-                previewSizePreference.setSummary(previewSizeString);
-                PreferenceUtils.saveString(
-                        getActivity(),
-                        pictureSizePrefKeyId,
-                        sizePair.picture != null ? sizePair.picture.toString() : null);
-            } else {
-                previewSizePreference.setSummary(previewSizePreference.getEntry());
-            }
-
-            previewSizePreference.setOnPreferenceChangeListener(
-                    (preference, newValue) -> {
-                        String newPreviewSizeStringValue = (String) newValue;
-                        previewSizePreference.setSummary(newPreviewSizeStringValue);
-                        PreferenceUtils.saveString(
-                                getActivity(),
-                                pictureSizePrefKeyId,
-                                previewToPictureSizeStringMap.get(newPreviewSizeStringValue));
-                        return true;
-                    });
-
-        } catch (Exception e) {
-            // If there's no camera for the given camera id, hide the corresponding preference.
-            ((PreferenceCategory) findPreference(getString(R.string.pref_category_key_camera)))
-                    .removePreference(previewSizePreference);
-        } finally {
-            if (camera != null) {
-                camera.release();
-            }
-        }
-    }
-
-    private void setUpCameraXTargetAnalysisSizePreference() {
-        ListPreference pref =
-                (ListPreference) findPreference(getString(R.string.pref_key_camerax_target_analysis_size));
-        String[] entries = new String[]{
-                "2000x2000",
-                "1600x1600",
-                "1200x1200",
-                "1000x1000",
-                "800x800",
-                "600x600",
-                "400x400",
-                "200x200",
-                "100x100",
-        };
-        pref.setEntries(entries);
-        pref.setEntryValues(entries);
-        pref.setSummary(pref.getEntry() == null ? "Default" : pref.getEntry());
-        pref.setOnPreferenceChangeListener(
-                (preference, newValue) -> {
-                    String newStringValue = (String) newValue;
-                    pref.setSummary(newStringValue);
-                    PreferenceUtils.saveString(
-                            getActivity(),
-                            R.string.pref_key_camerax_target_analysis_size,
-                            newStringValue);
-                    return true;
-                });
-    }
-
-    private void setUpFaceDetectionPreferences() {
-        setUpListPreference(R.string.pref_key_live_preview_face_detection_landmark_mode);
-        setUpListPreference(R.string.pref_key_live_preview_face_detection_contour_mode);
-        setUpListPreference(R.string.pref_key_live_preview_face_detection_classification_mode);
-        setUpListPreference(R.string.pref_key_live_preview_face_detection_performance_mode);
-
-        EditTextPreference minFaceSizePreference =
-                (EditTextPreference)
-                        findPreference(getString(R.string.pref_key_live_preview_face_detection_min_face_size));
-        minFaceSizePreference.setSummary(minFaceSizePreference.getText());
-        minFaceSizePreference.setOnPreferenceChangeListener(
-                (preference, newValue) -> {
-                    try {
-                        float minFaceSize = Float.parseFloat((String) newValue);
-                        if (minFaceSize >= 0.0f && minFaceSize <= 1.0f) {
-                            minFaceSizePreference.setSummary((String) newValue);
-                            return true;
-                        }
-                    } catch (NumberFormatException e) {
-                        // Fall through intentionally.
-                    }
-
-                    Toast.makeText(
-                            getActivity(), R.string.pref_toast_invalid_min_face_size, Toast.LENGTH_LONG)
-                            .show();
-                    return false;
-                });
-    }
-
-    private void setUpListPreference(@StringRes int listPreferenceKeyId) {
-        ListPreference listPreference = (ListPreference) findPreference(getString(listPreferenceKeyId));
-        listPreference.setSummary(listPreference.getEntry());
-        listPreference.setOnPreferenceChangeListener(
-                (preference, newValue) -> {
-                    int index = listPreference.findIndexOfValue((String) newValue);
-                    listPreference.setSummary(listPreference.getEntries()[index]);
-                    return true;
-                });
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.preference;
+
+import android.hardware.Camera;
+import android.os.Bundle;
+import android.preference.EditTextPreference;
+import android.preference.ListPreference;
+import android.preference.PreferenceCategory;
+import android.preference.PreferenceFragment;
+import android.widget.Toast;
+
+import androidx.annotation.StringRes;
+
+import com.google.mlkit.vision.demo.CameraSource;
+import com.google.mlkit.vision.demo.CameraSource.SizePair;
+import com.google.mlkit.vision.demo.R;
+
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * Configures live preview demo settings.
+ */
+public class LivePreviewPreferenceFragment extends PreferenceFragment {
+
+    protected boolean isCameraXSetting;
+
+    @Override
+    public void onCreate(Bundle savedInstanceState) {
+        super.onCreate(savedInstanceState);
+
+        addPreferencesFromResource(R.xml.preference_live_preview);
+        setUpCameraPreferences();
+        setUpFaceDetectionPreferences();
+    }
+
+    private void setUpCameraPreferences() {
+        PreferenceCategory cameraPreference =
+                (PreferenceCategory) findPreference(getString(R.string.pref_category_key_camera));
+
+        if (isCameraXSetting) {
+            cameraPreference.removePreference(
+                    findPreference(getString(R.string.pref_key_rear_camera_preview_size)));
+            cameraPreference.removePreference(
+                    findPreference(getString(R.string.pref_key_front_camera_preview_size)));
+            setUpCameraXTargetAnalysisSizePreference();
+        } else {
+            cameraPreference.removePreference(
+                    findPreference(getString(R.string.pref_key_camerax_target_analysis_size)));
+            setUpCameraPreviewSizePreference(
+                    R.string.pref_key_rear_camera_preview_size,
+                    R.string.pref_key_rear_camera_picture_size,
+                    CameraSource.CAMERA_FACING_BACK);
+            setUpCameraPreviewSizePreference(
+                    R.string.pref_key_front_camera_preview_size,
+                    R.string.pref_key_front_camera_picture_size,
+                    CameraSource.CAMERA_FACING_FRONT);
+        }
+    }
+
+    private void setUpCameraPreviewSizePreference(
+            @StringRes int previewSizePrefKeyId, @StringRes int pictureSizePrefKeyId, int cameraId) {
+        ListPreference previewSizePreference =
+                (ListPreference) findPreference(getString(previewSizePrefKeyId));
+
+        Camera camera = null;
+        try {
+            camera = Camera.open(cameraId);
+
+            List<SizePair> previewSizeList = CameraSource.generateValidPreviewSizeList(camera);
+            String[] previewSizeStringValues = new String[previewSizeList.size()];
+            Map<String, String> previewToPictureSizeStringMap = new HashMap<>();
+            for (int i = 0; i < previewSizeList.size(); i++) {
+                SizePair sizePair = previewSizeList.get(i);
+                previewSizeStringValues[i] = sizePair.preview.toString();
+                if (sizePair.picture != null) {
+                    previewToPictureSizeStringMap.put(
+                            sizePair.preview.toString(), sizePair.picture.toString());
+                }
+            }
+            previewSizePreference.setEntries(previewSizeStringValues);
+            previewSizePreference.setEntryValues(previewSizeStringValues);
+
+            if (previewSizePreference.getEntry() == null) {
+                // First time of opening the Settings page.
+                SizePair sizePair =
+                        CameraSource.selectSizePair(
+                                camera,
+                                CameraSource.DEFAULT_REQUESTED_CAMERA_PREVIEW_WIDTH,
+                                CameraSource.DEFAULT_REQUESTED_CAMERA_PREVIEW_HEIGHT);
+                String previewSizeString = sizePair.preview.toString();
+                previewSizePreference.setValue(previewSizeString);
+                previewSizePreference.setSummary(previewSizeString);
+                PreferenceUtils.saveString(
+                        getActivity(),
+                        pictureSizePrefKeyId,
+                        sizePair.picture != null ? sizePair.picture.toString() : null);
+            } else {
+                previewSizePreference.setSummary(previewSizePreference.getEntry());
+            }
+
+            previewSizePreference.setOnPreferenceChangeListener(
+                    (preference, newValue) -> {
+                        String newPreviewSizeStringValue = (String) newValue;
+                        previewSizePreference.setSummary(newPreviewSizeStringValue);
+                        PreferenceUtils.saveString(
+                                getActivity(),
+                                pictureSizePrefKeyId,
+                                previewToPictureSizeStringMap.get(newPreviewSizeStringValue));
+                        return true;
+                    });
+
+        } catch (Exception e) {
+            // If there's no camera for the given camera id, hide the corresponding preference.
+            ((PreferenceCategory) findPreference(getString(R.string.pref_category_key_camera)))
+                    .removePreference(previewSizePreference);
+        } finally {
+            if (camera != null) {
+                camera.release();
+            }
+        }
+    }
+
+    private void setUpCameraXTargetAnalysisSizePreference() {
+        ListPreference pref =
+                (ListPreference) findPreference(getString(R.string.pref_key_camerax_target_analysis_size));
+        String[] entries = new String[]{
+                "2000x2000",
+                "1600x1600",
+                "1200x1200",
+                "1000x1000",
+                "800x800",
+                "600x600",
+                "400x400",
+                "200x200",
+                "100x100",
+        };
+        pref.setEntries(entries);
+        pref.setEntryValues(entries);
+        pref.setSummary(pref.getEntry() == null ? "Default" : pref.getEntry());
+        pref.setOnPreferenceChangeListener(
+                (preference, newValue) -> {
+                    String newStringValue = (String) newValue;
+                    pref.setSummary(newStringValue);
+                    PreferenceUtils.saveString(
+                            getActivity(),
+                            R.string.pref_key_camerax_target_analysis_size,
+                            newStringValue);
+                    return true;
+                });
+    }
+
+    private void setUpFaceDetectionPreferences() {
+        setUpListPreference(R.string.pref_key_live_preview_face_detection_landmark_mode);
+        setUpListPreference(R.string.pref_key_live_preview_face_detection_contour_mode);
+        setUpListPreference(R.string.pref_key_live_preview_face_detection_classification_mode);
+        setUpListPreference(R.string.pref_key_live_preview_face_detection_performance_mode);
+
+        EditTextPreference minFaceSizePreference =
+                (EditTextPreference)
+                        findPreference(getString(R.string.pref_key_live_preview_face_detection_min_face_size));
+        minFaceSizePreference.setSummary(minFaceSizePreference.getText());
+        minFaceSizePreference.setOnPreferenceChangeListener(
+                (preference, newValue) -> {
+                    try {
+                        float minFaceSize = Float.parseFloat((String) newValue);
+                        if (minFaceSize >= 0.0f && minFaceSize <= 1.0f) {
+                            minFaceSizePreference.setSummary((String) newValue);
+                            return true;
+                        }
+                    } catch (NumberFormatException e) {
+                        // Fall through intentionally.
+                    }
+
+                    Toast.makeText(
+                            getActivity(), R.string.pref_toast_invalid_min_face_size, Toast.LENGTH_LONG)
+                            .show();
+                    return false;
+                });
+    }
+
+    private void setUpListPreference(@StringRes int listPreferenceKeyId) {
+        ListPreference listPreference = (ListPreference) findPreference(getString(listPreferenceKeyId));
+        listPreference.setSummary(listPreference.getEntry());
+        listPreference.setOnPreferenceChangeListener(
+                (preference, newValue) -> {
+                    int index = listPreference.findIndexOfValue((String) newValue);
+                    listPreference.setSummary(listPreference.getEntries()[index]);
+                    return true;
+                });
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/PreferenceUtils.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/PreferenceUtils.java
index d2d7efe..53f7aee 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/PreferenceUtils.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/PreferenceUtils.java
@@ -1,235 +1,235 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.preference;
-
-import android.content.Context;
-import android.content.SharedPreferences;
-import android.os.Build.VERSION_CODES;
-import android.preference.PreferenceManager;
-
-import androidx.annotation.Nullable;
-import androidx.annotation.RequiresApi;
-import androidx.annotation.StringRes;
-
-import com.google.android.gms.common.images.Size;
-import com.google.common.base.Preconditions;
-import com.google.mlkit.common.model.LocalModel;
-import com.google.mlkit.vision.demo.CameraSource;
-import com.google.mlkit.vision.demo.CameraSource.SizePair;
-import com.google.mlkit.vision.demo.R;
-import com.google.mlkit.vision.face.FaceDetectorOptions;
-import com.google.mlkit.vision.objects.ObjectDetectorOptionsBase.DetectorMode;
-import com.google.mlkit.vision.objects.custom.CustomObjectDetectorOptions;
-import com.google.mlkit.vision.objects.defaults.ObjectDetectorOptions;
-
-/**
- * Utility class to retrieve shared preferences.
- */
-public class PreferenceUtils {
-
-    static void saveString(Context context, @StringRes int prefKeyId, @Nullable String value) {
-        PreferenceManager.getDefaultSharedPreferences(context)
-                .edit()
-                .putString(context.getString(prefKeyId), value)
-                .apply();
-    }
-
-    @Nullable
-    public static SizePair getCameraPreviewSizePair(Context context, int cameraId) {
-        Preconditions.checkArgument(
-                cameraId == CameraSource.CAMERA_FACING_BACK
-                        || cameraId == CameraSource.CAMERA_FACING_FRONT);
-        String previewSizePrefKey;
-        String pictureSizePrefKey;
-        if (cameraId == CameraSource.CAMERA_FACING_BACK) {
-            previewSizePrefKey = context.getString(R.string.pref_key_rear_camera_preview_size);
-            pictureSizePrefKey = context.getString(R.string.pref_key_rear_camera_picture_size);
-        } else {
-            previewSizePrefKey = context.getString(R.string.pref_key_front_camera_preview_size);
-            pictureSizePrefKey = context.getString(R.string.pref_key_front_camera_picture_size);
-        }
-
-        try {
-            SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
-            return new SizePair(
-                    Size.parseSize(sharedPreferences.getString(previewSizePrefKey, null)),
-                    Size.parseSize(sharedPreferences.getString(pictureSizePrefKey, null)));
-        } catch (Exception e) {
-            return null;
-        }
-    }
-
-    @RequiresApi(VERSION_CODES.LOLLIPOP)
-    @Nullable
-    public static android.util.Size getCameraXTargetAnalysisSize(Context context) {
-        String prefKey = context.getString(R.string.pref_key_camerax_target_analysis_size);
-        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
-        try {
-            return android.util.Size.parseSize(sharedPreferences.getString(prefKey, null));
-        } catch (Exception e) {
-            return null;
-        }
-    }
-
-    public static ObjectDetectorOptions getObjectDetectorOptionsForStillImage(Context context) {
-        return getObjectDetectorOptions(
-                context,
-                R.string.pref_key_still_image_object_detector_enable_multiple_objects,
-                R.string.pref_key_still_image_object_detector_enable_classification,
-                ObjectDetectorOptions.SINGLE_IMAGE_MODE);
-    }
-
-    public static ObjectDetectorOptions getObjectDetectorOptionsForLivePreview(Context context) {
-        return getObjectDetectorOptions(
-                context,
-                R.string.pref_key_live_preview_object_detector_enable_multiple_objects,
-                R.string.pref_key_live_preview_object_detector_enable_classification,
-                ObjectDetectorOptions.STREAM_MODE);
-    }
-
-    private static ObjectDetectorOptions getObjectDetectorOptions(
-            Context context,
-            @StringRes int prefKeyForMultipleObjects,
-            @StringRes int prefKeyForClassification,
-            @DetectorMode int mode) {
-
-        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
-
-        boolean enableMultipleObjects =
-                sharedPreferences.getBoolean(context.getString(prefKeyForMultipleObjects), false);
-        boolean enableClassification =
-                sharedPreferences.getBoolean(context.getString(prefKeyForClassification), true);
-
-        ObjectDetectorOptions.Builder builder =
-                new ObjectDetectorOptions.Builder().setDetectorMode(mode);
-        if (enableMultipleObjects) {
-            builder.enableMultipleObjects();
-        }
-        if (enableClassification) {
-            builder.enableClassification();
-        }
-        return builder.build();
-    }
-
-    public static CustomObjectDetectorOptions getCustomObjectDetectorOptionsForStillImage(
-            Context context, LocalModel localModel) {
-        return getCustomObjectDetectorOptions(
-                context,
-                localModel,
-                R.string.pref_key_still_image_object_detector_enable_multiple_objects,
-                R.string.pref_key_still_image_object_detector_enable_classification,
-                CustomObjectDetectorOptions.SINGLE_IMAGE_MODE);
-    }
-
-    public static CustomObjectDetectorOptions getCustomObjectDetectorOptionsForLivePreview(
-            Context context, LocalModel localModel) {
-        return getCustomObjectDetectorOptions(
-                context,
-                localModel,
-                R.string.pref_key_live_preview_object_detector_enable_multiple_objects,
-                R.string.pref_key_live_preview_object_detector_enable_classification,
-                CustomObjectDetectorOptions.STREAM_MODE);
-    }
-
-    private static CustomObjectDetectorOptions getCustomObjectDetectorOptions(
-            Context context,
-            LocalModel localModel,
-            @StringRes int prefKeyForMultipleObjects,
-            @StringRes int prefKeyForClassification,
-            @DetectorMode int mode) {
-
-        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
-
-        boolean enableMultipleObjects =
-                sharedPreferences.getBoolean(context.getString(prefKeyForMultipleObjects), false);
-        boolean enableClassification =
-                sharedPreferences.getBoolean(context.getString(prefKeyForClassification), true);
-
-        CustomObjectDetectorOptions.Builder builder =
-                new CustomObjectDetectorOptions.Builder(localModel).setDetectorMode(mode);
-        if (enableMultipleObjects) {
-            builder.enableMultipleObjects();
-        }
-        if (enableClassification) {
-            builder.enableClassification();
-        }
-        return builder.build();
-    }
-
-    public static FaceDetectorOptions getFaceDetectorOptionsForLivePreview(Context context) {
-        int landmarkMode =
-                getModeTypePreferenceValue(
-                        context,
-                        R.string.pref_key_live_preview_face_detection_landmark_mode,
-                        FaceDetectorOptions.LANDMARK_MODE_NONE);
-        int contourMode =
-                getModeTypePreferenceValue(
-                        context,
-                        R.string.pref_key_live_preview_face_detection_contour_mode,
-                        FaceDetectorOptions.CONTOUR_MODE_ALL);
-        int classificationMode =
-                getModeTypePreferenceValue(
-                        context,
-                        R.string.pref_key_live_preview_face_detection_classification_mode,
-                        FaceDetectorOptions.CLASSIFICATION_MODE_NONE);
-        int performanceMode =
-                getModeTypePreferenceValue(
-                        context,
-                        R.string.pref_key_live_preview_face_detection_performance_mode,
-                        FaceDetectorOptions.PERFORMANCE_MODE_FAST);
-
-        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
-        boolean enableFaceTracking =
-                sharedPreferences.getBoolean(
-                        context.getString(R.string.pref_key_live_preview_face_detection_face_tracking), false);
-        float minFaceSize =
-                Float.parseFloat(
-                        sharedPreferences.getString(
-                                context.getString(R.string.pref_key_live_preview_face_detection_min_face_size),
-                                "0.1"));
-
-        FaceDetectorOptions.Builder optionsBuilder =
-                new FaceDetectorOptions.Builder()
-                        .setLandmarkMode(landmarkMode)
-                        .setContourMode(contourMode)
-                        .setClassificationMode(classificationMode)
-                        .setPerformanceMode(performanceMode)
-                        .setMinFaceSize(minFaceSize);
-        if (enableFaceTracking) {
-            optionsBuilder.enableTracking();
-        }
-        return optionsBuilder.build();
-    }
-
-    /**
-     * Mode type preference is backed by {@link android.preference.ListPreference} which only support
-     * storing its entry value as string type, so we need to retrieve as string and then convert to
-     * integer.
-     */
-    private static int getModeTypePreferenceValue(
-            Context context, @StringRes int prefKeyResId, int defaultValue) {
-        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
-        String prefKey = context.getString(prefKeyResId);
-        return Integer.parseInt(sharedPreferences.getString(prefKey, String.valueOf(defaultValue)));
-    }
-
-    public static boolean isCameraLiveViewportEnabled(Context context) {
-        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
-        String prefKey = context.getString(R.string.pref_key_camera_live_viewport);
-        return sharedPreferences.getBoolean(prefKey, false);
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.preference;
+
+import android.content.Context;
+import android.content.SharedPreferences;
+import android.os.Build.VERSION_CODES;
+import android.preference.PreferenceManager;
+
+import androidx.annotation.Nullable;
+import androidx.annotation.RequiresApi;
+import androidx.annotation.StringRes;
+
+import com.google.android.gms.common.images.Size;
+import com.google.common.base.Preconditions;
+import com.google.mlkit.common.model.LocalModel;
+import com.google.mlkit.vision.demo.CameraSource;
+import com.google.mlkit.vision.demo.CameraSource.SizePair;
+import com.google.mlkit.vision.demo.R;
+import com.google.mlkit.vision.face.FaceDetectorOptions;
+import com.google.mlkit.vision.objects.ObjectDetectorOptionsBase.DetectorMode;
+import com.google.mlkit.vision.objects.custom.CustomObjectDetectorOptions;
+import com.google.mlkit.vision.objects.defaults.ObjectDetectorOptions;
+
+/**
+ * Utility class to retrieve shared preferences.
+ */
+public class PreferenceUtils {
+
+    static void saveString(Context context, @StringRes int prefKeyId, @Nullable String value) {
+        PreferenceManager.getDefaultSharedPreferences(context)
+                .edit()
+                .putString(context.getString(prefKeyId), value)
+                .apply();
+    }
+
+    @Nullable
+    public static SizePair getCameraPreviewSizePair(Context context, int cameraId) {
+        Preconditions.checkArgument(
+                cameraId == CameraSource.CAMERA_FACING_BACK
+                        || cameraId == CameraSource.CAMERA_FACING_FRONT);
+        String previewSizePrefKey;
+        String pictureSizePrefKey;
+        if (cameraId == CameraSource.CAMERA_FACING_BACK) {
+            previewSizePrefKey = context.getString(R.string.pref_key_rear_camera_preview_size);
+            pictureSizePrefKey = context.getString(R.string.pref_key_rear_camera_picture_size);
+        } else {
+            previewSizePrefKey = context.getString(R.string.pref_key_front_camera_preview_size);
+            pictureSizePrefKey = context.getString(R.string.pref_key_front_camera_picture_size);
+        }
+
+        try {
+            SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
+            return new SizePair(
+                    Size.parseSize(sharedPreferences.getString(previewSizePrefKey, null)),
+                    Size.parseSize(sharedPreferences.getString(pictureSizePrefKey, null)));
+        } catch (Exception e) {
+            return null;
+        }
+    }
+
+    @RequiresApi(VERSION_CODES.LOLLIPOP)
+    @Nullable
+    public static android.util.Size getCameraXTargetAnalysisSize(Context context) {
+        String prefKey = context.getString(R.string.pref_key_camerax_target_analysis_size);
+        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
+        try {
+            return android.util.Size.parseSize(sharedPreferences.getString(prefKey, null));
+        } catch (Exception e) {
+            return null;
+        }
+    }
+
+    public static ObjectDetectorOptions getObjectDetectorOptionsForStillImage(Context context) {
+        return getObjectDetectorOptions(
+                context,
+                R.string.pref_key_still_image_object_detector_enable_multiple_objects,
+                R.string.pref_key_still_image_object_detector_enable_classification,
+                ObjectDetectorOptions.SINGLE_IMAGE_MODE);
+    }
+
+    public static ObjectDetectorOptions getObjectDetectorOptionsForLivePreview(Context context) {
+        return getObjectDetectorOptions(
+                context,
+                R.string.pref_key_live_preview_object_detector_enable_multiple_objects,
+                R.string.pref_key_live_preview_object_detector_enable_classification,
+                ObjectDetectorOptions.STREAM_MODE);
+    }
+
+    private static ObjectDetectorOptions getObjectDetectorOptions(
+            Context context,
+            @StringRes int prefKeyForMultipleObjects,
+            @StringRes int prefKeyForClassification,
+            @DetectorMode int mode) {
+
+        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
+
+        boolean enableMultipleObjects =
+                sharedPreferences.getBoolean(context.getString(prefKeyForMultipleObjects), false);
+        boolean enableClassification =
+                sharedPreferences.getBoolean(context.getString(prefKeyForClassification), true);
+
+        ObjectDetectorOptions.Builder builder =
+                new ObjectDetectorOptions.Builder().setDetectorMode(mode);
+        if (enableMultipleObjects) {
+            builder.enableMultipleObjects();
+        }
+        if (enableClassification) {
+            builder.enableClassification();
+        }
+        return builder.build();
+    }
+
+    public static CustomObjectDetectorOptions getCustomObjectDetectorOptionsForStillImage(
+            Context context, LocalModel localModel) {
+        return getCustomObjectDetectorOptions(
+                context,
+                localModel,
+                R.string.pref_key_still_image_object_detector_enable_multiple_objects,
+                R.string.pref_key_still_image_object_detector_enable_classification,
+                CustomObjectDetectorOptions.SINGLE_IMAGE_MODE);
+    }
+
+    public static CustomObjectDetectorOptions getCustomObjectDetectorOptionsForLivePreview(
+            Context context, LocalModel localModel) {
+        return getCustomObjectDetectorOptions(
+                context,
+                localModel,
+                R.string.pref_key_live_preview_object_detector_enable_multiple_objects,
+                R.string.pref_key_live_preview_object_detector_enable_classification,
+                CustomObjectDetectorOptions.STREAM_MODE);
+    }
+
+    private static CustomObjectDetectorOptions getCustomObjectDetectorOptions(
+            Context context,
+            LocalModel localModel,
+            @StringRes int prefKeyForMultipleObjects,
+            @StringRes int prefKeyForClassification,
+            @DetectorMode int mode) {
+
+        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
+
+        boolean enableMultipleObjects =
+                sharedPreferences.getBoolean(context.getString(prefKeyForMultipleObjects), false);
+        boolean enableClassification =
+                sharedPreferences.getBoolean(context.getString(prefKeyForClassification), true);
+
+        CustomObjectDetectorOptions.Builder builder =
+                new CustomObjectDetectorOptions.Builder(localModel).setDetectorMode(mode);
+        if (enableMultipleObjects) {
+            builder.enableMultipleObjects();
+        }
+        if (enableClassification) {
+            builder.enableClassification();
+        }
+        return builder.build();
+    }
+
+    public static FaceDetectorOptions getFaceDetectorOptionsForLivePreview(Context context) {
+        int landmarkMode =
+                getModeTypePreferenceValue(
+                        context,
+                        R.string.pref_key_live_preview_face_detection_landmark_mode,
+                        FaceDetectorOptions.LANDMARK_MODE_NONE);
+        int contourMode =
+                getModeTypePreferenceValue(
+                        context,
+                        R.string.pref_key_live_preview_face_detection_contour_mode,
+                        FaceDetectorOptions.CONTOUR_MODE_ALL);
+        int classificationMode =
+                getModeTypePreferenceValue(
+                        context,
+                        R.string.pref_key_live_preview_face_detection_classification_mode,
+                        FaceDetectorOptions.CLASSIFICATION_MODE_NONE);
+        int performanceMode =
+                getModeTypePreferenceValue(
+                        context,
+                        R.string.pref_key_live_preview_face_detection_performance_mode,
+                        FaceDetectorOptions.PERFORMANCE_MODE_FAST);
+
+        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
+        boolean enableFaceTracking =
+                sharedPreferences.getBoolean(
+                        context.getString(R.string.pref_key_live_preview_face_detection_face_tracking), false);
+        float minFaceSize =
+                Float.parseFloat(
+                        sharedPreferences.getString(
+                                context.getString(R.string.pref_key_live_preview_face_detection_min_face_size),
+                                "0.1"));
+
+        FaceDetectorOptions.Builder optionsBuilder =
+                new FaceDetectorOptions.Builder()
+                        .setLandmarkMode(landmarkMode)
+                        .setContourMode(contourMode)
+                        .setClassificationMode(classificationMode)
+                        .setPerformanceMode(performanceMode)
+                        .setMinFaceSize(minFaceSize);
+        if (enableFaceTracking) {
+            optionsBuilder.enableTracking();
+        }
+        return optionsBuilder.build();
+    }
+
+    /**
+     * Mode type preference is backed by {@link android.preference.ListPreference} which only support
+     * storing its entry value as string type, so we need to retrieve as string and then convert to
+     * integer.
+     */
+    private static int getModeTypePreferenceValue(
+            Context context, @StringRes int prefKeyResId, int defaultValue) {
+        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
+        String prefKey = context.getString(prefKeyResId);
+        return Integer.parseInt(sharedPreferences.getString(prefKey, String.valueOf(defaultValue)));
+    }
+
+    public static boolean isCameraLiveViewportEnabled(Context context) {
+        SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
+        String prefKey = context.getString(R.string.pref_key_camera_live_viewport);
+        return sharedPreferences.getBoolean(prefKey, false);
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/SettingsActivity.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/SettingsActivity.java
index 92c684a..aa18742 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/SettingsActivity.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/SettingsActivity.java
@@ -1,78 +1,78 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.preference;
-
-import android.os.Bundle;
-import android.preference.PreferenceFragment;
-
-import androidx.appcompat.app.ActionBar;
-import androidx.appcompat.app.AppCompatActivity;
-
-import com.google.mlkit.vision.demo.R;
-
-/**
- * Hosts the preference fragment to configure settings for a demo activity that specified by the
- * {@link LaunchSource}.
- */
-public class SettingsActivity extends AppCompatActivity {
-
-    public static final String EXTRA_LAUNCH_SOURCE = "extra_launch_source";
-
-    /**
-     * Specifies where this activity is launched from.
-     */
-    public enum LaunchSource {
-        LIVE_PREVIEW(R.string.pref_screen_title_live_preview, LivePreviewPreferenceFragment.class),
-        STILL_IMAGE(R.string.pref_screen_title_still_image, StillImagePreferenceFragment.class),
-        CAMERAX_LIVE_PREVIEW(
-                R.string.pref_screen_title_camerax_live_preview,
-                CameraXLivePreviewPreferenceFragment.class);
-
-        private final int titleResId;
-        private final Class<? extends PreferenceFragment> prefFragmentClass;
-
-        LaunchSource(int titleResId, Class<? extends PreferenceFragment> prefFragmentClass) {
-            this.titleResId = titleResId;
-            this.prefFragmentClass = prefFragmentClass;
-        }
-    }
-
-    @Override
-    protected void onCreate(Bundle savedInstanceState) {
-        super.onCreate(savedInstanceState);
-
-        setContentView(R.layout.activity_settings);
-
-        LaunchSource launchSource =
-                (LaunchSource) getIntent().getSerializableExtra(EXTRA_LAUNCH_SOURCE);
-        ActionBar actionBar = getSupportActionBar();
-        if (actionBar != null) {
-            actionBar.setTitle(launchSource.titleResId);
-        }
-
-        try {
-            getFragmentManager()
-                    .beginTransaction()
-                    .replace(
-                            R.id.settings_container,
-                            launchSource.prefFragmentClass.getDeclaredConstructor().newInstance())
-                    .commit();
-        } catch (Exception e) {
-            throw new RuntimeException(e);
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.preference;
+
+import android.os.Bundle;
+import android.preference.PreferenceFragment;
+
+import androidx.appcompat.app.ActionBar;
+import androidx.appcompat.app.AppCompatActivity;
+
+import com.google.mlkit.vision.demo.R;
+
+/**
+ * Hosts the preference fragment to configure settings for a demo activity that specified by the
+ * {@link LaunchSource}.
+ */
+public class SettingsActivity extends AppCompatActivity {
+
+    public static final String EXTRA_LAUNCH_SOURCE = "extra_launch_source";
+
+    /**
+     * Specifies where this activity is launched from.
+     */
+    public enum LaunchSource {
+        LIVE_PREVIEW(R.string.pref_screen_title_live_preview, LivePreviewPreferenceFragment.class),
+        STILL_IMAGE(R.string.pref_screen_title_still_image, StillImagePreferenceFragment.class),
+        CAMERAX_LIVE_PREVIEW(
+                R.string.pref_screen_title_camerax_live_preview,
+                CameraXLivePreviewPreferenceFragment.class);
+
+        private final int titleResId;
+        private final Class<? extends PreferenceFragment> prefFragmentClass;
+
+        LaunchSource(int titleResId, Class<? extends PreferenceFragment> prefFragmentClass) {
+            this.titleResId = titleResId;
+            this.prefFragmentClass = prefFragmentClass;
+        }
+    }
+
+    @Override
+    protected void onCreate(Bundle savedInstanceState) {
+        super.onCreate(savedInstanceState);
+
+        setContentView(R.layout.activity_settings);
+
+        LaunchSource launchSource =
+                (LaunchSource) getIntent().getSerializableExtra(EXTRA_LAUNCH_SOURCE);
+        ActionBar actionBar = getSupportActionBar();
+        if (actionBar != null) {
+            actionBar.setTitle(launchSource.titleResId);
+        }
+
+        try {
+            getFragmentManager()
+                    .beginTransaction()
+                    .replace(
+                            R.id.settings_container,
+                            launchSource.prefFragmentClass.getDeclaredConstructor().newInstance())
+                    .commit();
+        } catch (Exception e) {
+            throw new RuntimeException(e);
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/StillImagePreferenceFragment.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/StillImagePreferenceFragment.java
index 0e10654..81bbf8d 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/StillImagePreferenceFragment.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/StillImagePreferenceFragment.java
@@ -1,34 +1,34 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.preference;
-
-import android.os.Bundle;
-import android.preference.PreferenceFragment;
-
-import com.google.mlkit.vision.demo.R;
-
-/**
- * Configures still image demo settings.
- */
-public class StillImagePreferenceFragment extends PreferenceFragment {
-
-    @Override
-    public void onCreate(Bundle savedInstanceState) {
-        super.onCreate(savedInstanceState);
-        addPreferencesFromResource(R.xml.preference_still_image);
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.preference;
+
+import android.os.Bundle;
+import android.preference.PreferenceFragment;
+
+import com.google.mlkit.vision.demo.R;
+
+/**
+ * Configures still image demo settings.
+ */
+public class StillImagePreferenceFragment extends PreferenceFragment {
+
+    @Override
+    public void onCreate(Bundle savedInstanceState) {
+        super.onCreate(savedInstanceState);
+        addPreferencesFromResource(R.xml.preference_still_image);
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/textdetector/TextGraphic.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/textdetector/TextGraphic.java
index 4c64dce..cc85657 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/textdetector/TextGraphic.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/textdetector/TextGraphic.java
@@ -1,117 +1,117 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.textdetector;
-
-import android.graphics.Canvas;
-import android.graphics.Color;
-import android.graphics.Paint;
-import android.graphics.RectF;
-import android.util.Log;
-
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.demo.GraphicOverlay.Graphic;
-import com.google.mlkit.vision.text.Text;
-import com.google.mlkit.vision.text.Text.Element;
-import com.google.mlkit.vision.text.Text.Line;
-import com.google.mlkit.vision.text.Text.TextBlock;
-
-import java.util.Arrays;
-
-/**
- * Graphic instance for rendering TextBlock position, size, and ID within an associated graphic
- * overlay view.
- */
-public class TextGraphic extends Graphic {
-
-    private static final String TAG = "TextGraphic";
-
-    private static final int TEXT_COLOR = Color.BLACK;
-    private static final int MARKER_COLOR = Color.WHITE;
-    private static final float TEXT_SIZE = 54.0f;
-    private static final float STROKE_WIDTH = 4.0f;
-
-    private final Paint rectPaint;
-    private final Paint textPaint;
-    private final Paint labelPaint;
-    private final Text text;
-
-    TextGraphic(GraphicOverlay overlay, Text text) {
-        super(overlay);
-
-        this.text = text;
-
-        rectPaint = new Paint();
-        rectPaint.setColor(MARKER_COLOR);
-        rectPaint.setStyle(Paint.Style.STROKE);
-        rectPaint.setStrokeWidth(STROKE_WIDTH);
-
-        textPaint = new Paint();
-        textPaint.setColor(TEXT_COLOR);
-        textPaint.setTextSize(TEXT_SIZE);
-
-        labelPaint = new Paint();
-        labelPaint.setColor(MARKER_COLOR);
-        labelPaint.setStyle(Paint.Style.FILL);
-        // Redraw the overlay, as this graphic has been added.
-        postInvalidate();
-    }
-
-    /**
-     * Draws the text block annotations for position, size, and raw value on the supplied canvas.
-     */
-    @Override
-    public void draw(Canvas canvas) {
-        Log.d(TAG, "Text is: " + text.getText());
-        for (TextBlock textBlock : text.getTextBlocks()) {
-            // Renders the text at the bottom of the box.
-            Log.d(TAG, "TextBlock text is: " + textBlock.getText());
-            Log.d(TAG, "TextBlock boundingbox is: " + textBlock.getBoundingBox());
-            Log.d(TAG, "TextBlock cornerpoint is: " + Arrays.toString(textBlock.getCornerPoints()));
-            for (Line line : textBlock.getLines()) {
-                Log.d(TAG, "Line text is: " + line.getText());
-                Log.d(TAG, "Line boundingbox is: " + line.getBoundingBox());
-                Log.d(TAG, "Line cornerpoint is: " + Arrays.toString(line.getCornerPoints()));
-                // Draws the bounding box around the TextBlock.
-                RectF rect = new RectF(line.getBoundingBox());
-                rect.left = translateX(rect.left);
-                rect.top = translateY(rect.top);
-                rect.right = translateX(rect.right);
-                rect.bottom = translateY(rect.bottom);
-                canvas.drawRect(rect, rectPaint);
-
-                float lineHeight = TEXT_SIZE + 2 * STROKE_WIDTH;
-                float textWidth = textPaint.measureText(line.getText());
-                float left = isImageFlipped() ? rect.right : rect.left;
-                canvas.drawRect(
-                        left - STROKE_WIDTH,
-                        rect.top - lineHeight,
-                        left + textWidth + 2 * STROKE_WIDTH,
-                        rect.top,
-                        labelPaint);
-                // Renders the text at the bottom of the box.
-                canvas.drawText(line.getText(), left, rect.top - STROKE_WIDTH, textPaint);
-
-                for (Element element : line.getElements()) {
-                    Log.d(TAG, "Element text is: " + element.getText());
-                    Log.d(TAG, "Element boundingbox is: " + element.getBoundingBox());
-                    Log.d(TAG, "Element cornerpoint is: " + Arrays.toString(element.getCornerPoints()));
-                    Log.d(TAG, "Element language is: " + element.getRecognizedLanguage());
-                }
-            }
-        }
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.textdetector;
+
+import android.graphics.Canvas;
+import android.graphics.Color;
+import android.graphics.Paint;
+import android.graphics.RectF;
+import android.util.Log;
+
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.demo.GraphicOverlay.Graphic;
+import com.google.mlkit.vision.text.Text;
+import com.google.mlkit.vision.text.Text.Element;
+import com.google.mlkit.vision.text.Text.Line;
+import com.google.mlkit.vision.text.Text.TextBlock;
+
+import java.util.Arrays;
+
+/**
+ * Graphic instance for rendering TextBlock position, size, and ID within an associated graphic
+ * overlay view.
+ */
+public class TextGraphic extends Graphic {
+
+    private static final String TAG = "TextGraphic";
+
+    private static final int TEXT_COLOR = Color.BLACK;
+    private static final int MARKER_COLOR = Color.WHITE;
+    private static final float TEXT_SIZE = 54.0f;
+    private static final float STROKE_WIDTH = 4.0f;
+
+    private final Paint rectPaint;
+    private final Paint textPaint;
+    private final Paint labelPaint;
+    private final Text text;
+
+    TextGraphic(GraphicOverlay overlay, Text text) {
+        super(overlay);
+
+        this.text = text;
+
+        rectPaint = new Paint();
+        rectPaint.setColor(MARKER_COLOR);
+        rectPaint.setStyle(Paint.Style.STROKE);
+        rectPaint.setStrokeWidth(STROKE_WIDTH);
+
+        textPaint = new Paint();
+        textPaint.setColor(TEXT_COLOR);
+        textPaint.setTextSize(TEXT_SIZE);
+
+        labelPaint = new Paint();
+        labelPaint.setColor(MARKER_COLOR);
+        labelPaint.setStyle(Paint.Style.FILL);
+        // Redraw the overlay, as this graphic has been added.
+        postInvalidate();
+    }
+
+    /**
+     * Draws the text block annotations for position, size, and raw value on the supplied canvas.
+     */
+    @Override
+    public void draw(Canvas canvas) {
+        Log.d(TAG, "Text is: " + text.getText());
+        for (TextBlock textBlock : text.getTextBlocks()) {
+            // Renders the text at the bottom of the box.
+            Log.d(TAG, "TextBlock text is: " + textBlock.getText());
+            Log.d(TAG, "TextBlock boundingbox is: " + textBlock.getBoundingBox());
+            Log.d(TAG, "TextBlock cornerpoint is: " + Arrays.toString(textBlock.getCornerPoints()));
+            for (Line line : textBlock.getLines()) {
+                Log.d(TAG, "Line text is: " + line.getText());
+                Log.d(TAG, "Line boundingbox is: " + line.getBoundingBox());
+                Log.d(TAG, "Line cornerpoint is: " + Arrays.toString(line.getCornerPoints()));
+                // Draws the bounding box around the TextBlock.
+                RectF rect = new RectF(line.getBoundingBox());
+                rect.left = translateX(rect.left);
+                rect.top = translateY(rect.top);
+                rect.right = translateX(rect.right);
+                rect.bottom = translateY(rect.bottom);
+                canvas.drawRect(rect, rectPaint);
+
+                float lineHeight = TEXT_SIZE + 2 * STROKE_WIDTH;
+                float textWidth = textPaint.measureText(line.getText());
+                float left = isImageFlipped() ? rect.right : rect.left;
+                canvas.drawRect(
+                        left - STROKE_WIDTH,
+                        rect.top - lineHeight,
+                        left + textWidth + 2 * STROKE_WIDTH,
+                        rect.top,
+                        labelPaint);
+                // Renders the text at the bottom of the box.
+                canvas.drawText(line.getText(), left, rect.top - STROKE_WIDTH, textPaint);
+
+                for (Element element : line.getElements()) {
+                    Log.d(TAG, "Element text is: " + element.getText());
+                    Log.d(TAG, "Element boundingbox is: " + element.getBoundingBox());
+                    Log.d(TAG, "Element cornerpoint is: " + Arrays.toString(element.getCornerPoints()));
+                    Log.d(TAG, "Element language is: " + element.getRecognizedLanguage());
+                }
+            }
+        }
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/textdetector/TextRecognitionProcessor.java b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/textdetector/TextRecognitionProcessor.java
index 3861132..fb32c24 100755
--- a/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/textdetector/TextRecognitionProcessor.java
+++ b/android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/textdetector/TextRecognitionProcessor.java
@@ -1,113 +1,113 @@
-/*
- * Copyright 2020 Google LLC. All rights reserved.
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.google.mlkit.vision.demo.textdetector;
-
-import android.content.Context;
-import android.graphics.Point;
-import android.util.Log;
-
-import androidx.annotation.NonNull;
-
-import com.google.android.gms.tasks.Task;
-import com.google.mlkit.vision.common.InputImage;
-import com.google.mlkit.vision.demo.GraphicOverlay;
-import com.google.mlkit.vision.demo.VisionProcessorBase;
-import com.google.mlkit.vision.text.Text;
-import com.google.mlkit.vision.text.Text.Element;
-import com.google.mlkit.vision.text.Text.Line;
-import com.google.mlkit.vision.text.TextRecognition;
-import com.google.mlkit.vision.text.TextRecognizer;
-
-import java.util.List;
-
-/**
- * Processor for the text detector demo.
- */
-public class TextRecognitionProcessor extends VisionProcessorBase<Text> {
-
-    private static final String TAG = "TextRecProcessor";
-
-    private final TextRecognizer textRecognizer;
-
-    public TextRecognitionProcessor(Context context) {
-        super(context);
-        textRecognizer = TextRecognition.getClient();
-    }
-
-    @Override
-    public void stop() {
-        super.stop();
-        textRecognizer.close();
-    }
-
-    @Override
-    protected Task<Text> detectInImage(InputImage image) {
-        return textRecognizer.process(image);
-    }
-
-    @Override
-    protected void onSuccess(@NonNull Text text, @NonNull GraphicOverlay graphicOverlay) {
-        Log.d(TAG, "On-device Text detection successful");
-        logExtrasForTesting(text);
-        graphicOverlay.add(new TextGraphic(graphicOverlay, text));
-    }
-
-    private static void logExtrasForTesting(Text text) {
-        if (text != null) {
-            Log.v(MANUAL_TESTING_LOG, "Detected text has : " + text.getTextBlocks().size() + " blocks");
-            for (int i = 0; i < text.getTextBlocks().size(); ++i) {
-                List<Line> lines = text.getTextBlocks().get(i).getLines();
-                Log.v(
-                        MANUAL_TESTING_LOG,
-                        String.format("Detected text block %d has %d lines", i, lines.size()));
-                for (int j = 0; j < lines.size(); ++j) {
-                    List<Element> elements = lines.get(j).getElements();
-                    Log.v(
-                            MANUAL_TESTING_LOG,
-                            String.format("Detected text line %d has %d elements", j, elements.size()));
-                    for (int k = 0; k < elements.size(); ++k) {
-                        Element element = elements.get(k);
-                        Log.v(
-                                MANUAL_TESTING_LOG,
-                                String.format("Detected text element %d says: %s", k, element.getText()));
-                        Log.v(
-                                MANUAL_TESTING_LOG,
-                                String.format(
-                                        "Detected text element %d has a bounding box: %s",
-                                        k, element.getBoundingBox().flattenToString()));
-                        Log.v(
-                                MANUAL_TESTING_LOG,
-                                String.format(
-                                        "Expected corner point size is 4, get %d", element.getCornerPoints().length));
-                        for (Point point : element.getCornerPoints()) {
-                            Log.v(
-                                    MANUAL_TESTING_LOG,
-                                    String.format(
-                                            "Corner point for element %d is located at: x - %d, y = %d",
-                                            k, point.x, point.y));
-                        }
-                    }
-                }
-            }
-        }
-    }
-
-    @Override
-    protected void onFailure(@NonNull Exception e) {
-        Log.w(TAG, "Text detection failed." + e);
-    }
-}
+/*
+ * Copyright 2020 Google LLC. All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.mlkit.vision.demo.textdetector;
+
+import android.content.Context;
+import android.graphics.Point;
+import android.util.Log;
+
+import androidx.annotation.NonNull;
+
+import com.google.android.gms.tasks.Task;
+import com.google.mlkit.vision.common.InputImage;
+import com.google.mlkit.vision.demo.GraphicOverlay;
+import com.google.mlkit.vision.demo.VisionProcessorBase;
+import com.google.mlkit.vision.text.Text;
+import com.google.mlkit.vision.text.Text.Element;
+import com.google.mlkit.vision.text.Text.Line;
+import com.google.mlkit.vision.text.TextRecognition;
+import com.google.mlkit.vision.text.TextRecognizer;
+
+import java.util.List;
+
+/**
+ * Processor for the text detector demo.
+ */
+public class TextRecognitionProcessor extends VisionProcessorBase<Text> {
+
+    private static final String TAG = "TextRecProcessor";
+
+    private final TextRecognizer textRecognizer;
+
+    public TextRecognitionProcessor(Context context) {
+        super(context);
+        textRecognizer = TextRecognition.getClient();
+    }
+
+    @Override
+    public void stop() {
+        super.stop();
+        textRecognizer.close();
+    }
+
+    @Override
+    protected Task<Text> detectInImage(InputImage image) {
+        return textRecognizer.process(image);
+    }
+
+    @Override
+    protected void onSuccess(@NonNull Text text, @NonNull GraphicOverlay graphicOverlay) {
+        Log.d(TAG, "On-device Text detection successful");
+        logExtrasForTesting(text);
+        graphicOverlay.add(new TextGraphic(graphicOverlay, text));
+    }
+
+    private static void logExtrasForTesting(Text text) {
+        if (text != null) {
+            Log.v(MANUAL_TESTING_LOG, "Detected text has : " + text.getTextBlocks().size() + " blocks");
+            for (int i = 0; i < text.getTextBlocks().size(); ++i) {
+                List<Line> lines = text.getTextBlocks().get(i).getLines();
+                Log.v(
+                        MANUAL_TESTING_LOG,
+                        String.format("Detected text block %d has %d lines", i, lines.size()));
+                for (int j = 0; j < lines.size(); ++j) {
+                    List<Element> elements = lines.get(j).getElements();
+                    Log.v(
+                            MANUAL_TESTING_LOG,
+                            String.format("Detected text line %d has %d elements", j, elements.size()));
+                    for (int k = 0; k < elements.size(); ++k) {
+                        Element element = elements.get(k);
+                        Log.v(
+                                MANUAL_TESTING_LOG,
+                                String.format("Detected text element %d says: %s", k, element.getText()));
+                        Log.v(
+                                MANUAL_TESTING_LOG,
+                                String.format(
+                                        "Detected text element %d has a bounding box: %s",
+                                        k, element.getBoundingBox().flattenToString()));
+                        Log.v(
+                                MANUAL_TESTING_LOG,
+                                String.format(
+                                        "Expected corner point size is 4, get %d", element.getCornerPoints().length));
+                        for (Point point : element.getCornerPoints()) {
+                            Log.v(
+                                    MANUAL_TESTING_LOG,
+                                    String.format(
+                                            "Corner point for element %d is located at: x - %d, y = %d",
+                                            k, point.x, point.y));
+                        }
+                    }
+                }
+            }
+        }
+    }
+
+    @Override
+    protected void onFailure(@NonNull Exception e) {
+        Log.w(TAG, "Text detection failed." + e);
+    }
+}
diff --git a/android/vision-quickstart/app/src/main/res/drawable-hdpi/ic_switch_camera_white_48dp.xml b/android/vision-quickstart/app/src/main/res/drawable-hdpi/ic_switch_camera_white_48dp.xml
index 63266d6..ce96243 100755
--- a/android/vision-quickstart/app/src/main/res/drawable-hdpi/ic_switch_camera_white_48dp.xml
+++ b/android/vision-quickstart/app/src/main/res/drawable-hdpi/ic_switch_camera_white_48dp.xml
@@ -1,9 +1,9 @@
-<?xml version="1.0" encoding="utf-8"?>
-<!-- This is an example InsetDrawable. It should be manually reviewed. -->
-<inset xmlns:android="http://schemas.android.com/apk/res/android"
-    android:drawable="@drawable/ic_switch_camera_white_48dp_inset"
-    android:insetTop="3.333333492dp"
-    android:insetLeft="3.333333492dp"
-    android:insetBottom="7.333333492dp"
-    android:insetRight="3.333333492dp"
-    android:visible="true" />
+<?xml version="1.0" encoding="utf-8"?>
+<!-- This is an example InsetDrawable. It should be manually reviewed. -->
+<inset xmlns:android="http://schemas.android.com/apk/res/android"
+    android:drawable="@drawable/ic_switch_camera_white_48dp_inset"
+    android:insetTop="3.333333492dp"
+    android:insetLeft="3.333333492dp"
+    android:insetBottom="7.333333492dp"
+    android:insetRight="3.333333492dp"
+    android:visible="true" />
diff --git a/android/vision-quickstart/app/src/main/res/drawable-mdpi/ic_switch_camera_white_48dp.xml b/android/vision-quickstart/app/src/main/res/drawable-mdpi/ic_switch_camera_white_48dp.xml
index 38c8412..8f3d98c 100755
--- a/android/vision-quickstart/app/src/main/res/drawable-mdpi/ic_switch_camera_white_48dp.xml
+++ b/android/vision-quickstart/app/src/main/res/drawable-mdpi/ic_switch_camera_white_48dp.xml
@@ -1,9 +1,9 @@
-<?xml version="1.0" encoding="utf-8"?>
-<!-- This is an example InsetDrawable. It should be manually reviewed. -->
-<inset xmlns:android="http://schemas.android.com/apk/res/android"
-    android:drawable="@drawable/ic_switch_camera_white_48dp_inset"
-    android:insetTop="3dp"
-    android:insetLeft="3dp"
-    android:insetBottom="7dp"
-    android:insetRight="3dp"
-    android:visible="true" />
+<?xml version="1.0" encoding="utf-8"?>
+<!-- This is an example InsetDrawable. It should be manually reviewed. -->
+<inset xmlns:android="http://schemas.android.com/apk/res/android"
+    android:drawable="@drawable/ic_switch_camera_white_48dp_inset"
+    android:insetTop="3dp"
+    android:insetLeft="3dp"
+    android:insetBottom="7dp"
+    android:insetRight="3dp"
+    android:visible="true" />
diff --git a/android/vision-quickstart/app/src/main/res/drawable-xhdpi/ic_switch_camera_white_48dp.xml b/android/vision-quickstart/app/src/main/res/drawable-xhdpi/ic_switch_camera_white_48dp.xml
index fb06b0c..c8b43fb 100755
--- a/android/vision-quickstart/app/src/main/res/drawable-xhdpi/ic_switch_camera_white_48dp.xml
+++ b/android/vision-quickstart/app/src/main/res/drawable-xhdpi/ic_switch_camera_white_48dp.xml
@@ -1,9 +1,9 @@
-<?xml version="1.0" encoding="utf-8"?>
-<!-- This is an example InsetDrawable. It should be manually reviewed. -->
-<inset xmlns:android="http://schemas.android.com/apk/res/android"
-    android:drawable="@drawable/ic_switch_camera_white_48dp_inset"
-    android:insetTop="3.5dp"
-    android:insetLeft="3.5dp"
-    android:insetBottom="7.5dp"
-    android:insetRight="3.5dp"
-    android:visible="true" />
+<?xml version="1.0" encoding="utf-8"?>
+<!-- This is an example InsetDrawable. It should be manually reviewed. -->
+<inset xmlns:android="http://schemas.android.com/apk/res/android"
+    android:drawable="@drawable/ic_switch_camera_white_48dp_inset"
+    android:insetTop="3.5dp"
+    android:insetLeft="3.5dp"
+    android:insetBottom="7.5dp"
+    android:insetRight="3.5dp"
+    android:visible="true" />
diff --git a/android/vision-quickstart/app/src/main/res/drawable-xxhdpi/ic_switch_camera_white_48dp.xml b/android/vision-quickstart/app/src/main/res/drawable-xxhdpi/ic_switch_camera_white_48dp.xml
index a814bfe..1f123ee 100755
--- a/android/vision-quickstart/app/src/main/res/drawable-xxhdpi/ic_switch_camera_white_48dp.xml
+++ b/android/vision-quickstart/app/src/main/res/drawable-xxhdpi/ic_switch_camera_white_48dp.xml
@@ -1,9 +1,9 @@
-<?xml version="1.0" encoding="utf-8"?>
-<!-- This is an example InsetDrawable. It should be manually reviewed. -->
-<inset xmlns:android="http://schemas.android.com/apk/res/android"
-    android:drawable="@drawable/ic_switch_camera_white_48dp_inset"
-    android:insetTop="3.666666746dp"
-    android:insetLeft="3.666666746dp"
-    android:insetBottom="7.666666985dp"
-    android:insetRight="3.666666746dp"
-    android:visible="true" />
+<?xml version="1.0" encoding="utf-8"?>
+<!-- This is an example InsetDrawable. It should be manually reviewed. -->
+<inset xmlns:android="http://schemas.android.com/apk/res/android"
+    android:drawable="@drawable/ic_switch_camera_white_48dp_inset"
+    android:insetTop="3.666666746dp"
+    android:insetLeft="3.666666746dp"
+    android:insetBottom="7.666666985dp"
+    android:insetRight="3.666666746dp"
+    android:visible="true" />
diff --git a/android/vision-quickstart/app/src/main/res/drawable-xxxhdpi/ic_switch_camera_white_48dp.xml b/android/vision-quickstart/app/src/main/res/drawable-xxxhdpi/ic_switch_camera_white_48dp.xml
index e3c887f..031e1f7 100755
--- a/android/vision-quickstart/app/src/main/res/drawable-xxxhdpi/ic_switch_camera_white_48dp.xml
+++ b/android/vision-quickstart/app/src/main/res/drawable-xxxhdpi/ic_switch_camera_white_48dp.xml
@@ -1,9 +1,9 @@
-<?xml version="1.0" encoding="utf-8"?>
-<!-- This is an example InsetDrawable. It should be manually reviewed. -->
-<inset xmlns:android="http://schemas.android.com/apk/res/android"
-    android:drawable="@drawable/ic_switch_camera_white_48dp_inset"
-    android:insetTop="3.75dp"
-    android:insetLeft="3.75dp"
-    android:insetBottom="7.75dp"
-    android:insetRight="3.75dp"
-    android:visible="true" />
+<?xml version="1.0" encoding="utf-8"?>
+<!-- This is an example InsetDrawable. It should be manually reviewed. -->
+<inset xmlns:android="http://schemas.android.com/apk/res/android"
+    android:drawable="@drawable/ic_switch_camera_white_48dp_inset"
+    android:insetTop="3.75dp"
+    android:insetLeft="3.75dp"
+    android:insetBottom="7.75dp"
+    android:insetRight="3.75dp"
+    android:visible="true" />
diff --git a/android/vision-quickstart/app/src/main/res/drawable/list_item_background.xml b/android/vision-quickstart/app/src/main/res/drawable/list_item_background.xml
index c72c0e5..cbfd883 100644
--- a/android/vision-quickstart/app/src/main/res/drawable/list_item_background.xml
+++ b/android/vision-quickstart/app/src/main/res/drawable/list_item_background.xml
@@ -1,9 +1,9 @@
-<?xml version="1.0" encoding="utf-8"?>
-<shape xmlns:android="http://schemas.android.com/apk/res/android"
-    android:shape="rectangle" >
-    <stroke android:width="3dip" android:color="@color/blue"/>
-    <corners android:bottomRightRadius="16dp"
-        android:bottomLeftRadius="16dp"
-        android:topLeftRadius="16dp"
-        android:topRightRadius="16dp" />
+<?xml version="1.0" encoding="utf-8"?>
+<shape xmlns:android="http://schemas.android.com/apk/res/android"
+    android:shape="rectangle" >
+    <stroke android:width="3dip" android:color="@color/blue"/>
+    <corners android:bottomRightRadius="16dp"
+        android:bottomLeftRadius="16dp"
+        android:topLeftRadius="16dp"
+        android:topRightRadius="16dp" />
 </shape>
\ No newline at end of file
diff --git a/android/vision-quickstart/app/src/main/res/drawable/logo_mlkit.xml b/android/vision-quickstart/app/src/main/res/drawable/logo_mlkit.xml
index 1d256e0..b9b272c 100755
--- a/android/vision-quickstart/app/src/main/res/drawable/logo_mlkit.xml
+++ b/android/vision-quickstart/app/src/main/res/drawable/logo_mlkit.xml
@@ -1,42 +1,42 @@
-<?xml version="1.0" encoding="utf-8"?>
-<vector xmlns:android="http://schemas.android.com/apk/res/android"
-    xmlns:tools="http://schemas.android.com/tools"
-    tools:ignore="NewApi"
-    android:width="172dp"
-    android:height="129dp"
-    android:viewportWidth="172.43"
-    android:viewportHeight="129.06">
-    <path
-        android:fillColor="#4285f4"
-        android:pathData="M1.102,114.948l57.68,-109.632l16.815,8.847l-57.68,109.632z" />
-    <path
-        android:fillColor="#0d47a1"
-        android:pathData="M9.5,119.43m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
-    <path
-        android:fillColor="#abccfc"
-        android:pathData="M57.69,9.76h19v109.85h-19z" />
-    <path
-        android:fillColor="#0d47a1"
-        android:pathData="M67.19,9.76m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
-    <path
-        android:fillColor="#4285f4"
-        android:pathData="M58.779,114.962l57.68,-109.632l16.815,8.847l-57.68,109.632z" />
-    <path
-        android:fillColor="#abccfc"
-        android:pathData="M115.38,9.76h19v109.85h-19z" />
-    <path
-        android:fillColor="#4285f4"
-        android:pathData="M124.88,109.93h38.39v19h-38.39z" />
-    <path
-        android:fillColor="#0d47a1"
-        android:pathData="M124.88,119.43m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
-    <path
-        android:fillColor="#0d47a1"
-        android:pathData="M163.26,119.43m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
-    <path
-        android:fillColor="#0d47a1"
-        android:pathData="M124.88,9.76m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
-    <path
-        android:fillColor="#0d47a1"
-        android:pathData="M67.19,119.43m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
-</vector>
+<?xml version="1.0" encoding="utf-8"?>
+<vector xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:tools="http://schemas.android.com/tools"
+    tools:ignore="NewApi"
+    android:width="172dp"
+    android:height="129dp"
+    android:viewportWidth="172.43"
+    android:viewportHeight="129.06">
+    <path
+        android:fillColor="#4285f4"
+        android:pathData="M1.102,114.948l57.68,-109.632l16.815,8.847l-57.68,109.632z" />
+    <path
+        android:fillColor="#0d47a1"
+        android:pathData="M9.5,119.43m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
+    <path
+        android:fillColor="#abccfc"
+        android:pathData="M57.69,9.76h19v109.85h-19z" />
+    <path
+        android:fillColor="#0d47a1"
+        android:pathData="M67.19,9.76m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
+    <path
+        android:fillColor="#4285f4"
+        android:pathData="M58.779,114.962l57.68,-109.632l16.815,8.847l-57.68,109.632z" />
+    <path
+        android:fillColor="#abccfc"
+        android:pathData="M115.38,9.76h19v109.85h-19z" />
+    <path
+        android:fillColor="#4285f4"
+        android:pathData="M124.88,109.93h38.39v19h-38.39z" />
+    <path
+        android:fillColor="#0d47a1"
+        android:pathData="M124.88,119.43m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
+    <path
+        android:fillColor="#0d47a1"
+        android:pathData="M163.26,119.43m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
+    <path
+        android:fillColor="#0d47a1"
+        android:pathData="M124.88,9.76m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
+    <path
+        android:fillColor="#0d47a1"
+        android:pathData="M67.19,119.43m-9.5,0a9.5,9.5 0,1 1,19 0a9.5,9.5 0,1 1,-19 0" />
+</vector>
diff --git a/android/vision-quickstart/app/src/main/res/layout-land/activity_camerax_live_preview.xml b/android/vision-quickstart/app/src/main/res/layout-land/activity_camerax_live_preview.xml
index 45397d5..09c9d3e 100755
--- a/android/vision-quickstart/app/src/main/res/layout-land/activity_camerax_live_preview.xml
+++ b/android/vision-quickstart/app/src/main/res/layout-land/activity_camerax_live_preview.xml
@@ -1,57 +1,57 @@
-<?xml version="1.0" encoding="utf-8"?>
-<androidx.constraintlayout.widget.ConstraintLayout
-    xmlns:android="http://schemas.android.com/apk/res/android"
-    xmlns:app="http://schemas.android.com/apk/res-auto"
-    android:layout_width="match_parent"
-    android:layout_height="match_parent"
-    android:keepScreenOn="true">
-
-  <androidx.camera.view.PreviewView
-      android:id="@+id/preview_view"
-      android:layout_width="0dp"
-      android:layout_height="match_parent"
-      app:layout_constraintStart_toStartOf="parent"
-      app:layout_constraintEnd_toStartOf="@+id/control"/>
-
-  <com.google.mlkit.vision.demo.GraphicOverlay
-      android:id="@+id/graphic_overlay"
-      android:layout_width="0dp"
-      android:layout_height="match_parent"
-      app:layout_constraintStart_toStartOf="@id/preview_view"
-      app:layout_constraintEnd_toEndOf="@id/preview_view" />
-
-  <FrameLayout
-      android:id="@id/control"
-      android:layout_width="220dp"
-      android:layout_height="match_parent"
-      app:layout_constraintStart_toEndOf="@id/preview_view"
-      app:layout_constraintEnd_toEndOf="parent"
-      android:background="#000">
-
-    <Spinner
-        android:id="@+id/spinner"
-        android:layout_width="match_parent"
-        android:layout_height="wrap_content"
-        android:layout_gravity="top"/>
-
-    <ToggleButton
-        android:id="@+id/facing_switch"
-        android:layout_width="48dp"
-        android:layout_height="48dp"
-        android:layout_gravity="bottom|start"
-        android:background="@layout/toggle_style"
-        android:checked="false"
-        android:textOff=""
-        android:textOn=""/>
-
-    <ImageView
-        android:id="@+id/settings_button"
-        android:layout_width="wrap_content"
-        android:layout_height="wrap_content"
-        android:layout_gravity="bottom|end"
-        android:padding="12dp"
-        android:contentDescription="@string/menu_item_settings"
-        android:src="@drawable/ic_settings_white_24dp"/>
-  </FrameLayout>
-
-</androidx.constraintlayout.widget.ConstraintLayout>
+<?xml version="1.0" encoding="utf-8"?>
+<androidx.constraintlayout.widget.ConstraintLayout
+    xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:app="http://schemas.android.com/apk/res-auto"
+    android:layout_width="match_parent"
+    android:layout_height="match_parent"
+    android:keepScreenOn="true">
+
+  <androidx.camera.view.PreviewView
+      android:id="@+id/preview_view"
+      android:layout_width="0dp"
+      android:layout_height="match_parent"
+      app:layout_constraintStart_toStartOf="parent"
+      app:layout_constraintEnd_toStartOf="@+id/control"/>
+
+  <com.google.mlkit.vision.demo.GraphicOverlay
+      android:id="@+id/graphic_overlay"
+      android:layout_width="0dp"
+      android:layout_height="match_parent"
+      app:layout_constraintStart_toStartOf="@id/preview_view"
+      app:layout_constraintEnd_toEndOf="@id/preview_view" />
+
+  <FrameLayout
+      android:id="@id/control"
+      android:layout_width="220dp"
+      android:layout_height="match_parent"
+      app:layout_constraintStart_toEndOf="@id/preview_view"
+      app:layout_constraintEnd_toEndOf="parent"
+      android:background="#000">
+
+    <Spinner
+        android:id="@+id/spinner"
+        android:layout_width="match_parent"
+        android:layout_height="wrap_content"
+        android:layout_gravity="top"/>
+
+    <ToggleButton
+        android:id="@+id/facing_switch"
+        android:layout_width="48dp"
+        android:layout_height="48dp"
+        android:layout_gravity="bottom|start"
+        android:background="@layout/toggle_style"
+        android:checked="false"
+        android:textOff=""
+        android:textOn=""/>
+
+    <ImageView
+        android:id="@+id/settings_button"
+        android:layout_width="wrap_content"
+        android:layout_height="wrap_content"
+        android:layout_gravity="bottom|end"
+        android:padding="12dp"
+        android:contentDescription="@string/menu_item_settings"
+        android:src="@drawable/ic_settings_white_24dp"/>
+  </FrameLayout>
+
+</androidx.constraintlayout.widget.ConstraintLayout>
diff --git a/android/vision-quickstart/app/src/main/res/layout-land/activity_live_preview.xml b/android/vision-quickstart/app/src/main/res/layout-land/activity_live_preview.xml
index 049056c..348ee19 100755
--- a/android/vision-quickstart/app/src/main/res/layout-land/activity_live_preview.xml
+++ b/android/vision-quickstart/app/src/main/res/layout-land/activity_live_preview.xml
@@ -1,55 +1,55 @@
-<?xml version="1.0" encoding="utf-8"?>
-<RelativeLayout
-    xmlns:android="http://schemas.android.com/apk/res/android"
-    android:orientation="horizontal"
-    android:layout_width="match_parent"
-    android:layout_height="match_parent"
-    android:background="#000"
-    android:keepScreenOn="true">
-
-  <com.google.mlkit.vision.demo.CameraSourcePreview
-      android:id="@+id/preview"
-      android:layout_width="match_parent"
-      android:layout_height="match_parent">
-
-    <com.google.mlkit.vision.demo.GraphicOverlay
-        android:id="@+id/graphic_overlay"
-        android:layout_width="match_parent"
-        android:layout_height="match_parent" />
-
-  </com.google.mlkit.vision.demo.CameraSourcePreview>
-
-  <FrameLayout
-      android:id="@+id/control"
-      android:layout_width="220dp"
-      android:layout_height="match_parent"
-      android:layout_alignParentRight="true"
-      android:layout_alignParentTop="true"
-      android:background="#000" >
-
-      <Spinner
-          android:id="@+id/spinner"
-          android:layout_width="match_parent"
-          android:layout_height="wrap_content"
-          android:layout_gravity="center_horizontal" />
-
-      <ToggleButton
-          android:id="@+id/facing_switch"
-          android:layout_width="48dp"
-          android:layout_height="48dp"
-          android:layout_gravity="bottom|start"
-          android:background="@layout/toggle_style"
-          android:textOff=""
-          android:textOn=""
-          android:checked="false" />
-
-      <include
-          layout="@layout/settings_style"
-          android:id="@+id/settings_button"
-          android:layout_width="wrap_content"
-          android:layout_height="wrap_content"
-          android:layout_gravity="bottom|end"/>
-
-  </FrameLayout>
-
-</RelativeLayout>
+<?xml version="1.0" encoding="utf-8"?>
+<RelativeLayout
+    xmlns:android="http://schemas.android.com/apk/res/android"
+    android:orientation="horizontal"
+    android:layout_width="match_parent"
+    android:layout_height="match_parent"
+    android:background="#000"
+    android:keepScreenOn="true">
+
+  <com.google.mlkit.vision.demo.CameraSourcePreview
+      android:id="@+id/preview"
+      android:layout_width="match_parent"
+      android:layout_height="match_parent">
+
+    <com.google.mlkit.vision.demo.GraphicOverlay
+        android:id="@+id/graphic_overlay"
+        android:layout_width="match_parent"
+        android:layout_height="match_parent" />
+
+  </com.google.mlkit.vision.demo.CameraSourcePreview>
+
+  <FrameLayout
+      android:id="@+id/control"
+      android:layout_width="220dp"
+      android:layout_height="match_parent"
+      android:layout_alignParentRight="true"
+      android:layout_alignParentTop="true"
+      android:background="#000" >
+
+      <Spinner
+          android:id="@+id/spinner"
+          android:layout_width="match_parent"
+          android:layout_height="wrap_content"
+          android:layout_gravity="center_horizontal" />
+
+      <ToggleButton
+          android:id="@+id/facing_switch"
+          android:layout_width="48dp"
+          android:layout_height="48dp"
+          android:layout_gravity="bottom|start"
+          android:background="@layout/toggle_style"
+          android:textOff=""
+          android:textOn=""
+          android:checked="false" />
+
+      <include
+          layout="@layout/settings_style"
+          android:id="@+id/settings_button"
+          android:layout_width="wrap_content"
+          android:layout_height="wrap_content"
+          android:layout_gravity="bottom|end"/>
+
+  </FrameLayout>
+
+</RelativeLayout>
diff --git a/android/vision-quickstart/app/src/main/res/layout/activity_camerax_live_preview.xml b/android/vision-quickstart/app/src/main/res/layout/activity_camerax_live_preview.xml
index e997ab8..bca50c3 100755
--- a/android/vision-quickstart/app/src/main/res/layout/activity_camerax_live_preview.xml
+++ b/android/vision-quickstart/app/src/main/res/layout/activity_camerax_live_preview.xml
@@ -1,61 +1,61 @@
-<?xml version="1.0" encoding="utf-8"?>
-<androidx.constraintlayout.widget.ConstraintLayout
-    xmlns:android="http://schemas.android.com/apk/res/android"
-    xmlns:app="http://schemas.android.com/apk/res-auto"
-    android:layout_width="match_parent"
-    android:layout_height="match_parent"
-    android:keepScreenOn="true">
-
-  <androidx.camera.view.PreviewView
-      android:id="@+id/preview_view"
-      android:layout_width="match_parent"
-      android:layout_height="0dp"
-      app:layout_constraintTop_toTopOf="parent"
-      app:layout_constraintBottom_toTopOf="@+id/control"/>
-
-  <com.google.mlkit.vision.demo.GraphicOverlay
-      android:id="@+id/graphic_overlay"
-      android:layout_width="0dp"
-      android:layout_height="0dp"
-      app:layout_constraintLeft_toLeftOf="@id/preview_view"
-      app:layout_constraintRight_toRightOf="@id/preview_view"
-      app:layout_constraintTop_toTopOf="@id/preview_view"
-      app:layout_constraintBottom_toBottomOf="@id/preview_view"/>
-
-  <include
-      android:id="@+id/settings_button"
-      layout="@layout/settings_style"
-      android:layout_width="wrap_content"
-      android:layout_height="wrap_content"
-      app:layout_constraintRight_toRightOf="@id/preview_view"
-      app:layout_constraintTop_toTopOf="@id/preview_view" />
-
-  <LinearLayout
-      android:id="@id/control"
-      android:layout_width="match_parent"
-      android:layout_height="60dp"
-      app:layout_constraintTop_toBottomOf="@id/preview_view"
-      app:layout_constraintBottom_toBottomOf="parent"
-      android:background="#000"
-      android:orientation="horizontal">
-
-    <ToggleButton
-        android:id="@+id/facing_switch"
-        android:layout_width="48dp"
-        android:layout_height="48dp"
-        android:layout_gravity="center_vertical"
-        android:background="@layout/toggle_style"
-        android:checked="false"
-        android:textOff=""
-        android:textOn=""/>
-
-    <Spinner
-        android:id="@+id/spinner"
-        android:layout_width="0dp"
-        android:layout_weight="1"
-        android:layout_height="wrap_content"
-        android:layout_gravity="center"/>
-
-  </LinearLayout>
-
-</androidx.constraintlayout.widget.ConstraintLayout>
+<?xml version="1.0" encoding="utf-8"?>
+<androidx.constraintlayout.widget.ConstraintLayout
+    xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:app="http://schemas.android.com/apk/res-auto"
+    android:layout_width="match_parent"
+    android:layout_height="match_parent"
+    android:keepScreenOn="true">
+
+  <androidx.camera.view.PreviewView
+      android:id="@+id/preview_view"
+      android:layout_width="match_parent"
+      android:layout_height="0dp"
+      app:layout_constraintTop_toTopOf="parent"
+      app:layout_constraintBottom_toTopOf="@+id/control"/>
+
+  <com.google.mlkit.vision.demo.GraphicOverlay
+      android:id="@+id/graphic_overlay"
+      android:layout_width="0dp"
+      android:layout_height="0dp"
+      app:layout_constraintLeft_toLeftOf="@id/preview_view"
+      app:layout_constraintRight_toRightOf="@id/preview_view"
+      app:layout_constraintTop_toTopOf="@id/preview_view"
+      app:layout_constraintBottom_toBottomOf="@id/preview_view"/>
+
+  <include
+      android:id="@+id/settings_button"
+      layout="@layout/settings_style"
+      android:layout_width="wrap_content"
+      android:layout_height="wrap_content"
+      app:layout_constraintRight_toRightOf="@id/preview_view"
+      app:layout_constraintTop_toTopOf="@id/preview_view" />
+
+  <LinearLayout
+      android:id="@id/control"
+      android:layout_width="match_parent"
+      android:layout_height="60dp"
+      app:layout_constraintTop_toBottomOf="@id/preview_view"
+      app:layout_constraintBottom_toBottomOf="parent"
+      android:background="#000"
+      android:orientation="horizontal">
+
+    <ToggleButton
+        android:id="@+id/facing_switch"
+        android:layout_width="48dp"
+        android:layout_height="48dp"
+        android:layout_gravity="center_vertical"
+        android:background="@layout/toggle_style"
+        android:checked="false"
+        android:textOff=""
+        android:textOn=""/>
+
+    <Spinner
+        android:id="@+id/spinner"
+        android:layout_width="0dp"
+        android:layout_weight="1"
+        android:layout_height="wrap_content"
+        android:layout_gravity="center"/>
+
+  </LinearLayout>
+
+</androidx.constraintlayout.widget.ConstraintLayout>
diff --git a/android/vision-quickstart/app/src/main/res/layout/activity_chooser.xml b/android/vision-quickstart/app/src/main/res/layout/activity_chooser.xml
index 01e0d79..f0a2270 100755
--- a/android/vision-quickstart/app/src/main/res/layout/activity_chooser.xml
+++ b/android/vision-quickstart/app/src/main/res/layout/activity_chooser.xml
@@ -1,35 +1,35 @@
-<?xml version="1.0" encoding="utf-8"?>
-<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
-    xmlns:app="http://schemas.android.com/apk/res-auto"
-    android:layout_width="match_parent"
-    android:layout_height="match_parent"
-    android:paddingTop="@dimen/activity_vertical_margin"
-    android:paddingBottom="@dimen/activity_vertical_margin"
-    android:paddingLeft="@dimen/activity_horizontal_margin"
-    android:paddingRight="@dimen/activity_horizontal_margin"
-    android:orientation="vertical">
-
-  <ImageView
-      android:id="@+id/imageView"
-      android:contentDescription="@string/app_name"
-      android:layout_width="match_parent"
-      android:layout_height="50dp"
-      android:layout_marginTop="32dp"
-      app:srcCompat="@drawable/logo_mlkit" />
-
-  <TextView
-      android:layout_width="match_parent"
-      android:layout_height="wrap_content"
-      android:paddingTop="32dp"
-      android:paddingBottom="32dp"
-      android:fontFamily="google-sans"
-      android:gravity="center_horizontal"
-      android:text="@string/app_name"
-      android:textColor="@color/white"
-      android:textSize="18sp"/>
-
-  <ListView
-      android:id="@+id/test_activity_list_view"
-      android:layout_width="match_parent"
-      android:layout_height="match_parent"/>
-</LinearLayout>
+<?xml version="1.0" encoding="utf-8"?>
+<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:app="http://schemas.android.com/apk/res-auto"
+    android:layout_width="match_parent"
+    android:layout_height="match_parent"
+    android:paddingTop="@dimen/activity_vertical_margin"
+    android:paddingBottom="@dimen/activity_vertical_margin"
+    android:paddingLeft="@dimen/activity_horizontal_margin"
+    android:paddingRight="@dimen/activity_horizontal_margin"
+    android:orientation="vertical">
+
+  <ImageView
+      android:id="@+id/imageView"
+      android:contentDescription="@string/app_name"
+      android:layout_width="match_parent"
+      android:layout_height="50dp"
+      android:layout_marginTop="32dp"
+      app:srcCompat="@drawable/logo_mlkit" />
+
+  <TextView
+      android:layout_width="match_parent"
+      android:layout_height="wrap_content"
+      android:paddingTop="32dp"
+      android:paddingBottom="32dp"
+      android:fontFamily="google-sans"
+      android:gravity="center_horizontal"
+      android:text="@string/app_name"
+      android:textColor="@color/white"
+      android:textSize="18sp"/>
+
+  <ListView
+      android:id="@+id/test_activity_list_view"
+      android:layout_width="match_parent"
+      android:layout_height="match_parent"/>
+</LinearLayout>
diff --git a/android/vision-quickstart/app/src/main/res/layout/activity_entry_choice.xml b/android/vision-quickstart/app/src/main/res/layout/activity_entry_choice.xml
index 0825400..372db4f 100644
--- a/android/vision-quickstart/app/src/main/res/layout/activity_entry_choice.xml
+++ b/android/vision-quickstart/app/src/main/res/layout/activity_entry_choice.xml
@@ -1,31 +1,31 @@
-<?xml version="1.0" encoding="utf-8"?>
-<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
-    android:layout_width="wrap_content"
-    android:layout_height="wrap_content"
-    android:layout_gravity="center"
-    android:paddingTop="@dimen/activity_vertical_margin"
-    android:paddingBottom="@dimen/activity_vertical_margin"
-    android:paddingLeft="@dimen/activity_horizontal_margin"
-    android:paddingRight="@dimen/activity_horizontal_margin"
-    android:orientation="vertical">
-
-    <TextView
-        android:background="@drawable/list_item_background"
-        android:id="@+id/java_entry_point"
-        android:layout_width="wrap_content"
-        android:layout_height="wrap_content"
-        android:layout_margin="@dimen/activity_vertical_margin"
-        android:padding="20dp"
-        android:text="@string/java_entry_title"
-        android:textSize="26sp" />
-
-    <TextView
-        android:background="@drawable/list_item_background"
-        android:id="@+id/kotlin_entry_point"
-        android:layout_width="wrap_content"
-        android:layout_height="wrap_content"
-        android:layout_margin="@dimen/activity_vertical_margin"
-        android:padding="20dp"
-        android:text="@string/kotlin_entry_title"
-        android:textSize="26sp" />
+<?xml version="1.0" encoding="utf-8"?>
+<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
+    android:layout_width="wrap_content"
+    android:layout_height="wrap_content"
+    android:layout_gravity="center"
+    android:paddingTop="@dimen/activity_vertical_margin"
+    android:paddingBottom="@dimen/activity_vertical_margin"
+    android:paddingLeft="@dimen/activity_horizontal_margin"
+    android:paddingRight="@dimen/activity_horizontal_margin"
+    android:orientation="vertical">
+
+    <TextView
+        android:background="@drawable/list_item_background"
+        android:id="@+id/java_entry_point"
+        android:layout_width="wrap_content"
+        android:layout_height="wrap_content"
+        android:layout_margin="@dimen/activity_vertical_margin"
+        android:padding="20dp"
+        android:text="@string/java_entry_title"
+        android:textSize="26sp" />
+
+    <TextView
+        android:background="@drawable/list_item_background"
+        android:id="@+id/kotlin_entry_point"
+        android:layout_width="wrap_content"
+        android:layout_height="wrap_content"
+        android:layout_margin="@dimen/activity_vertical_margin"
+        android:padding="20dp"
+        android:text="@string/kotlin_entry_title"
+        android:textSize="26sp" />
 </LinearLayout>
\ No newline at end of file
diff --git a/android/vision-quickstart/app/src/main/res/layout/activity_live_preview.xml b/android/vision-quickstart/app/src/main/res/layout/activity_live_preview.xml
index bb4dd8d..d757a92 100755
--- a/android/vision-quickstart/app/src/main/res/layout/activity_live_preview.xml
+++ b/android/vision-quickstart/app/src/main/res/layout/activity_live_preview.xml
@@ -1,65 +1,65 @@
-<?xml version="1.0" encoding="utf-8"?>
-<RelativeLayout xmlns:android="http://schemas.android.com/apk/res/android"
-    xmlns:tools="http://schemas.android.com/tools"
-    tools:ignore="RtlHardcoded"
-    android:layout_width="match_parent"
-    android:layout_height="match_parent"
-    android:background="#000"
-    android:keepScreenOn="true"
-    android:orientation="vertical">
-
-  <com.google.mlkit.vision.demo.CameraSourcePreview
-      android:id="@+id/preview"
-      android:layout_width="match_parent"
-      android:layout_height="wrap_content"
-      android:layout_alignParentLeft="true"
-      android:layout_alignParentTop="true">
-
-    <com.google.mlkit.vision.demo.GraphicOverlay
-        android:id="@+id/graphic_overlay"
-        android:layout_width="match_parent"
-        android:layout_height="match_parent"
-        android:layout_alignParentBottom="true"
-        android:layout_alignParentLeft="true"
-        android:layout_alignParentTop="true"/>
-  </com.google.mlkit.vision.demo.CameraSourcePreview>
-
-  <include
-      layout="@layout/settings_style"
-      android:id="@+id/settings_button"
-      android:layout_width="wrap_content"
-      android:layout_height="wrap_content"
-      android:layout_alignParentTop="true"
-      android:layout_alignParentEnd="true"
-      android:layout_alignParentRight="true"/>
-
-  <LinearLayout
-      android:id="@+id/control"
-      android:layout_width="match_parent"
-      android:layout_height="60dp"
-      android:layout_alignParentBottom="true"
-      android:layout_alignParentLeft="true"
-      android:layout_toRightOf="@id/preview"
-      android:background="#000"
-      android:orientation="horizontal">
-
-    <ToggleButton
-        android:id="@+id/facing_switch"
-        android:layout_width="48dp"
-        android:layout_height="48dp"
-        android:layout_gravity="center_vertical"
-        android:background="@layout/toggle_style"
-        android:checked="false"
-        android:textOff=""
-        android:textOn=""/>
-
-    <Spinner
-        android:id="@+id/spinner"
-        android:layout_width="0dp"
-        android:layout_weight="1"
-        android:layout_height="wrap_content"
-        android:layout_gravity="center"/>
-
-  </LinearLayout>
-
-</RelativeLayout>
+<?xml version="1.0" encoding="utf-8"?>
+<RelativeLayout xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:tools="http://schemas.android.com/tools"
+    tools:ignore="RtlHardcoded"
+    android:layout_width="match_parent"
+    android:layout_height="match_parent"
+    android:background="#000"
+    android:keepScreenOn="true"
+    android:orientation="vertical">
+
+  <com.google.mlkit.vision.demo.CameraSourcePreview
+      android:id="@+id/preview"
+      android:layout_width="match_parent"
+      android:layout_height="wrap_content"
+      android:layout_alignParentLeft="true"
+      android:layout_alignParentTop="true">
+
+    <com.google.mlkit.vision.demo.GraphicOverlay
+        android:id="@+id/graphic_overlay"
+        android:layout_width="match_parent"
+        android:layout_height="match_parent"
+        android:layout_alignParentBottom="true"
+        android:layout_alignParentLeft="true"
+        android:layout_alignParentTop="true"/>
+  </com.google.mlkit.vision.demo.CameraSourcePreview>
+
+  <include
+      layout="@layout/settings_style"
+      android:id="@+id/settings_button"
+      android:layout_width="wrap_content"
+      android:layout_height="wrap_content"
+      android:layout_alignParentTop="true"
+      android:layout_alignParentEnd="true"
+      android:layout_alignParentRight="true"/>
+
+  <LinearLayout
+      android:id="@+id/control"
+      android:layout_width="match_parent"
+      android:layout_height="60dp"
+      android:layout_alignParentBottom="true"
+      android:layout_alignParentLeft="true"
+      android:layout_toRightOf="@id/preview"
+      android:background="#000"
+      android:orientation="horizontal">
+
+    <ToggleButton
+        android:id="@+id/facing_switch"
+        android:layout_width="48dp"
+        android:layout_height="48dp"
+        android:layout_gravity="center_vertical"
+        android:background="@layout/toggle_style"
+        android:checked="false"
+        android:textOff=""
+        android:textOn=""/>
+
+    <Spinner
+        android:id="@+id/spinner"
+        android:layout_width="0dp"
+        android:layout_weight="1"
+        android:layout_height="wrap_content"
+        android:layout_gravity="center"/>
+
+  </LinearLayout>
+
+</RelativeLayout>
diff --git a/android/vision-quickstart/app/src/main/res/layout/activity_settings.xml b/android/vision-quickstart/app/src/main/res/layout/activity_settings.xml
index 9c37b46..df7a2a7 100755
--- a/android/vision-quickstart/app/src/main/res/layout/activity_settings.xml
+++ b/android/vision-quickstart/app/src/main/res/layout/activity_settings.xml
@@ -1,8 +1,8 @@
-<?xml version="1.0" encoding="utf-8"?>
-<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
-    android:id="@+id/settings_container"
-    android:layout_width="match_parent"
-    android:layout_height="match_parent"
-    android:orientation="vertical">
-
-</LinearLayout>
+<?xml version="1.0" encoding="utf-8"?>
+<LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
+    android:id="@+id/settings_container"
+    android:layout_width="match_parent"
+    android:layout_height="match_parent"
+    android:orientation="vertical">
+
+</LinearLayout>
diff --git a/android/vision-quickstart/app/src/main/res/layout/activity_still_image.xml b/android/vision-quickstart/app/src/main/res/layout/activity_still_image.xml
index 6fe8d0a..f9cddaf 100755
--- a/android/vision-quickstart/app/src/main/res/layout/activity_still_image.xml
+++ b/android/vision-quickstart/app/src/main/res/layout/activity_still_image.xml
@@ -1,77 +1,77 @@
-<?xml version="1.0" encoding="utf-8"?>
-<androidx.constraintlayout.widget.ConstraintLayout
-    xmlns:android="http://schemas.android.com/apk/res/android"
-    xmlns:app="http://schemas.android.com/apk/res-auto"
-    android:id="@+id/root"
-    android:layout_width="match_parent"
-    android:layout_height="match_parent"
-    android:keepScreenOn="true">
-
-  <ImageView
-      android:id="@+id/preview"
-      android:layout_width="wrap_content"
-      android:layout_height="wrap_content"
-      android:adjustViewBounds="true"
-      app:layout_constraintBottom_toTopOf="@+id/control"
-      app:layout_constraintEnd_toEndOf="parent"
-      app:layout_constraintStart_toStartOf="parent"
-      app:layout_constraintTop_toTopOf="parent" />
-
-  <com.google.mlkit.vision.demo.GraphicOverlay
-      android:id="@+id/graphic_overlay"
-      android:layout_width="0dp"
-      android:layout_height="0dp"
-      app:layout_constraintLeft_toLeftOf="@id/preview"
-      app:layout_constraintRight_toRightOf="@id/preview"
-      app:layout_constraintTop_toTopOf="@id/preview"
-      app:layout_constraintBottom_toBottomOf="@id/preview"/>
-
-  <LinearLayout
-      android:id="@id/control"
-      android:layout_width="match_parent"
-      android:layout_height="wrap_content"
-      app:layout_constraintBottom_toBottomOf="parent"
-      android:background="#000"
-      android:orientation="vertical">
-
-    <Button
-        android:id="@+id/select_image_button"
-        android:layout_width="wrap_content"
-        android:layout_height="wrap_content"
-        android:layout_gravity="center"
-        android:layout_margin="12dp"
-        android:text="@string/select_image"/>
-
-    <LinearLayout
-        android:id="@+id/control2"
-        android:layout_width="match_parent"
-        android:layout_height="60dp"
-        app:layout_constraintBottom_toBottomOf="parent"
-        android:background="#000"
-        android:orientation="horizontal">
-
-      <Spinner
-          android:id="@+id/size_selector"
-          android:layout_width="0dp"
-          android:layout_weight="1"
-          android:layout_height="wrap_content"
-          android:layout_gravity="center"/>
-
-      <Spinner
-          android:id="@+id/feature_selector"
-          android:layout_width="0dp"
-          android:layout_weight="1"
-          android:layout_height="wrap_content"
-          android:layout_gravity="center"/>
-    </LinearLayout>
-  </LinearLayout>
-
-  <include
-      layout="@layout/settings_style"
-      android:id="@+id/settings_button"
-      android:layout_width="wrap_content"
-      android:layout_height="wrap_content"
-      app:layout_constraintRight_toRightOf="@id/root"
-      app:layout_constraintTop_toTopOf="@id/root"/>
-
-</androidx.constraintlayout.widget.ConstraintLayout>
+<?xml version="1.0" encoding="utf-8"?>
+<androidx.constraintlayout.widget.ConstraintLayout
+    xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:app="http://schemas.android.com/apk/res-auto"
+    android:id="@+id/root"
+    android:layout_width="match_parent"
+    android:layout_height="match_parent"
+    android:keepScreenOn="true">
+
+  <ImageView
+      android:id="@+id/preview"
+      android:layout_width="wrap_content"
+      android:layout_height="wrap_content"
+      android:adjustViewBounds="true"
+      app:layout_constraintBottom_toTopOf="@+id/control"
+      app:layout_constraintEnd_toEndOf="parent"
+      app:layout_constraintStart_toStartOf="parent"
+      app:layout_constraintTop_toTopOf="parent" />
+
+  <com.google.mlkit.vision.demo.GraphicOverlay
+      android:id="@+id/graphic_overlay"
+      android:layout_width="0dp"
+      android:layout_height="0dp"
+      app:layout_constraintLeft_toLeftOf="@id/preview"
+      app:layout_constraintRight_toRightOf="@id/preview"
+      app:layout_constraintTop_toTopOf="@id/preview"
+      app:layout_constraintBottom_toBottomOf="@id/preview"/>
+
+  <LinearLayout
+      android:id="@id/control"
+      android:layout_width="match_parent"
+      android:layout_height="wrap_content"
+      app:layout_constraintBottom_toBottomOf="parent"
+      android:background="#000"
+      android:orientation="vertical">
+
+    <Button
+        android:id="@+id/select_image_button"
+        android:layout_width="wrap_content"
+        android:layout_height="wrap_content"
+        android:layout_gravity="center"
+        android:layout_margin="12dp"
+        android:text="@string/select_image"/>
+
+    <LinearLayout
+        android:id="@+id/control2"
+        android:layout_width="match_parent"
+        android:layout_height="60dp"
+        app:layout_constraintBottom_toBottomOf="parent"
+        android:background="#000"
+        android:orientation="horizontal">
+
+      <Spinner
+          android:id="@+id/size_selector"
+          android:layout_width="0dp"
+          android:layout_weight="1"
+          android:layout_height="wrap_content"
+          android:layout_gravity="center"/>
+
+      <Spinner
+          android:id="@+id/feature_selector"
+          android:layout_width="0dp"
+          android:layout_weight="1"
+          android:layout_height="wrap_content"
+          android:layout_gravity="center"/>
+    </LinearLayout>
+  </LinearLayout>
+
+  <include
+      layout="@layout/settings_style"
+      android:id="@+id/settings_button"
+      android:layout_width="wrap_content"
+      android:layout_height="wrap_content"
+      app:layout_constraintRight_toRightOf="@id/root"
+      app:layout_constraintTop_toTopOf="@id/root"/>
+
+</androidx.constraintlayout.widget.ConstraintLayout>
diff --git a/android/vision-quickstart/app/src/main/res/layout/settings_style.xml b/android/vision-quickstart/app/src/main/res/layout/settings_style.xml
index 8505ae1..cbda720 100755
--- a/android/vision-quickstart/app/src/main/res/layout/settings_style.xml
+++ b/android/vision-quickstart/app/src/main/res/layout/settings_style.xml
@@ -1,8 +1,8 @@
-<?xml version="1.0" encoding="utf-8"?>
-<ImageView
-    xmlns:android="http://schemas.android.com/apk/res/android"
-    android:layout_width="wrap_content"
-    android:layout_height="wrap_content"
-    android:padding="12dp"
-    android:contentDescription="@string/menu_item_settings"
-    android:src="@drawable/ic_settings_white_24dp"/>
+<?xml version="1.0" encoding="utf-8"?>
+<ImageView
+    xmlns:android="http://schemas.android.com/apk/res/android"
+    android:layout_width="wrap_content"
+    android:layout_height="wrap_content"
+    android:padding="12dp"
+    android:contentDescription="@string/menu_item_settings"
+    android:src="@drawable/ic_settings_white_24dp"/>
diff --git a/android/vision-quickstart/app/src/main/res/layout/spinner_style.xml b/android/vision-quickstart/app/src/main/res/layout/spinner_style.xml
index 40949dc..66d9120 100755
--- a/android/vision-quickstart/app/src/main/res/layout/spinner_style.xml
+++ b/android/vision-quickstart/app/src/main/res/layout/spinner_style.xml
@@ -1,10 +1,10 @@
-<?xml version="1.0" encoding="utf-8"?>
-<TextView
-    xmlns:android="http://schemas.android.com/apk/res/android"
-    android:textStyle="bold"
-    android:layout_width="match_parent"
-    android:layout_height="wrap_content"
-    android:padding="1dip"
-    android:gravity="center"
-    android:textColor="#FFF"
-    android:textSize="16sp"/>
+<?xml version="1.0" encoding="utf-8"?>
+<TextView
+    xmlns:android="http://schemas.android.com/apk/res/android"
+    android:textStyle="bold"
+    android:layout_width="match_parent"
+    android:layout_height="wrap_content"
+    android:padding="1dip"
+    android:gravity="center"
+    android:textColor="#FFF"
+    android:textSize="16sp"/>
diff --git a/android/vision-quickstart/app/src/main/res/layout/toggle_style.xml b/android/vision-quickstart/app/src/main/res/layout/toggle_style.xml
index 9a0c782..2a8468a 100755
--- a/android/vision-quickstart/app/src/main/res/layout/toggle_style.xml
+++ b/android/vision-quickstart/app/src/main/res/layout/toggle_style.xml
@@ -1,9 +1,9 @@
-<?xml version="1.0" encoding="utf-8"?>
-<selector xmlns:android="http://schemas.android.com/apk/res/android">
-  <item
-      android:drawable="@drawable/ic_switch_camera_white_48dp"
-      android:state_checked="true"/>
-  <item
-      android:drawable="@drawable/ic_switch_camera_white_48dp"
-      android:state_checked="false"/>
-</selector>
+<?xml version="1.0" encoding="utf-8"?>
+<selector xmlns:android="http://schemas.android.com/apk/res/android">
+  <item
+      android:drawable="@drawable/ic_switch_camera_white_48dp"
+      android:state_checked="true"/>
+  <item
+      android:drawable="@drawable/ic_switch_camera_white_48dp"
+      android:state_checked="false"/>
+</selector>
diff --git a/android/vision-quickstart/app/src/main/res/menu/camera_button_menu.xml b/android/vision-quickstart/app/src/main/res/menu/camera_button_menu.xml
index 8caf7e3..d618b34 100755
--- a/android/vision-quickstart/app/src/main/res/menu/camera_button_menu.xml
+++ b/android/vision-quickstart/app/src/main/res/menu/camera_button_menu.xml
@@ -1,12 +1,12 @@
-<?xml version="1.0" encoding="utf-8"?>
-<menu xmlns:android="http://schemas.android.com/apk/res/android"
-    xmlns:app="http://schemas.android.com/apk/res-auto">
-  <item android:id="@+id/select_images_from_local"
-      android:title="Select image from album"
-      android:orderInCategory="100"
-      app:showAsAction="never" />
-  <item android:id="@+id/take_photo_using_camera"
-      android:title="Take photo"
-      android:orderInCategory="100"
-      app:showAsAction="never" />
-</menu>
+<?xml version="1.0" encoding="utf-8"?>
+<menu xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:app="http://schemas.android.com/apk/res-auto">
+  <item android:id="@+id/select_images_from_local"
+      android:title=